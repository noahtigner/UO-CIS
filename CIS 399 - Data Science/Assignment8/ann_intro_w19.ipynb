{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rh4uU7eob-bc"
   },
   "source": [
    "<h1>\n",
    "<center>\n",
    "Module 8: Artificial Neural Nets\n",
    "</center>\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Deep learning is in the news and I think it is important for you to gain insight into its underlying mechanism. Spoiler alert: it is not that complicated. At least the basic theory is relatively straightforward. There are many many twiddles that are complex. But we can get a handle on the basics without too much difficulty (he says glibly).\n",
    "  <p>\n",
    "    The underlying idea of deep learning comes from an idea called neural nets (and before that, perceptrons). This can be a bit misleading. While the early work might have used the human brain as its model, with neurons firing, current deep learning research has dropped the brain connection.\n",
    "    <p>\n",
    "      This week we will build a way simple neural net. But even this simple net shows off all the pieces we need to grapple with. So let's get going.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_F-eyfiQj2ig"
   },
   "source": [
    "<h2>You have seen numpy before - we will be using it again</h2>\n",
    "\n",
    "We will use it to build 1d and 2d matrices. You could do the same thing with nested lists. But numpy has been honed to give fast processing so it is the go to library for working with neural net models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zn2536_DVRFX"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JJP5W7PQ5yB7"
   },
   "source": [
    "<h2>Our First Neural Net</h2>\n",
    "There is a lot of jargon around neural nets. I'll introduce you to some of it and note when it is jargon you might want to remember. First, what we will call a neural net is sometimes referred to as an artifical neural net or ANN (jargon). Take a look at the ANN below then let's talk about it.\n",
    "\n",
    "<img src='https://www.dropbox.com/s/09vo4h9mufmo6tn/Screenshot%202019-02-01%2015.23.42.png?raw=1'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bI53b4Fd6wtG"
   },
   "source": [
    "<h2>The Input layer</h2>\n",
    "\n",
    "Every ANN has an input layer. There is something called the input set or feature set (jargon). You can see that we have 3 circles, also called nodes (jargon), in the net above. The general idea is that we supply 3 values for the input and crank the net (my jargon) to get an output. \n",
    "<p>\n",
    "  It is totally fitting for you to think of the 3 input nodes as 3 columns in a table. The input set is the entire set of rows. We feed one row at a time to the net which pulls out the values of the 3 columns as input. Make sense?\n",
    "<p>\n",
    "You can view x1 as a feature, x2 as a feature and x3 as a feature. A feature of what? Well, if we were working with the titanic data, maybe x1 is Age, x2 is Gender and x3 is PClass. The rows of the titanic table would equal the feature set, where each row is called a sample (jargon).\n",
    "<p>\n",
    " Is there any magic about having 3 nodes in input layer? No. We are using 3 to keep things simple. But it is more typical to have many more nodes. For Titanic and Loan tables we would probably have around 10 nodes x1 through x10. If we were working with a 10 by 10 image of pixels, we would have 100 input nodes, one for each pixel.\n",
    "  <p>\n",
    "    Do the input values have to be of a specific form? They have to be numeric. And common practice is to normalize them to fall between 0 and 1. In our example we will use binary values. You can read this as x1,x2 and x3 correspond to specific features of some object. Making them binary says if x1 is 1 then the feature x1 is present in the current object, etc. Not unlike ohe, right? But the caveat is that you do not have to one-hot encode them. You could feed raw values from the Age column, for instance. They are numbers, right?\n",
    "    <p>\n",
    "      Let's build a feature set.  Remember, each item in this set is called a sample (analogous to a row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "vsxrSEX2Wa0N",
    "outputId": "9da4ddf0-b2a9-47d4-f7a8-916952105b21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_set = np.array([[0,1,0],[0,0,1],[1,0,0],[1,1,0],[1,1,1]])  #5 samples of 3 values each\n",
    "print(feature_set.shape)\n",
    "feature_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fptXcXwHauIF"
   },
   "source": [
    "The shape of the matrices we create with numpy is important. We have to match them up. We will run into this next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfEEge4Qhuqx"
   },
   "source": [
    "<h2>The Output layer</h2>\n",
    "â€‹\n",
    "Every ANN has an output layer. As the term \"layer\" implies, there can be more than one output node. We will get back to this later. For now we have only a single output node that corresponds cleanly with what we have been calling the target column. So if we are working with Titanic, the ouptut node would produce either 1 or 0 for every sample. We will see that it actually produces a value between 0 and 1 that we can view as the appoximation to a binary value. So if we get an output of `.7` we could view that as leaning toward `1`. A value of `.2` is leaning toward `0`.\n",
    "<p>\n",
    "  The output of an ANN is by convention called `z`.\n",
    "<p>\n",
    "Let's build the actual values we expect to be produced for the 5 samples. We can then later compare what our net produces against the actuals. There is a bit of a gotcha in how to use numpy to define the actuals. Your first shot might be as below.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "JeoON_XslUyN",
    "outputId": "27008cb2-7ad7-4b23-c15a-1e3b9b2658d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = np.array([1,0,0,1,1])  #5 actual values that go with the 5 samples - similar to values in Survived column\n",
    "print(test_labels.shape)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvgaGWlEmBLh"
   },
   "source": [
    "The problem is that we want the actuals to have the shape `(5, 1)` to align with the samples shape of `(5,3)`. Let's look at alternative ways to add a new dimension. First, I will use `numpy` to expand `test_labels` into the shape `(5, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "1ZhtVroQcJxb",
    "outputId": "cbc26f2e-4218-4e92-cc4f-d1764107b0d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels1 = np.expand_dims(test_labels, axis=1)  # Equivalent to test_labels[:,np.newaxis]\n",
    "print(labels1.shape)\n",
    "labels1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UnV-yNvFcIvp"
   },
   "source": [
    "As an alternative, I can start with a nested list and reshape it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "e9phyh61jocb",
    "outputId": "dcfc66a1-88c7-47a9-b31e-cbc5685e1673"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "(5, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels2 = np.array([[1,0,0,1,1]])  #note now nested\n",
    "print(labels2.shape)  #before shape\n",
    "labels2 = labels2.reshape(5,1)  #this should now align with the samples shape\n",
    "print(labels2.shape)  #after shape\n",
    "labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyFvjyN2deVV"
   },
   "outputs": [],
   "source": [
    "labels = labels2  #go ahead and use labels2 (which is equiv to labels1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZGOG_dZ_dsUA"
   },
   "source": [
    "<h2>Let's take stock</h2>\n",
    "\n",
    "We have our input feature set, which consists of 5 samples (rows). For now you can think of this as a reworked version of the Titanic table or Loan table with only 3 columns in use and 5 rows of data.\n",
    "<p>\n",
    "  We have the actual value of the target column for each sample. Would be equivalent to the `Survived` column.\n",
    "  <p>\n",
    "    Next up are the internals of the net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLs5FUMaeYNP"
   },
   "source": [
    "<h2>The weights</h2>\n",
    "Focus on the vairalbes w1, w2 and w3. These stand for the weights associated with the connections or links from the 3 input nodes to the output node. I tend to think of the weights actually being part of the output node but they are typically drawn on the links themselves. It is these weights that are the key to everything. The goal is to learn (jargon) them. We will start them off as random numbers. We will see later how we will adjust them depending if we predicted right or wrong.\n",
    "<p>\n",
    "  The typical way to choose the initial weights is as random numbers drawn from a uniform distribution between 0 and 1. The cool thing about the `rand` method is that it allows us to specify the shape of numbers we want. In our case we want a 3 x 1 shape to match up with the 3 values of the input nodes.\n",
    "  <p>\n",
    "    One more thing. I am using a seed to make sure I get the same random numbers every time I run this notebook. Helps with debugging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "BwOhW1FYWi1G",
    "outputId": "7ef94941-779a-4c06-d41e-68d3f38f7fab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.37454012],\n",
       "       [0.95071431],\n",
       "       [0.73199394]])"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)  #useful for debugging\n",
    "weights = np.random.rand(3,1)  \n",
    "print(weights.shape)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GsICjvaBhU00"
   },
   "source": [
    "<h2>The bias</h2>\n",
    "\n",
    "It's kind of confusing the way the tree is drawn above. There is actually a 4th link coming into the output node called the bias (jargon). One way to view it is as a bias node with a constant value of 1 (or 0 if you want to shut the bias off). It has a weight on the link. And that weight starts out as random.\n",
    "<p>\n",
    "  <img src='https://www.dropbox.com/s/2tyn4r20v83m0do/Screenshot%202019-02-24%2009.16.54.png?raw=1'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "bz4Y0Hhjg3uO",
    "outputId": "a8789696-70b1-45ce-bada-5d31e1a65e84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.59865848])"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = np.random.rand(1)\n",
    "print(bias.shape)\n",
    "bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iNQ-OWMlj6Fa"
   },
   "source": [
    "We can leave the bias in this shape given it does not align with anything (other than a phantom node that is always 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SXBeiuVV5qIx"
   },
   "source": [
    "<h2>The formula</h2>\n",
    "\n",
    "Here is just the ouput node from the figure.\n",
    "\n",
    "<img src='https://www.dropbox.com/s/1ckfzkhr4997db4/Screenshot%202019-02-05%2015.05.11.png?raw=1'>\n",
    "\n",
    "You can see  a summation xi`*`wi for i=1,n. In our case n = 3. So it says to mupltiply each input value by its corresonding link weight. And sum that all up. I suppose I could write a for-loop to do this. But numpy has some operations that will make it trivial. That is why we took time to get our matrices in the right shape.\n",
    "<p>\n",
    "  The bias gets added to the final sum.\n",
    "  <p>\n",
    "    Check out code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "MF1L7Aim7rkd",
    "outputId": "bb239460-3800-487c-d859-f965a34e8750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at first sample from feature_set - this is the raw input coming in\n",
    "\n",
    "sample0 = np.expand_dims(feature_set[0], axis=1) #transform to match up with weight shape\n",
    "print(sample0.shape)\n",
    "sample0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "pKr7v1KwazFu",
    "outputId": "867b4117-f00d-4bd9-b7d3-9b4ed584fcce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.95071431],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XW = np.multiply(sample0, weights)  #let numpy do its thing\n",
    "print(XW.shape)\n",
    "XW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4iNM1bt8ccYj"
   },
   "source": [
    "We now have each of the results of `xi*wi`. Out next step is to sum them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RYK_PpBBbzeK",
    "outputId": "af319957-ffb1-4ae9-f9d4-39506065079f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95071431])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sum the column directly - gets you the number in an array which is what we want\n",
    "\n",
    "XW_sum = np.sum(XW, axis=0)\n",
    "XW_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lTQkSXrxd32D"
   },
   "source": [
    "Now we need to add bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4Q0GSAjVdoof",
    "outputId": "43e8bf05-325b-4690-d5b9-dd628aec3308"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.54937279])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_output = XW_sum + bias\n",
    "raw_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ulj0m5pUetqO"
   },
   "source": [
    "<h2>Next way big idea: activation functions</h2>\n",
    "\n",
    "Why aren't we done? I can just use `raw_output` as the node's output. I am going to give you the intuition and punt on the details. I strongly suggest you take the CIS Machine Learning class to delve deeper. In fact I will keep repeating this so much that I will just put `CIS472` in parens to signal that that course provides details. Ok, back to the intuition. My claim is that all we really have now is a linear formula. So raw_output is the linear result of multiplying inputs by weights and summing. Because of this, we will only be effective looking at problems with a linear solution. The bad news is that the vast number of problems we want to model with an ANN are non-linear. And worse, even the linear ones have much simpler means to use to model, e.g., linear regression. So we are going to introduce a non-linear function that will take the raw_output result and transform it into the actual output z. This function is called the activation function (jargon).\n",
    "<p>\n",
    "  Our activation function, shown as sigma in the formula, will  help us grapple with highly non-linear problems. I am going to use a function called sigmoid. There are other alternatives with their pluses and minuses. In particular, the leaky-RELU function has become popular recently (CIS472). Here is the sigmoid function:\n",
    "  <br>\n",
    "  <img src='https://www.dropbox.com/s/gfa7zlka1oqnc9a/Screenshot%202019-02-06%2012.39.55.png?raw=1'>\n",
    "  <br>\n",
    "  Let's define it in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5SacpljWocW"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):  \n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67mjUqRoi7aj"
   },
   "source": [
    "We can get some intition of what is going on by plotting it on some random values. Notice that the ouput is between 0 (for large negative values) and 1 (for large positive values). The decimal point is a bit hard to discern on the y axis but it is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "ULeJuHUzWXOH",
    "outputId": "bbabd34f-d7d7-48f4-cca1-ca103ffb74ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f782f8aef60>]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#randomly generate 100 linearly-spaced points between -10 and 10\n",
    "input = np.linspace(-10, 10, 100)\n",
    "\n",
    "from matplotlib import pyplot as plt  \n",
    "plt.plot(input, sigmoid(input), c=\"r\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5HQCc8ARjYhQ"
   },
   "source": [
    "Ok, ready to try it on our raw_output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5eHcvfe5jdB8",
    "outputId": "3ed56889-59a3-4011-a7b2-40534413e90f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82482312])"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = sigmoid(raw_output)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHkycIqekgmN"
   },
   "source": [
    "<h2>How did we do?</h2>\n",
    "\n",
    "We have an ouput very close to 1. How far are we off from the actual value? If the actual value is 0, we are way off. If it is 1, we are close. What we need is an error function (jargon). This is also called the cost function (jargon) or loss function (jargon). It gives us a way to compute how far we are off. I am going to use a standard function called Mean-Squared Error. Here it is.\n",
    "<br>\n",
    "<img src='https://www.dropbox.com/s/cltfyoukbg3h0cb/Screenshot%202019-02-01%2015.25.35.png?raw=1'>\n",
    "<br>\n",
    "Our n is 1: we are computing the error for a single sample at a time, i.e., a batch size of 1 (jargon). So this simplfies to below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cv9B_oCcmgE_"
   },
   "outputs": [],
   "source": [
    "def mse(z,y):\n",
    "  return (z-y)**2\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m7f2JdSNnBmb",
    "outputId": "a58eec0e-6ba2-4e23-af85-6807948f69ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03068694])"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = mse(z, labels[0])  #looking at label for 0th sample\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_hbj9TDKv5aa"
   },
   "source": [
    "Pretty small cost/error, right? Looks like the actual value was 1. So we were close.\n",
    "<p>\n",
    "  We are now done with what is called forward propogation. We have produced a result in `z` for the first sample and computed the error, which we are calling the cost. Now comes the fun part: \"learning\". You want to delve into machine learning? We are now at the learning stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XJR2dm5wps3"
   },
   "source": [
    "<h2>Backward Propogation</h2>\n",
    "\n",
    "Let me first give you the intuition of what learning means in an ANN. We have an error, right? What I want to do is reduce that error. How can I reduce the error? The only knobs I have to turn are the weights (including the bias weight). So I want to change the weights to reduce the error.\n",
    "<p>\n",
    "  Next question: how can we change each weight to reduce the error? Here is one idea. We have 4 weights. Keep trying different combinations of the 4 to find a combo that is closer to 1 than `0.82482312` and hence reduces our error. I'll call this the brute force approach. It does not work. At least not for ANNs with hundreds or even thousands of weights. We need a more principled way to do weight changing.\n",
    "  <p>\n",
    "  I'll give you a way that uses partial differential-equations and the chain rule. Again, I am going to give you a high-level view of things (CIS472). The intuition is that I want to make the mse result smaller. The mse function has 2 parameters, but I can only control 1 of them, `z`. So the question I ask is how to change z to make mse(z,y) smaller? That is a partial differential-equation question I claim. How does a change in one of the parameters (a partial of the full set of parameters) affect the output? Answer: take the partial derivative of mse with respect to z. You can find the full derivation on the web and CIS472. I'll just tell you that it is `(z-y)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBMiK01D8PDW"
   },
   "outputs": [],
   "source": [
    "#derivate of the mse cost function with respect to z\n",
    "\n",
    "def mse_der(z,y):\n",
    "  return z-y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VeAzjDd_I-_Z"
   },
   "source": [
    "Let's apply it to what we have for sample 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9biW7TkBJE9q",
    "outputId": "e9768713-342d-4e43-fece-e400366971d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.17517688]\n"
     ]
    }
   ],
   "source": [
    "mse_deriv_value = mse_der(z, labels[0])\n",
    "print(mse_deriv_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yrs4o2Ua9FcS"
   },
   "source": [
    "Cool. We now know we need to make a change to `z` of `-.175` to reduce our cost. But we now have to ask a follow up question. How did we get z in the first place? Looking backward in the net, we can see that the sigmoid function produced z. You got it. We will repeat the process for the sigmoid function. The sigmoid function takes our dot product of inputs and weights plus bias as input to produce z. So the question is how does sigmoid change in respect to the weights (including bias)? That is another partial derivative question. I need to know the partial derivate of the sigmoid function. I am going to be nice and just give it to you. But you can google to see all the steps and CIS472."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_7nd2GJ0Ws6b"
   },
   "outputs": [],
   "source": [
    "#derivative of the sigmoid function with respect to x (which is raw_output)\n",
    "\n",
    "def sigmoid_der(x):  \n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vD0L4XrfJvOS"
   },
   "source": [
    "Now applying it to sample 1 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FsWOoAhNJzuV",
    "outputId": "8e2bea40-3d71-4227-bb93-3901390ad877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14448994]\n"
     ]
    }
   ],
   "source": [
    "sigmoid_deriv_value = sigmoid_der(raw_output)\n",
    "print(sigmoid_deriv_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cMsaEKLT-ZpD"
   },
   "source": [
    "We now know we need to make a change to `raw_output` of `.144` for sigmoid to play its part in helping reduce our cost.\n",
    "<p>\n",
    "  You can guess the drill by now. We have to ask how can we make a change to `raw_output` to eventually reduce the cost?\n",
    "Keep paddling upstream. We now are at the stage of looking at the make up of raw_output. We know it is the sum of `xi*wi` plus bias. We are getting close to the knobs we can turn,  i.e., the weights. Here is how we got raw_output:\n",
    "<pre>\n",
    "`raw_output = x1*w1 + x2*w2 + x3*w3 + b`\n",
    "</pre>\n",
    "What we need is the partial derivative of this sum with respect to each weight. Note that we are actually building 4 chains: one from w1, one from w2, one from w3 and one from the bias. What is the change in raw_output in terms of w1 (i.e., what is the partial derivative of the summation with respect to w1)? It's x1, i.e., the input from node1. For example if we change w1 by a small value h and hold everything else constant, we will see:\n",
    "<pre>\n",
    "`x1*(w1+h) = x1*w1 + x1*h` \n",
    "</pre>\n",
    "so a change of `x1*h` in the result. Same for w2 and w3: use their respective inputs as the partial derivate. You can view b (the bias) as a weight on the constant value 1. Hence, its derivate is simply 1. If you change `b` by `h` you will see a change in the summation of `1*h` or simply `h`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1C15jfgVCVBg"
   },
   "source": [
    "<h2>Glue this all together</h2>\n",
    "\n",
    "I think we have the pieces we need. Our goal is to answer 4 separate questions: how to change w1, how to change w2, how to change w3, how to change the bias. Let's start with the first question. How should we change w1 to reduce the cost. First, let's compute the value of the last 2 derivates in the chain and cache that in a variable. We only have to do this once for all the weights. It is a component of all 4 chains that stays the same no matter what weight we are focusing on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HJLq5wulCt7k",
    "outputId": "b9a5de27-513f-491c-cfc6-7955e52061f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0253113]\n"
     ]
    }
   ],
   "source": [
    "#last 2 terms in each of the 4 chains leading to weights\n",
    "\n",
    "z_delta = mse_deriv_value * sigmoid_deriv_value  #this stays constant for each weight-chain we focus on\n",
    "print(z_delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "75f6o7aiKNjU",
    "outputId": "b9629623-d63b-4d24-d636-f057c8d7419d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.]\n"
     ]
    }
   ],
   "source": [
    "#complete the chain that leads to weight 1\n",
    "\n",
    "x1 = sample0[0]  #x1 is the input that goes with w1 - it is the derivative of the sum with respect to w1\n",
    "w1_chain_value = (x1 * z_delta)  #this completes the chain from w1 all the way to output z and the cost function\n",
    "\n",
    "print(w1_chain_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6orYQw5fKquT"
   },
   "source": [
    "What does this say? It literally says we need to change w1 by `-0.` to see a change in cost, i.e., don't make a change. What it actually says is that if we have a value of 0 for a feature, or more generally, a value of 0 anywhere in the chain, then we will always get a change of 0. In essence, we will ignore weight 1 for this sample; it contributed nothing, good or bad, to the final result. As you can see, same thing will happen for x3: it also has a value of 0. That leaves us with w2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vSNLFg4vKuaV",
    "outputId": "5999f056-b962-485b-dab5-630fa8b4a688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0253113]\n"
     ]
    }
   ],
   "source": [
    "x2 = sample0[1]  #x2 is the input that goes with w2 - it is the derivative of the sum with respect to w2\n",
    "w2_chain_value = (x2 * z_delta)\n",
    "\n",
    "print(w2_chain_value)  #this is the change we need to make for w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HmDuX-oyK80O",
    "outputId": "22304856-245e-4b31-df41-dfc139600cd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.]\n"
     ]
    }
   ],
   "source": [
    "x3 = sample0[2]  #x3 is the input that goes with w3 - it is the derivate of the sum with respect to w3\n",
    "w3_chain_value = (x3 * z_delta)\n",
    "\n",
    "print(w3_chain_value)  #0 just like we thought it would be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2CyG4AVxLQQW"
   },
   "source": [
    "The bias derivate is just 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WJ5t_mT-LV4p",
    "outputId": "31127270-f026-4c2c-f525-58b2608d1c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0253113]\n"
     ]
    }
   ],
   "source": [
    "b_chain_value = 1.0 * z_delta\n",
    "print(b_chain_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AkoFcKpqLrsJ"
   },
   "source": [
    "<h2>We are amost ready to go</h2>\n",
    "\n",
    "We now have all the changes we have to make. A knotty question is how to make them. We know we want to make changes to all the weights to reduce the cost. And we have all the raw changes. But do we add or subtract those raw changes? What we really get with the changes is the slope of the cost function  at a specific point (i.e., the weight we are focuing on). I could bring in some nice graphs here that show you that we want to move along the slope toward a minimum, i.e., 0. And to do that, we subtract. What that means is that if the slope is positive we get a true subtraction. If the slope is negative we actually get an addition. I won't bring the graphs in but they are way easy to find by googling. And yet again, CIS472\n",
    "<p>\n",
    "  One more piece of jargon. This idea of following the slope down to a minimum is called gradient descent. You will hear it all the time. It is not the only way to do back-propogation but it is the standard for now. We have been doing gradient descent in case that is not clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bpcUjFmkTioi"
   },
   "source": [
    "<h2>One last thing - the learning rate</h2>\n",
    "\n",
    "Here is what I want to do:\n",
    "<pre>\n",
    "weights[0][0] -= w1_chain_value  #make the actual change by subtracting the slope\n",
    "</pre>\n",
    "But I have a concern. If I don't tamp this down the change can whipsaw me: first I'll lower the weight but by too much; then I will compensate by rasiing the weight by too much. I am going to add a new hyper-parameter called the learning rate (jargon). So now I have this where `alpha` is the learning rate.\n",
    "\n",
    "<pre>\n",
    "`weights[0][0] -= alpha * w1_chain_value  #make the actual change`\n",
    "</pre>\n",
    "I said I would not bring in graphs, but I kind of like this figure as visualization. It is simple being in 2d-space where we mostly are in n-space for large n, i.e., we are searching over a much more complex surface. But it gets the idea across. The top graph is with a very small learning rate (maybe close to 0) that makes changes extremely cautiously. While it makes steady progress toward the minimum, it can take too long. On the other hand, a learning rate close to 1 or higher can bounce back and forth, potentially getting farther and farther away as it over-compensates as shown in the bottom figure. I really like the discussion of gradient descent and learning rates discussed here: https://blog.paperspace.com/intro-to-optimization-in-deep-learning-gradient-descent/.\n",
    "<p>\n",
    "<img src='https://www.dropbox.com/s/ful9uc4htqhwmtm/Screenshot%202019-02-07%2015.46.20.png?raw=1'>\n",
    "  <p>\n",
    "Keeping the learning rate at an effective value is a whole area on its own. See https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10 or CIS472."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I5VKJXqhUWjy"
   },
   "source": [
    "I'll set the learning rate at `.05` and not change it. Why do I say I won't change it? Becuase some recent research says that you should modify your learning rate as you go (CIS472). I'll keep it constant.\n",
    "<p>\n",
    "  It does open up a question for me. Should we be changing our hyper-parameters as we go? We have been viewing them as constants we set before getting into tree building or row-choosing in K-NN. But maybe we should change them on the fly. Could be an interesting topic for research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "o10OrtqsGG57",
    "outputId": "3840f6e0-39f9-4ce9-9967-9f38a746dd51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3745401188473625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3745401188473625"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = .05  #learning rate that does not change once set\n",
    "\n",
    "print(weights[0][0])\n",
    "weights[0][0] -= alpha*w1_chain_value  #make the actual change\n",
    "weights[0][0]  #no change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aLIxumq4sTPQ"
   },
   "source": [
    "We just made our adjustment to w1. Now for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "xcd0XOwAuN_n",
    "outputId": "5179bf55-3e24-4e79-cd4f-bf84b6446a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95071431]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.95197987])"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(weights[1])\n",
    "weights[1] -= alpha*w2_chain_value  #make the actual change\n",
    "weights[1]  #up a bit: minus minus is a plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "mdevaiA8surV",
    "outputId": "6a5f5226-2eba-4e30-9d7e-35e70f7c0c43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73199394]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.73199394])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(weights[2])\n",
    "weights[2] -= alpha*w3_chain_value  #make the actual change\n",
    "weights[2]  #no change as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "9cqLB2ess8wq",
    "outputId": "1129325d-ed73-4db3-d1b7-3832c639fea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59865848]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.59992405])"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bias)\n",
    "bias -= alpha*b_chain_value  #make the actual change\n",
    "bias  #up a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jhvNAizabMej"
   },
   "source": [
    "<h2>Another big idea - epochs</h2>\n",
    "\n",
    "In machine learning models that do not use an ANN approach, e.g., decision trees, we have a training set and a test set. We run through the training set once to build our model. Then we test it. Not so with an ANN. We do run through the training set. But then we do it again and again. Each march through the training set is called an epoch (jargon). I have a tendency to pronounce it \"ep ick\" from my surfing days: epic wave dude. But it is actually \"eee pock\". If I slip you will know what I mean.\n",
    "<p>\n",
    "  There is no concept of epoch in decision trees.\n",
    "We don't adjust our tree on the fly given how well we do at prediction. There is no cost function applied until we have completed all of our predictions.  It's pretty cut-and-dry. We use the GIG score to decide on a splitter and then move our way down to build more of the tree. Once the tree is built, it is built. Not going to change unless we rebuild it with different hyper-parameters.\n",
    "<p>\n",
    "  With an ANN we adjust our model at every sample. One time through the training set is unlikely enough to train our weights, especially if we have a low learning rate. We need to go over the samples again and again. How many times? That is a hyper-parameter that you set. How do you know when to stop? When it appears that the cost has reached a minimum; your weight adjustments are not getting anywhere better. We need an epoch-loop that reruns the samples over and over, constantly adjusting the weights. Something like:\n",
    "  <p>\n",
    "\n",
    "<pre>\n",
    "for i in range(max_epoch):\n",
    "     for sample in samples:\n",
    "         #do forward propogation\n",
    "         #do backward propogation\n",
    "</pre>\n",
    "Ok, let's start defining our ANN builder loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1uH19Ryrebf"
   },
   "outputs": [],
   "source": [
    "all_samples = feature_set  #just a renaming that makes it clearer to me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gpifco3S0hho"
   },
   "source": [
    "Here are samples as reminder: `np.array([[0,1,0],[0,0,1],[1,0,0],[1,1,0],[1,1,1]])`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cLr7Mfn_uryo"
   },
   "source": [
    "<h2>Let's crank this puppy up</h2>\n",
    "\n",
    "I am going to restart the weights at random values at top. And I will choose to run 10 epochs.\n",
    "<p>\n",
    "  I'll print out the cost at the end of every epoch. We hope to see the cost going down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Nc8FYtzMzo5Z",
    "outputId": "49fe2da3-c263-496a-9fb0-2e58b401bfb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 23]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [0,0]\n",
    "\n",
    "x += [1,23]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "QBVhxELOgywU",
    "outputId": "338a8525-e02d-4af8-cebd-3095ab88cbc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, array([0.23823768]))\n",
      "(1, array([0.21841014]))\n",
      "(2, array([0.20097284]))\n",
      "(3, array([0.18730351]))\n",
      "(4, array([0.17758921]))\n",
      "(5, array([0.17109738]))\n",
      "(6, array([0.16681728]))\n",
      "(7, array([0.16389386]))\n",
      "(8, array([0.16174732]))\n",
      "(9, array([0.16002945]))\n"
     ]
    }
   ],
   "source": [
    "#reset the weights\n",
    "np.random.seed(42)  #useful for debugging\n",
    "weights = np.random.rand(3,1)\n",
    "bias = np.random.rand(1)\n",
    "\n",
    "max_epochs = 10  #just try it for 10 to debug\n",
    "\n",
    "cost_accumulator = [0, 0]  #[count, sum] use to print out costs now and then\n",
    "\n",
    "for i in range(max_epochs):\n",
    "  \n",
    "  #Go through each sample forward and backward\n",
    "  for j in range(len(all_samples)):\n",
    "\n",
    "\n",
    "    #do forward propogation\n",
    "    sample = np.expand_dims(all_samples[j], axis=1) #transform to match up with weight shape\n",
    "    XW = np.multiply(sample, weights)\n",
    "    XW_sum = np.sum(XW, axis=0)\n",
    "    raw_output = XW_sum + bias\n",
    "    z = sigmoid(raw_output)\n",
    "\n",
    "    #compute error\n",
    "    cost = mse(z, labels[j])\n",
    "    cost_accumulator[0] += 1\n",
    "    cost_accumulator[1] += cost\n",
    "    \n",
    "    #back propogation\n",
    "    mse_deriv_value = mse_der(z, labels[j])\n",
    "    sigmoid_deriv_value = sigmoid_der(raw_output)\n",
    "    z_delta = mse_deriv_value * sigmoid_deriv_value\n",
    "    \n",
    "    #update weights\n",
    "    for k in range(len(weights)):\n",
    "      weights[k][0] -= alpha * all_samples[j][k] * z_delta\n",
    "\n",
    "    #update bias\n",
    "    bias -=  1.0*z_delta\n",
    "      \n",
    "  #print average cost\n",
    "  if i%1 == 0:\n",
    "    average_cost = cost_accumulator[1]/cost_accumulator[0]  #really mse\n",
    "    print((i,average_cost))\n",
    "    cost_accumulator = [0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ub2G1ac5vJSI"
   },
   "source": [
    "Can we do better with more epochs? Before we try some different epoch values, let's get this into a function to make it easier to experiment. Notice that I have avoided using the constant `3` in the function. In this way the function should work with any number of input nodes. Cool, huh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIM-MWKC34Vd"
   },
   "outputs": [],
   "source": [
    "def ann_simple(all_samples, labels, weights, bias, hypers={}):\n",
    "  \n",
    "  '''\n",
    "  Can build an ANN with n input nodes and one output node.\n",
    "  Uses sigmoid and mse.\n",
    "  '''\n",
    "  \n",
    "  input_n = all_samples.shape[1]  #number of inputs in each sample\n",
    "  \n",
    "  assert weights.shape == (input_n,1), 'weights needs to have same shape as sample'\n",
    "  assert all_samples.shape[0] >= 1, 'all_samples must represent 1 or more samples'\n",
    "  assert bias.shape == (1,) , 'a single bias weight for output node'\n",
    "  assert labels.shape[1] == 1, 'actual value for the 1 output node'\n",
    "  assert labels.shape[0] == all_samples.shape[0], 'labels must match up with samples'\n",
    "  \n",
    "  hyper_keys = [*hypers]  #fails on 2.7\n",
    "  target_set = set(['epochs', 'cost-reporting', 'learning-rate'])  #might add more later\n",
    "  diff_set = set(hyper_keys) - target_set\n",
    "  if diff_set: print('WARNING: unrecognized hyper parameters ' + str(diff_set))\n",
    "\n",
    "  max_epochs = hypers['epochs'] if 'epochs' in hypers else 100\n",
    "  cost_reporting = hypers['cost-reporting'] if 'cost-reporting' in hypers else 100  #how often to report epoch cost\n",
    "  alpha = hypers['learning-rate'] if 'learning-rate' in hypers else .05\n",
    "  \n",
    "  cost_accumulator = [0, 0]  #[count, sum] use to print out costs now and then\n",
    "  \n",
    "  for i in range(max_epochs):\n",
    "\n",
    "    #Go through each sample forward and backward\n",
    "    for j in range(len(all_samples)):\n",
    "\n",
    "\n",
    "      #do forward propogation\n",
    "      sample = np.expand_dims(all_samples[j], axis=1) #transform to match up with weight shape\n",
    "      XW = np.multiply(sample, weights)\n",
    "      XW_sum = np.sum(XW, axis=0)\n",
    "      raw_output = XW_sum + bias\n",
    "      z = sigmoid(raw_output)  #what we are predicting\n",
    "\n",
    "      #compute error\n",
    "      cost = mse(z, labels[j])\n",
    "      cost_accumulator[0] += 1  #use to print out\n",
    "      cost_accumulator[1] += cost  #use to print out\n",
    "\n",
    "      #back propogation\n",
    "      mse_deriv_value = mse_der(z, labels[j])\n",
    "      sigmoid_deriv_value = sigmoid_der(raw_output)\n",
    "      z_delta = mse_deriv_value * sigmoid_deriv_value\n",
    "\n",
    "      #update weights - notice z_delta part of each update\n",
    "      for k in range(len(weights)):\n",
    "        weights[k][0] -= alpha * all_samples[j][k] * z_delta\n",
    "        \n",
    "      #update bias\n",
    "      bias -=  1.0*z_delta\n",
    "\n",
    "    #print ith cost value\n",
    "    if i%cost_reporting == 0:\n",
    "        average_cost = cost_accumulator[1]/cost_accumulator[0]  #really mse where n is cost_reporting epochs\n",
    "        print((i,average_cost))\n",
    "        cost_accumulator = [0, 0]  #reset\n",
    "  #end epoch loop\n",
    "  \n",
    "  if cost_accumulator[0]:\n",
    "    average_cost = cost_accumulator[1]/cost_accumulator[0]  #really mse where n is cost_reporting epochs\n",
    "    print((max_epochs,average_cost))\n",
    "    \n",
    "  return (weights,bias)  #don't lose these! They are the whole model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I_zGhLfLwXLL"
   },
   "source": [
    "I'm going to define one more function that resets all the weights for each experiment we try. And the cool thing about this function is that it is elastic. It will provide weights for your sample size. If you pass it samples where each sample has 4 input values, the function will randomize 4 weights. I like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1jri1AlBLYM"
   },
   "outputs": [],
   "source": [
    "def from_scratch(samples, labels, hypers):\n",
    "  \n",
    "  input_n = samples.shape[1]\n",
    "  \n",
    "  #reset weights to initial values. Seed of 42 guarantees same random values\n",
    "  np.random.seed(42)\n",
    "  weights = np.random.rand(input_n,1)  #elasticity in action\n",
    "  bias = np.random.rand(1)\n",
    "  \n",
    "  return ann_simple(samples, labels, weights, bias, hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tEaYaDfkDDfn"
   },
   "source": [
    "<h2>Let's do a first test</h2>\n",
    "\n",
    "I'll try with 10 epochs and report on every epoch. Should match our results above before we introducted the functions. And it does. Good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "ZoKl7BcJ-vn7",
    "outputId": "17395191-9b20-4c03-c688-103398f8b13a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, array([0.23823768]))\n",
      "(1, array([0.21841014]))\n",
      "(2, array([0.20097284]))\n",
      "(3, array([0.18730351]))\n",
      "(4, array([0.17758921]))\n",
      "(5, array([0.17109738]))\n",
      "(6, array([0.16681728]))\n",
      "(7, array([0.16389386]))\n",
      "(8, array([0.16174732]))\n",
      "(9, array([0.16002945]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.34994795],\n",
       "        [1.02310216],\n",
       "        [0.67207782]]), array([-0.63186666]))"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_scratch(all_samples, labels, hypers={'epochs':10, 'cost-reporting': 1}) #report cost on each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JzsxBTC6DXSf"
   },
   "source": [
    "10 epochs? Pshaw. 10 is for the timid.\n",
    "<p>\n",
    "  Just to show you we are not in Kansas anymore, check this out. I am going to use 200,000 epochs. I'll report the average error every 2000th time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1764
    },
    "colab_type": "code",
    "id": "7Rwwkz-6CWyX",
    "outputId": "f17b1663-f149-446e-d449-d151cfc2c7b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, array([0.23823768]))\n",
      "(2000, array([0.02196255]))\n",
      "(4000, array([0.0034249]))\n",
      "(6000, array([0.00192183]))\n",
      "(8000, array([0.00133299]))\n",
      "(10000, array([0.00101865]))\n",
      "(12000, array([0.00082336]))\n",
      "(14000, array([0.00069039]))\n",
      "(16000, array([0.00059409]))\n",
      "(18000, array([0.00052117]))\n",
      "(20000, array([0.00046407]))\n",
      "(22000, array([0.00041814]))\n",
      "(24000, array([0.00038043]))\n",
      "(26000, array([0.0003489]))\n",
      "(28000, array([0.00032216]))\n",
      "(30000, array([0.0002992]))\n",
      "(32000, array([0.00027928]))\n",
      "(34000, array([0.00026182]))\n",
      "(36000, array([0.0002464]))\n",
      "(38000, array([0.00023269]))\n",
      "(40000, array([0.00022041]))\n",
      "(42000, array([0.00020935]))\n",
      "(44000, array([0.00019935]))\n",
      "(46000, array([0.00019025]))\n",
      "(48000, array([0.00018194]))\n",
      "(50000, array([0.00017432]))\n",
      "(52000, array([0.00016731]))\n",
      "(54000, array([0.00016084]))\n",
      "(56000, array([0.00015484]))\n",
      "(58000, array([0.00014928]))\n",
      "(60000, array([0.0001441]))\n",
      "(62000, array([0.00013926]))\n",
      "(64000, array([0.00013474]))\n",
      "(66000, array([0.0001305]))\n",
      "(68000, array([0.00012652]))\n",
      "(70000, array([0.00012277]))\n",
      "(72000, array([0.00011924]))\n",
      "(74000, array([0.0001159]))\n",
      "(76000, array([0.00011274]))\n",
      "(78000, array([0.00010976]))\n",
      "(80000, array([0.00010692]))\n",
      "(82000, array([0.00010423]))\n",
      "(84000, array([0.00010166]))\n",
      "(86000, array([9.92235815e-05]))\n",
      "(88000, array([9.6897664e-05]))\n",
      "(90000, array([9.46777809e-05]))\n",
      "(92000, array([9.25568592e-05]))\n",
      "(94000, array([9.05284409e-05]))\n",
      "(96000, array([8.85866168e-05]))\n",
      "(98000, array([8.672597e-05]))\n",
      "(100000, array([8.49415256e-05]))\n",
      "(102000, array([8.32287065e-05]))\n",
      "(104000, array([8.15832944e-05]))\n",
      "(106000, array([8.00013955e-05]))\n",
      "(108000, array([7.84794099e-05]))\n",
      "(110000, array([7.70140042e-05]))\n",
      "(112000, array([7.56020877e-05]))\n",
      "(114000, array([7.42407902e-05]))\n",
      "(116000, array([7.29274432e-05]))\n",
      "(118000, array([7.16595622e-05]))\n",
      "(120000, array([7.04348313e-05]))\n",
      "(122000, array([6.92510889e-05]))\n",
      "(124000, array([6.81063154e-05]))\n",
      "(126000, array([6.69986216e-05]))\n",
      "(128000, array([6.5926238e-05]))\n",
      "(130000, array([6.48875063e-05]))\n",
      "(132000, array([6.38808698e-05]))\n",
      "(134000, array([6.29048666e-05]))\n",
      "(136000, array([6.1958122e-05]))\n",
      "(138000, array([6.10393424e-05]))\n",
      "(140000, array([6.01473089e-05]))\n",
      "(142000, array([5.92808728e-05]))\n",
      "(144000, array([5.84389499e-05]))\n",
      "(146000, array([5.76205162e-05]))\n",
      "(148000, array([5.68246043e-05]))\n",
      "(150000, array([5.60502987e-05]))\n",
      "(152000, array([5.52967331e-05]))\n",
      "(154000, array([5.45630866e-05]))\n",
      "(156000, array([5.38485813e-05]))\n",
      "(158000, array([5.31524791e-05]))\n",
      "(160000, array([5.24740791e-05]))\n",
      "(162000, array([5.1812716e-05]))\n",
      "(164000, array([5.11677569e-05]))\n",
      "(166000, array([5.05386002e-05]))\n",
      "(168000, array([4.9924673e-05]))\n",
      "(170000, array([4.93254301e-05]))\n",
      "(172000, array([4.87403516e-05]))\n",
      "(174000, array([4.81689421e-05]))\n",
      "(176000, array([4.7610729e-05]))\n",
      "(178000, array([4.70652611e-05]))\n",
      "(180000, array([4.65321076e-05]))\n",
      "(182000, array([4.60108568e-05]))\n",
      "(184000, array([4.55011152e-05]))\n",
      "(186000, array([4.50025064e-05]))\n",
      "(188000, array([4.45146702e-05]))\n",
      "(190000, array([4.40372618e-05]))\n",
      "(192000, array([4.35699511e-05]))\n",
      "(194000, array([4.31124214e-05]))\n",
      "(196000, array([4.26643693e-05]))\n",
      "(198000, array([4.2225504e-05]))\n",
      "(200000, array([4.17956522e-05]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.12526813],\n",
       "        [10.03119447],\n",
       "        [-0.15533876]]), array([-4.92274282]))"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_scratch(all_samples, labels, hypers={'epochs':200000, 'cost-reporting': 2000}) #go big or go home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YezkKiKGC1b3"
   },
   "source": [
    "<h2>Wow</h2>\n",
    "\n",
    "Still driving cost down after 200K epochs. And look at the last reported cost. Way small. But don't confuse cost with accuracy. They are related but I'll leave that to you to explore in CIS472. For now a rule of thumb is the lower the cost, the better the accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Li7hQbhlJHiK"
   },
   "source": [
    "<h2>Let's do some testing</h2>\n",
    "\n",
    "We have trained our 4 weights. Let's go through the 5 samples and have our simple ANN predict. We can then get the accuracy.\n",
    "<p>\n",
    "  I am going to define a couple of functions that help with testing. Note I am using .5 as my descriminator. We know that the value `z` is produced by the sigmoid function and that function has a range of `0` to `1`. I am treating the sigmoid output as a probability. In a fancier version of the 2 functions below, I could take the descriminator in as a parameter. Here's a thought. What if I changed it to `.7`? In terms of our 4 cases, I am saying that false positives are costly to me so I want my 1 or yes predictions to have probability above 70%. I suppose I could do the same with random forest: to get a 1 result there has to be a super-majority of trees voting 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WeGrfROGHNCB"
   },
   "outputs": [],
   "source": [
    "def ann_predictor(sample, weights, bias):\n",
    "  \n",
    "  s2 = np.expand_dims(sample, axis=1)\n",
    "  XW = np.multiply(s2, weights)\n",
    "  XW_sum = np.sum(XW, axis=0)\n",
    "  raw_output = XW_sum + bias\n",
    "  z = sigmoid(raw_output)\n",
    "\n",
    "  return 1 if z > .5 else 0  #.5 should probably be a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fM9xvG9fHPIE"
   },
   "outputs": [],
   "source": [
    "def ann_tester(samples, labels, weights, bias):\n",
    "  weights = np.array(weights)\n",
    "  bias = np.array(bias)\n",
    "  \n",
    "  predictions = [ann_predictor(s, weights, bias) for s in samples]\n",
    "  zipped = list(zip(predictions, labels))\n",
    "  \n",
    "  return (zipped.count((1,1)) + zipped.count((0,0)))/len(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A---MnTwIE3M",
    "outputId": "81ac798e-5d1d-422c-c81a-c9cc533e79d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just copying and pasting weights and bias from above\n",
    "\n",
    "ann_tester(feature_set, labels, [[ 0.12526813], [10.03119447], [-0.15533876]], [-4.92274282])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hsjs6qT0JlNB"
   },
   "source": [
    "<h2>Yikes, we are prefect</h2>\n",
    "\n",
    "Don't get too excited. This is for only 5 samples. We wil come back to reality in the assignment notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5KvmUY17XuX"
   },
   "source": [
    "<h2>Recognize something both good and bad here</h2>\n",
    "\n",
    "Our entire model consists of the 4 weights above. That's it. Those 4 weights. Seems almost like magic. We don't have to store some complicated path structure. Just a set of weights. This is the beauty of it but also the worrisome part. What the heck do those weights mean? With a decision tree, we had an intuitive sense of its underlying structure. After 200K iterations I get this for weight 1: `0.12526813`. What does that mean? This is a huge question, both at the technical level and the societal level. How do I know what the model knows? Is there a way for it to explain itself? If not, how can I detect bias embedded in those weights? Is there any way for me, as a human, to change those weights in some principled way? Unless I know what they represent, I don't see a way.\n",
    "<p>\n",
    "  FYI: I just saw a blurb for a talk in our Philosophy Department. It focused on the ethics of neural nets and deep learning. Do we as humans need to know what our models know? Should models be explainable before they are put into use in society? Kind of interesting questions to me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ceOJcSWxEQJ-"
   },
   "source": [
    "<hr>\n",
    "<h1>Write it out</h1>\n",
    "<div class=h1_cell>\n",
    "\n",
    "I am going to change our library naming conventions. Since we are moving into the area of deep learning, I am going to keep a separate library for our new functions. I call it `library_w19_deep_1.py`. You can just fill it with the functions from this notebook.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ann_intro_w19.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
