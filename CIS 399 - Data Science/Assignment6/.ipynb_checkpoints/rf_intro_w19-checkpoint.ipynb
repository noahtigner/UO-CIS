{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i7l7ROhf6dFN"
   },
   "source": [
    "<h1>\n",
    "<center>\n",
    "Module 6: Random Forests - another approach to Bias-Variance\n",
    "</center>\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "In this module we will continue to look at means of tackling the Bias-Variance problem. We will focus on the Variance problem of overfitting. We will see a new concept called *ensemble* learning. I liken it to crowd-sourcing. Instead of relying on just one expert, let's round up a collection (AKA an ensemble) of experts. We can let them each, individually, come up with a prediction. Then we can take a vote and use the winning prediction.\n",
    "<p>\n",
    "The technique we will look at is called *Random Forests*. It is a special method falling under the more general heading of *bagging*. We will crowd-source a forest of trees to get their predictions and then take majority vote. Where, you ask, does this forest of trees come from? We build them following relatively straightforward steps. So to summarize, we first build our forest of decision trees. Then when we want to do predictions for real, we give each tree a vote and majority wins. Cool.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f9YvgXb76dFO"
   },
   "source": [
    "<h2>\n",
    "Jargon alerts\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Random forests have jargon that goes with them. I'll alert you to where jargony terms show up.\n",
    "<p>\n",
    "Jargon alert: *Random Forest* is jargon :) And so is *bagging* and *ensemble*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FQsSj4Es6dFQ",
    "outputId": "9c11e1ae-adc4-43fb-a9ab-60026d2b573f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "colab_type": "code",
    "id": "9liFynJ27IeB",
    "outputId": "007e9980-7e97-46f5-9c8d-5d0911adfc34"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>...</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>age_Child</th>\n",
       "      <th>age_Adult</th>\n",
       "      <th>age_Senior</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ok_child</th>\n",
       "      <th>pclass_1</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>...</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "\n",
       "      Sex   Age  SibSp  Parch     Ticket     Fare Cabin    ...    age_bin  \\\n",
       "0    male  22.0      1      0  A/5 21171   7.2500   NaN    ...      Child   \n",
       "1  female  38.0      1      0   PC 17599  71.2833   C85    ...      Adult   \n",
       "\n",
       "   age_Child  age_Adult  age_Senior  sex_female  sex_male  ok_child pclass_1  \\\n",
       "0          1          0           0           0         1         0        0   \n",
       "1          0          1           0           1         0         0        1   \n",
       "\n",
       "   pclass_2  pclass_3  \n",
       "0         0         1  \n",
       "1         0         0  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/content/gdrive/My Drive/class_tables/titanic_wrangled_week2.csv', 'r') as f:\n",
    "  titanic_table = pd.read_csv(f)\n",
    "\n",
    "titanic_table.head(2)  #make sure it looks ok - we see the results of our week 2 wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yr6MpU4P6dFV"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ftdZ_rDr6dFd"
   },
   "outputs": [],
   "source": [
    "!rm library_w19_week5b.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "CbGss14S74GH",
    "outputId": "b5b07e52-2844-470b-a629-0189ee1f5f08"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-b9f2307d-fece-4573-868f-5d0852eb3c37\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-b9f2307d-fece-4573-868f-5d0852eb3c37\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving library_w19_week5b.py to library_w19_week5b.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'library_w19_week5b.py': b'import pandas as pd\\nimport numpy as np\\nfrom functools import reduce\\n\\ndef predictor_case(row, pred, target):\\n\\tcase_dict = {(0,0): \\'true_negative\\', (1,1): \\'true_positive\\', (0,1): \\'false_negative\\', (1,0): \\'false_positive\\'}\\n\\tactual = row[target]\\n\\tprediction = row[pred]\\n\\tcase = case_dict[(prediction, actual)]\\n\\treturn case\\n\\ndef accuracy(cases):\\n    tp = cases[\\'true_positive\\'] if \\'true_positive\\' in cases else 0\\n    tn = cases[\\'true_negative\\'] if \\'true_negative\\' in cases else 0\\n    fp = cases[\\'false_positive\\'] if \\'false_positive\\' in cases else 0\\n    fn = cases[\\'false_negative\\'] if \\'false_negative\\' in cases else 0\\n\\n    result = (tp + tn)/(tp+tn+fp+fn) if (tp+tn+fp+fn) != 0 else 0\\n    return result\\n\\ndef f1(cases):\\n    #the heart of the matrix\\n    tp = cases[\\'true_positive\\'] if \\'true_positive\\' in cases else 0\\n    tn = cases[\\'true_negative\\'] if \\'true_negative\\' in cases else 0\\n    fp = cases[\\'false_positive\\'] if \\'false_positive\\' in cases else 0\\n    fn = cases[\\'false_negative\\'] if \\'false_negative\\' in cases else 0\\n    \\n    #other measures we can derive\\n    recall = tp/(tp+fn)  if (tp+fn) != 0 else 0 # positive correct divided by total positive in the table\\n    precision = tp/(tp+fp) if (tp+fp) != 0 else 0 # positive correct divided by all positive predictions made\\n    \\n    #now for the one we want\\n    recall_div = 1/recall if recall != 0 else 0\\n    precision_div = 1/precision if precision != 0 else 0\\n    f1 = 2/(recall_div + precision_div) if (recall_div + precision_div) != 0 else 0\\n    \\n    return f1\\n\\ndef informedness(cases):\\n    tp = cases[\\'true_positive\\'] if \\'true_positive\\' in cases else 0\\n    tn = cases[\\'true_negative\\'] if \\'true_negative\\' in cases else 0\\n    fp = cases[\\'false_positive\\'] if \\'false_positive\\' in cases else 0\\n    fn = cases[\\'false_negative\\'] if \\'false_negative\\' in cases else 0\\n\\n    recall = tp/(tp+fn)  if (tp+fn) != 0 else 0 # positive correct divided by total positive in the table\\n    specificty = tn/(tn+fp) if (tn+fp) != 0 else 0# negative correct divided by total negative in the table\\n    J = (recall + specificty) - 1\\n    return J\\n\\n#starting week 3\\n\\ndef probabilities(counts):\\n    count_0 = 0 if 0 not in counts else counts[0]  #could have no 0 values\\n    count_1 = 0 if 1 not in counts else counts[1]\\n    total = count_0 + count_1\\n    probs = (0,0) if total == 0 else (count_0/total, count_1/total)  #build 2-tuple\\n    return probs\\n\\ndef gini(counts):\\n    (p0,p1) = probabilities(counts)\\n    sum_probs = p0**2 + p1**2\\n    gini = 1 - sum_probs\\n    return gini\\n\\ndef gig(starting_table, split_column, target_column):\\n    \\n    #split into two branches, i.e., two sub-tables\\n    true_table = starting_table.loc[starting_table[split_column] == 1]\\n    false_table = starting_table.loc[starting_table[split_column] == 0]\\n    \\n    #Now see how the target column is divided up in each sub-table (and the starting table)\\n    true_counts = true_table[target_column].value_counts()  # Note using true_table and not starting_table\\n    false_counts = false_table[target_column].value_counts()  # Note using false_table and not starting_table\\n    starting_counts = starting_table[target_column].value_counts() \\n    \\n    #compute the gini impurity for the 3 tables\\n    starting_gini = gini(starting_counts)\\n    true_gini = gini(true_counts)\\n    false_gini = gini(false_counts)\\n\\n    #compute the weights\\n    starting_size = len(starting_table.index)\\n    true_weight = 0.0 if starting_size == 0 else len(true_table.index)/starting_size\\n    false_weight = 0.0 if starting_size == 0 else len(false_table.index)/starting_size\\n    \\n    #wrap it up and put on a bow\\n    gig = starting_gini - (true_weight * true_gini + false_weight * false_gini)\\n    \\n    return gig\\n\\n\\'\\'\\'\\ndef entropy(counts):\\n    (p0, p1) = probabilities(counts)\\n    term1 = -p0*math.log(p0,2) if p0 > 0 else 0\\n    term2 = -p1*math.log(p1,2) if p1 > 0 else 0\\n    entropy = term1 + term2\\n    return entropy\\n\\ndef IGain(starting_table, split_column, target_column):\\n    \\n    #split into two branches, i.e., two sub-tables\\n    true_table = starting_table.loc[starting_table[split_column] == 1]\\n    false_table = starting_table.loc[starting_table[split_column] == 0]\\n    \\n    #Now see how the target column is divided up in each sub-table (and the starting table)\\n    true_counts = true_table[target_column].value_counts()\\n    false_counts = false_table[target_column].value_counts()  # Note using true_table and not titanic_table\\n    starting_counts = starting_table[target_column].value_counts() \\n    \\n    #compute the entropy for the 3 tables\\n    starting_e = entropy(starting_counts)\\n    true_e = entropy(true_counts)\\n    false_e = entropy(false_counts)\\n\\n    #compute the weights\\n    starting_size = len(starting_table.index)\\n    true_weight = 0.0 if starting_size == 0 else 1.0*len(true_table.index)/starting_size\\n    false_weight = 0.0 if starting_size == 0 else 1.0*len(false_table.index)/starting_size\\n    \\n    #wrap it up and put on a bow\\n    infogain = starting_e - (true_weight * true_e + false_weight * false_e)\\n    \\n    return infogain\\n\\'\\'\\'\\n\\n#week 4\\n\\ndef build_pred(column, branch):\\n    return lambda row: row[column] == branch\\n\\ndef find_best_splitter(table, choice_list, target):\\n  \\n    assert (len(table)>0),\"Cannot split empty table\"\\n    assert (target in table),\"Target must be column in table\"\\n    \\n    gig_scores = map(lambda col: (col, gig(table, col, target)), choice_list)  #compute tuple (col, gig) for each column\\n    gig_sorted = sorted(gig_scores, key=lambda item: item[1], reverse=True)  # sort on gig\\n    return gig_sorted\\n\\nfrom functools import reduce\\n\\ndef generate_table(table, conjunction):\\n  \\n    assert (len(table)>0),\"Cannot generate from empty table\"\\n\\n    sub_table = reduce(lambda subtable, pair: subtable.loc[pair[1]], conjunction, table)\\n    return sub_table\\n\\ndef compute_prediction(table, target):\\n  \\n    assert (len(table)>0),\"Cannot predict from empty table\"\\n    assert (target in table),\"Target must be column in table\"\\n    \\n    counts = table[target].value_counts()  # counts looks like {0: v1, 1: v2}\\n\\n    if 0 not in counts:\\n        prediction = 1\\n    elif 1 not in counts:\\n        prediction = 0\\n    elif counts[1] > counts[0]:  # ties go to 0 (negative)\\n        prediction = 1\\n    else:\\n        prediction = 0\\n\\n    return prediction\\n\\ndef build_tree_iter(table, choices, target, hypers={} ):\\n\\n    assert (len(choices)>0),\"Must have at least one column in choices\"\\n    assert (target in table), \"Target column not in table\"\\n    assert (len(table) > 1), \"Table must have more than 1 row\"\\n\\n    hyper_keys = [*hypers]\\n    target_set = set([\\'max-depth\\',\\'gig-cutoff\\'])\\n    diff_set = set(hyper_keys) - target_set\\n    if diff_set: print(\\'WARNING: unrecognized hyper parameters \\' + str(diff_set))\\n    \\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(4, len(choices))\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\n    \\n    def iterative_build(k):\\n        columns_sorted = find_best_splitter(table, choices, target)\\n        (best_column, gig_value) = columns_sorted[0]\\n        \\n        #Note I add _1 or _0 to make it more readable for debugging\\n        current_paths = [{\\'conjunction\\': [(best_column+\\'_1\\', build_pred(best_column, 1))],\\n                          \\'prediction\\': None,\\n                          \\'gig_score\\': gig_value},\\n                         {\\'conjunction\\': [(best_column+\\'_0\\', build_pred(best_column, 0))],\\n                          \\'prediction\\': None,\\n                          \\'gig_score\\': gig_value}\\n                        ]\\n        k -= 1  # we just built a level as seed so subtract 1 from k\\n        tree_paths = []  # add completed paths here\\n        \\n        while k>0:\\n            new_paths = []\\n            for path in current_paths:\\n                old_conjunction = path[\\'conjunction\\']  # a list of (name, lambda)\\n                before_table = generate_table(table, old_conjunction)  #the subtable the current conjunct leads to\\n                columns_sorted = find_best_splitter(before_table, choices, target)\\n                (best_column, gig_value) = columns_sorted[0]\\n                if gig_value > gig_cutoff:\\n                    new_path_1 = {\\'conjunction\\': old_conjunction + [(best_column+\\'_1\\', build_pred(best_column, 1))],\\n                                \\'prediction\\': None,\\n                                 \\'gig_score\\': gig_value}\\n                    new_paths.append( new_path_1 ) #true\\n                    new_path_0 = {\\'conjunction\\': old_conjunction + [(best_column+\\'_0\\', build_pred(best_column, 0))],\\n                                \\'prediction\\': None,\\n                                 \\'gig_score\\': gig_value}\\n                    new_paths.append( new_path_0 ) #false\\n                else:\\n                    #not worth splitting so complete the path with a prediction\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\n                    tree_paths.append(path)\\n            #end for loop\\n            \\n            current_paths = new_paths\\n            if current_paths != []:\\n                k -= 1\\n            else:\\n                break  # nothing left to extend so have copied all paths to tree_paths\\n        #end while loop\\n\\n        #Generate predictions for all paths that have None\\n        for path in current_paths:\\n            conjunction = path[\\'conjunction\\']\\n            before_table = generate_table(table, conjunction)\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\n            tree_paths.append(path)\\n        return tree_paths\\n\\n    return {\\'paths\\': iterative_build(k), \\'weight\\': None}\\n\\ndef tree_predictor(row, tree):\\n  \\n    assert (len(tree[\\'paths\\']) > 0), \"Tree must have at least one path\"\\n    \\n    #go through each path, one by one (could use a map instead of for loop?)\\n    for path in tree[\\'paths\\']:\\n        conjuncts = path[\\'conjunction\\']\\n        result = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\n        if all(result):\\n            return path[\\'prediction\\']\\n    raise LookupError(\\'No true paths found for row: \\' + str(row))\\n\\n#============== Week 4 version b\\n\\ndef path_id(row, tree):\\n  \\n    assert (len(tree[\\'paths\\']) > 0), \"Tree must have at least one path\"\\n    \\n    #go through each path, one by one (could use a map instead of for loop?)\\n    for i, path in enumerate( tree[\\'paths\\']):\\n        conjuncts = path[\\'conjunction\\']\\n        result = map(lambda tup: tup[1](row), conjuncts)  # potential to be parallelized\\n        if all(result):\\n            return i\\n    raise LookupError(\\'No true paths found for row: \\' + str(row))\\n\\ndef reorder_paths(table, tree):\\n  \\n    new_paths = []\\n    paths = tree[\\'paths\\']\\n\\n    tempcounts = table.apply(lambda row: path_id(row, tree), axis=1)\\n    valcounts= tempcounts.value_counts()\\n    dictcounts = dict(valcounts)\\n    listcounts = list(dictcounts.items())\\n    sortedcounts = sorted(listcounts, key=lambda x: x[1], reverse=True)\\n    print(sortedcounts)\\n    \\n    for tup in sortedcounts:\\n        new_paths.append(paths[tup[0]])\\n        \\n    return new_paths\\n\\n#============== Week 5\\nfrom types import SimpleNamespace\\n\\ndef produce_scores(table, tree, target):\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: tree_predictor(row, tree), axis=1)\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\n    vc = cases.value_counts()\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\n\\ndef compute_training(slices, left_out):\\n    training_slices = []\\n    for i,slice in enumerate(slices):\\n        if i == left_out:\\n            continue\\n        training_slices.append(slices[i])\\n    return pd.concat(training_slices)  # note we are returning a table (DataFrame)\\n\\ndef k_fold(table, k, target, hypers, candidate_columns):\\n\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\n    \\n    total_len = len(table.index)\\n    slice_size = int(total_len/(1.0*k))\\n\\n    #generate the slices\\n    slices = []\\n    for i in range(k-1):\\n        a_slice =  table[i*slice_size:(i+1)*slice_size]\\n        slices.append( a_slice )\\n    slices.append( table[(k-1)*slice_size:] )  # whatever is left\\n    \\n    #do cross validation\\n    all_scores = []\\n    for i in range(k):\\n        test_table = slices[i]\\n        train_table = compute_training(slices, i)\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\n        result_row = {\\'name\\':\\'fold_\\'+str(i), \\'accuracy\\':scores[0], \\'f1\\':scores[1], \\'informedness\\':scores[2]}\\n        k_fold_results_table = k_fold_results_table.append(result_row,ignore_index=True)\\n        all_scores.append(scores)\\n        \\n    #compute the average\\n    average = list(reduce(np.add, all_scores[1:], all_scores[0])/k)\\n    result_row = {\\'name\\':\\'average\\', \\'accuracy\\':average[0], \\'f1\\':average[1], \\'informedness\\':average[2]}\\n    k_fold_results_table = k_fold_results_table.append(result_row,ignore_index=True)\\n    \\n    return k_fold_results_table\\n\\n########  Added from assignment notebook\\n\\n\\n\\ndef k_fold_random(table, k, target, hypers, candidate_columns):\\n\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\n    \\n    total_len = len(table.index)\\n    slice_size = int(total_len/(1.0*k))\\n\\n    #generate the slices\\n    \\n    #your new code here\\n    sub_table = table\\n    slices = []\\n    for i in range(k-1):\\n        new_slice = sub_table.sample(n=slice_size)\\n        sub_table = sub_table.loc[~sub_table.index.isin(new_slice.index)]\\n        slices.append( new_slice )\\n    slices.append( sub_table )\\n    verify_unique(slices)\\n    \\n    #do cross validation\\n    all_scores = []\\n    for i in range(k):\\n        test_table = slices[i]\\n        train_table = compute_training(slices, i)\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\n        result_row = {\\'name\\':\\'fold_\\'+str(i), \\'accuracy\\':scores[0], \\'f1\\':scores[1], \\'informedness\\':scores[2]}\\n        k_fold_results_table = k_fold_results_table.append(result_row,ignore_index=True)\\n        all_scores.append(scores)\\n        \\n    #compute the average\\n    average = list(reduce(np.add, all_scores[1:], all_scores[0])/k)\\n    result_row = {\\'name\\':\\'average\\', \\'accuracy\\':average[0], \\'f1\\':average[1], \\'informedness\\':average[2]}\\n    k_fold_results_table = k_fold_results_table.append(result_row,ignore_index=True)\\n    \\n    return k_fold_results_table\\n\\n#Determine if slices are mutually exclusive\\ndef verify_unique(slices):\\n    print((\\'total length all slices\\', sum([len(s) for s in slices])))\\n    for i, a_slice in enumerate(slices[:-1]):\\n        a_set = set(a_slice.index)\\n        for j, b_slice in enumerate(slices[i+1:]):\\n            b_set = set(b_slice.index)\\n            int_set = a_set.intersection(b_set)  # should be empty set as result\\n            print((i,j+i+1,int_set))\\n    return None\\n'}"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "NdT3Dk5m6dFi",
    "outputId": "fdd4a827-c53a-48d0-f6b7-f409dfade9e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t build_pred\t build_tree_iter\t compute_prediction\t compute_training\t f1\t find_best_splitter\t generate_table\t gig\t \n",
      "gini\t informedness\t k_fold\t k_fold_random\t path_id\t predictor_case\t probabilities\t produce_scores\t reorder_paths\t \n",
      "tree_predictor\t verify_unique\t \n"
     ]
    }
   ],
   "source": [
    "from library_w19_week5b import *\n",
    "\n",
    "%who function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "colab_type": "code",
    "id": "oGmEXIIU6dFm",
    "outputId": "c488e482-b117-4717-bd9c-abb86e2f7ad4",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>no_age</th>\n",
       "      <th>filled_age</th>\n",
       "      <th>emb_C</th>\n",
       "      <th>emb_Q</th>\n",
       "      <th>emb_S</th>\n",
       "      <th>emb_nan</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>age_Child</th>\n",
       "      <th>age_Adult</th>\n",
       "      <th>age_Senior</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ok_child</th>\n",
       "      <th>pclass_1</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                     Name   Sex   Age  SibSp  Parch  \\\n",
       "0         0       3  Braund, Mr. Owen Harris  male  22.0      1      0   \n",
       "\n",
       "      Ticket  Fare Cabin Embarked  no_age  filled_age  emb_C  emb_Q  emb_S  \\\n",
       "0  A/5 21171  7.25   NaN        S       0        22.0      0      0      1   \n",
       "\n",
       "   emb_nan age_bin  age_Child  age_Adult  age_Senior  sex_female  sex_male  \\\n",
       "0        0   Child          1          0           0           0         1   \n",
       "\n",
       "   ok_child  pclass_1  pclass_2  pclass_3  \n",
       "0         0         0         0         1  "
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_table.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bH3w96Ll6dFs"
   },
   "source": [
    "<h2>\n",
    "A forest starts with some trees\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Let's build a forest of two trees to get started. Once we see how to do that, we can scale it up to N trees.\n",
    "<p>\n",
    "Our approach will be to do random selections of both the rows (axis=0) and columns (axis=1) as we build the tree.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAvAi-8n6dFt"
   },
   "source": [
    "<h2>\n",
    "Step 1. Generate the training data for the first tree (and don't lose the left-out data)\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "We will take a slice from the entire table to use as training. This may sound familiar: we did something similar when doing K-folding. The big difference here is that we will take random rows *with replacement*. This means the same row can appear more than once in our slice. With K-Folding, we did not let this happen. And BTW, the size of the slice is the size of the original table, e.g. 891 rows in slice!\n",
    "<p>\n",
    "We don't want to lose track of the rows we did not use. They will become important later.\n",
    "<p>\n",
    "Jargon alert: selecting a random sample of rows for training (with replacement) is called *bootstrapping* or *bagging*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zlb-ixpS6dFu"
   },
   "source": [
    "<h2>\n",
    "Random but predictable\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "It is not easy debugging random algorithms. You want to use the same random numbers as you make changes and try things again. We will run into 2 types of random numbers in this module: ones generated from Python's `random` package; ones generated by `pandas` (which in turn uses `numpy`). Sorry, but will need to seed them both if we want consistent results.\n",
    "  <p>\n",
    "    As reminder, once we seed a generator with a constant (like 1000 below), we will get the same sequence of random numbers generated.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9hcqQTWi6dFz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "rng = np.random.RandomState(42)  #Will pass as arg to pandas sample method\n",
    "random.seed(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VtDKwQYi6dF3"
   },
   "source": [
    "<h2>\n",
    "Let's bootstrap!\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "We need a table that is same size as Titanic table (891 rows). We will select the rows in the Titanic Table randomly. We will allow replacement: the same row can be selected mulitple times. What is very cool is that Pandas gives us a method, `sample`, that does exactly what we want. Pretty nice of them.\n",
    "<p>\n",
    "As you can see below, I am setting the fraction of the table I want to 100%. And I am using my new_seed function to give me the random seed.\n",
    "<p>\n",
    "Once I have my new table, I am going to reindex it. This will create a new column `index` that has the row numbers from the original Titanic table. I'll want those later. Check it out.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "colab_type": "code",
    "id": "g-mBabIC6dF5",
    "outputId": "a776cfde-688f-4201-bd1a-78ce71d86d1a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>no_age</th>\n",
       "      <th>filled_age</th>\n",
       "      <th>emb_C</th>\n",
       "      <th>emb_Q</th>\n",
       "      <th>emb_S</th>\n",
       "      <th>emb_nan</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>age_Child</th>\n",
       "      <th>age_Adult</th>\n",
       "      <th>age_Senior</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ok_child</th>\n",
       "      <th>pclass_1</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>White, Mr. Richard Frasar</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35281</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>D26</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>435</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carter, Miss. Lucile Polk</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113760</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hansen, Mr. Claus Peter</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>350026</td>\n",
       "      <td>14.1083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cairns, Mr. Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113798</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Salkjelsvik, Miss. Anna Kristine</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343120</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Survived  Pclass                              Name     Sex   Age  \\\n",
       "0    102         0       1         White, Mr. Richard Frasar    male  21.0   \n",
       "1    435         1       1         Carter, Miss. Lucile Polk  female  14.0   \n",
       "2    860         0       3           Hansen, Mr. Claus Peter    male  41.0   \n",
       "3    270         0       1             Cairns, Mr. Alexander    male   NaN   \n",
       "4    106         1       3  Salkjelsvik, Miss. Anna Kristine  female  21.0   \n",
       "\n",
       "   SibSp  Parch  Ticket      Fare    Cabin Embarked  no_age  filled_age  \\\n",
       "0      0      1   35281   77.2875      D26        S       0   21.000000   \n",
       "1      1      2  113760  120.0000  B96 B98        S       0   14.000000   \n",
       "2      2      0  350026   14.1083      NaN        S       0   41.000000   \n",
       "3      0      0  113798   31.0000      NaN        S       1   29.699118   \n",
       "4      0      0  343120    7.6500      NaN        S       0   21.000000   \n",
       "\n",
       "   emb_C  emb_Q  emb_S  emb_nan age_bin  age_Child  age_Adult  age_Senior  \\\n",
       "0      0      0      1        0   Child          1          0           0   \n",
       "1      0      0      1        0   Child          1          0           0   \n",
       "2      0      0      1        0   Adult          0          1           0   \n",
       "3      0      0      1        0   Adult          0          1           0   \n",
       "4      0      0      1        0   Child          1          0           0   \n",
       "\n",
       "   sex_female  sex_male  ok_child  pclass_1  pclass_2  pclass_3  \n",
       "0           0         1         0         1         0         0  \n",
       "1           1         0         0         1         0         0  \n",
       "2           0         1         0         0         0         1  \n",
       "3           0         1         0         1         0         0  \n",
       "4           1         0         0         0         0         1  "
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1 = titanic_table.sample(frac=1.0, replace=True, random_state=rng)  # Easy peasy - thanks pandas!\n",
    "train1 = train1.reset_index()\n",
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "ZmcM_k-26dF-",
    "outputId": "810b7526-f506-49d5-a178-6b42611f5568"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     583\n",
       "False    308\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just for giggles, get a count of how many rows duplicated in train1\n",
    "train1.duplicated(['index'], keep=False).value_counts()  #583 rows are duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7z_t86hD6dGD"
   },
   "source": [
    "<h2>\n",
    "We will need the leftovers eventually\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Since we have duplicates in `train1`, there must be some rows from the Titanic table that were not included in train1. I would like to know which rows were left out of train1.\n",
    "<p>\n",
    "Jargon alert: the rows that are left out are called *out of bag*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "id": "Vuxmytg56dGE",
    "outputId": "b6f350d5-fb94-41c1-8629-a88ce49cd385"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>no_age</th>\n",
       "      <th>filled_age</th>\n",
       "      <th>emb_C</th>\n",
       "      <th>emb_Q</th>\n",
       "      <th>emb_S</th>\n",
       "      <th>emb_nan</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>age_Child</th>\n",
       "      <th>age_Adult</th>\n",
       "      <th>age_Senior</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ok_child</th>\n",
       "      <th>pclass_1</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Survived  Pclass                                          Name  \\\n",
       "0      2         1       3                        Heikkinen, Miss. Laina   \n",
       "1      3         1       1  Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "2      5         0       3                              Moran, Mr. James   \n",
       "3      6         0       1                       McCarthy, Mr. Timothy J   \n",
       "4     10         1       3               Sandstrom, Miss. Marguerite Rut   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \\\n",
       "0  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "1  female  35.0      1      0            113803  53.1000  C123        S   \n",
       "2    male   NaN      0      0            330877   8.4583   NaN        Q   \n",
       "3    male  54.0      0      0             17463  51.8625   E46        S   \n",
       "4  female   4.0      1      1           PP 9549  16.7000    G6        S   \n",
       "\n",
       "   no_age  filled_age  emb_C  emb_Q  emb_S  emb_nan age_bin  age_Child  \\\n",
       "0       0   26.000000      0      0      1        0   Child          1   \n",
       "1       0   35.000000      0      0      1        0   Adult          0   \n",
       "2       1   29.699118      0      1      0        0   Adult          0   \n",
       "3       0   54.000000      0      0      1        0  Senior          0   \n",
       "4       0    4.000000      0      0      1        0   Child          1   \n",
       "\n",
       "   age_Adult  age_Senior  sex_female  sex_male  ok_child  pclass_1  pclass_2  \\\n",
       "0          0           0           1         0         0         0         0   \n",
       "1          1           0           1         0         0         1         0   \n",
       "2          1           0           0         1         0         0         0   \n",
       "3          0           1           0         1         0         1         0   \n",
       "4          0           0           1         0         1         0         0   \n",
       "\n",
       "   pclass_3  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_out1 = titanic_table.loc[~titanic_table.index.isin(train1['index'])]  #what rows in titanic_table are not in train1?\n",
    "left_out1 = left_out1.reset_index()  #builds a new index column that comes from original titanic table\n",
    "left_out1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "ng4lFg_h6dGL",
    "outputId": "70654d10-17dc-4cb4-cd78-61f15146b51d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    342\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We expect no True values with this - should have unique rows\n",
    "left_out1.duplicated(['index'], keep=False).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCBXBssz6dGS"
   },
   "source": [
    "\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "We don't really need the entire left_out1 table. All we need are the values in the `index` column. We can use those to access rows in the Titanic table later. So will pull those indices out and put in a list.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7iCt6xml6dGT",
    "outputId": "0b047719-e434-4f17-b891-57bfb7b09e7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 5, 6, 10]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_out_indices1 = left_out1['index'].tolist()\n",
    "left_out_indices1[:5]  # should be same as what see in head() above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cJTeU5GQ6dGZ"
   },
   "source": [
    "<h2>\n",
    "Let's congratulate ourselves\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "We have completed the first big step in building our two-tree forest. We have generated a bootstrapped table, `train1`, that we can use for training our first tree.\n",
    "<p>\n",
    "Next step is to do the training.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V309L86j6dGa"
   },
   "outputs": [],
   "source": [
    "splitter_columns = [\n",
    " 'emb_C',\n",
    " 'emb_Q',\n",
    " 'emb_S',\n",
    " 'emb_nan',\n",
    " 'age_Child',\n",
    " 'age_Adult',\n",
    " 'age_Senior',\n",
    " 'no_age',\n",
    " 'ok_child',\n",
    " 'sex_female',\n",
    " 'pclass_1',\n",
    " 'pclass_2',\n",
    " 'pclass_3'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFxyy1e-6dGe"
   },
   "source": [
    "<h2>\n",
    "Training is a bit different\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Normally we would use all the columns in `splitter_columns` to build our tree. We are going to do something different. For each node in the tree we are building, I will only choose the best splitter from a subset of `splitter_columns`. What I choose to be in the subset will be random. The size of the subset, which I will call `m`, is a hyper-parameter that you can set. A rule of thumb is to set `m` to (at max) the square root of the length of `splitter_columns`. That length is `14` so I will use a value of `3` for `m`.\n",
    "<p>\n",
    "Jargon alert: choosing a random subset of columns/features is called *attribute bagging* which is a type of *random subspace sampling*.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gGoJOWxl6dGf",
    "outputId": "aef285bd-dc89-49cc-a483-fa6541b35fe1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = int(len(splitter_columns)**.5)  # default is square root of total number of splitters rounded down\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "90Nhpp7SfbC7"
   },
   "source": [
    "<h2>There are a lot of variations</h2>\n",
    "\n",
    "Choosing what subset of columns to consider at each node has been studied by many. The Wikipedia page on random forests is one place to start. To give you an idea, some have argued that the selection of the node splitter should be completely random (!) This means omitting computing gig scores and just choosing randomly among all the columns. Others have used a variation on that. Compute the gig score for all columns and order them. Select randomly from the top 5.\n",
    "<p>\n",
    "  As a reminder, this is all in the service of trying to avoid overfitting. The very general idea is that if you have a lot of trees with randomness thrown in, then it is a bit like crowd-sourcing. Maybe each tree does really well for certain columns. When you put them together, you get a whole that is better than parts.\n",
    "  <p>\n",
    "    Random forests have proven to be the go to method in the kinds of problems you will see on the kaggle web-site. They still are very popular, although deep learning has taken some of the spotlight off of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F65ZCuen6dGj"
   },
   "source": [
    "<h2>\n",
    "The Fickas variation\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Normally we would take a sample of m *with* replacement. That means, for m = 3, we could potentially have the result be `['no_age', 'no_age', 'no_age']`. In essence, since duplicates can be removed, this adds randomness to m. It really means that m can vary between 1 (all the same) and 3 (all different). If we have only 1 splitter in our candidate set, no need to run gig. It is basically the same as choosing a random column as discussed above.\n",
    "<p>\n",
    "For efficiency, I am going to sample *without* replacement. So I am not allowing duplicates in my resulting list. The price I pay is that I lose a bit of randomness.\n",
    "  <p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4qmgWqFT6dGl",
    "outputId": "9a172537-4587-4e92-9164-54d8b676d769"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no_age', 'emb_C', 'pclass_3']"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use random library sample method to get sample without replacement\n",
    "rcols = random.sample(splitter_columns, m)\n",
    "rcols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kZkGckgr6dGp"
   },
   "source": [
    "\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "We now have the candidate splitters (3 of them) for the root node of tree. We can use our library functions from past modules to do the rest.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "84Jy-cX76dGq",
    "outputId": "8094cb87-80e7-4a0f-ae78-50dc8cc689e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pclass_3', 0.03845127329425646)\n"
     ]
    }
   ],
   "source": [
    "columns_sorted = find_best_splitter(train1, rcols, 'Survived')  #notice using train1 and rcols\n",
    "(best_column, gig_value) = columns_sorted[0]\n",
    "print((best_column, gig_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OEq5AN446dG1"
   },
   "source": [
    "\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Now we can build the 2 starting paths emanating from the root node.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "ojV93QEg6dG2",
    "outputId": "5d0668f8-262a-4729-cd69-be227aff8bc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'conjunction': [('pclass_3_1',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.03845127329425646,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('pclass_3_0',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.03845127329425646,\n",
       "  'prediction': None}]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "current_paths = [{'conjunction': [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                  'prediction': None,\n",
    "                  'gig_score': gig_value},\n",
    "                 {'conjunction': [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                  'prediction': None,\n",
    "                  'gig_score': gig_value}]\n",
    "                 \n",
    "current_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_Vg2Hl06dG6"
   },
   "source": [
    "<div class=h1_cell>\n",
    "I'll follow another round of splitting, i.e., grow the tree to level 2. I am copying and pasting code from `build_tree_iter` here. But I am making some changes, which I'll mark with `new` comments.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "I1iNUGnp6dG7",
    "outputId": "a05c86e8-0172-4d7c-8740-2e2a2cf6e767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pclass_3', 'age_Child', 'emb_S']\n",
      "['sex_female', 'pclass_1', 'emb_S']\n"
     ]
    }
   ],
   "source": [
    "table = train1\n",
    "\n",
    "tree_paths = []\n",
    "new_paths = []\n",
    "gig_cutoff = 0.0\n",
    "\n",
    "for path in current_paths:\n",
    "    conjunct = path['conjunction']\n",
    "    before_table = generate_table(table, conjunct)\n",
    "    rcols = random.sample(splitter_columns, m)       #new - chooses random subset for each new node\n",
    "    print(rcols)\n",
    "    columns_sorted = find_best_splitter(before_table, rcols, 'Survived')  #new - using rcols\n",
    "    (best_column, gig_value) = columns_sorted[0]\n",
    "    if gig_value > gig_cutoff:\n",
    "        new_path_1 = {'conjunction': conjunct + [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                    'prediction': None,\n",
    "                     'gig_score': gig_value}\n",
    "        new_paths.append( new_path_1 ) #true\n",
    "        new_path_0 = {'conjunction': conjunct + [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                    'prediction': None,\n",
    "                     'gig_score': gig_value\n",
    "                     }\n",
    "        new_paths.append( new_path_0 ) #false\n",
    "    else:\n",
    "        #not worth splitting so complete the path with a prediction\n",
    "        path['prediction'] = compute_prediction(before_table, 'Survived')\n",
    "        tree_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "-Lm_FhsY6dG-",
    "outputId": "6d9f15b0-c9e5-4fcc-a99f-5a92a49d8862"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'conjunction': [('pclass_3_1',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('emb_S_1', <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.021049896049896044,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('pclass_3_1',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('emb_S_0', <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.021049896049896044,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('pclass_3_0',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('sex_female_1',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.2601615877054527,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('pclass_3_0',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('sex_female_0',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.2601615877054527,\n",
       "  'prediction': None}]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XV8m6PoN6dHD",
    "outputId": "18c4a3e1-ae28-43d7-83db-292beb375f00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_paths  # should be empty list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlTRsIZ66dHJ"
   },
   "source": [
    "<div class=h1_cell>\n",
    "I'll stop here with a tree of level 2. Now copy path info into tree_paths so includes predictions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SKsfeVV6dHK"
   },
   "outputs": [],
   "source": [
    "for path in new_paths:\n",
    "    conjunct = path['conjunction']\n",
    "    before_table = generate_table(table, conjunct)\n",
    "    path['prediction'] = compute_prediction(before_table, 'Survived')\n",
    "    tree_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "yLt025BJ6dHM",
    "outputId": "1d68ab60-a2e5-4d80-8227-79504182f30d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'conjunction': [('pclass_3_1',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('emb_S_1', <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.021049896049896044,\n",
       "  'prediction': 0},\n",
       " {'conjunction': [('pclass_3_1',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('emb_S_0', <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.021049896049896044,\n",
       "  'prediction': 0},\n",
       " {'conjunction': [('pclass_3_0',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('sex_female_1',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.2601615877054527,\n",
       "  'prediction': 1},\n",
       " {'conjunction': [('pclass_3_0',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('sex_female_0',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.2601615877054527,\n",
       "  'prediction': 0}]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_paths  #should see predictions on each path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "doCLY7Kk6dHR"
   },
   "source": [
    "<div class=h1_cell>\n",
    "I'm going to add another attribute `oob` to a tree. It stands for Out of Bag. We will make use of it later.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dFTUza26dHR"
   },
   "outputs": [],
   "source": [
    "tree1 = {'paths': tree_paths, 'weight': None, 'oob': left_out_indices1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FYEvZniG6dHU"
   },
   "outputs": [],
   "source": [
    "forest1 = [tree1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tLSHFqP6dHX"
   },
   "source": [
    "<h2>\n",
    "Big hand clap\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "We have successfully built the first tree in the forest. We could stop here with a one-tree forest (boring). Let's add at least one more tree.\n",
    "<p>\n",
    "I'll build the second tree without much in way of comments. It will look the same as construction of tree1.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8r0jC_86dHY"
   },
   "outputs": [],
   "source": [
    "#First generate new training data - every tree gets its own data\n",
    "train2 = titanic_table.sample(frac=1.0, replace=True, random_state=rng)\n",
    "left_out2 = titanic_table.loc[~titanic_table.index.isin(train2.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXBk4Nx06dHa"
   },
   "outputs": [],
   "source": [
    "train2 = train2.reset_index()\n",
    "left_out2 =left_out2.reset_index()\n",
    "left_out_indices2 = left_out2['index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "iyBMAg4g6dHd",
    "outputId": "f9b292fd-fa6e-4a56-d8b0-df70ef995d61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     558\n",
       "False    333\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.duplicated(['index'], keep=False).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CPbYmdAj6dHh",
    "outputId": "e50ef9f0-19b0-4b5e-bc46-a2df11df4078"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 8, 13, 19, 20]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_out_indices2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R5L8kYdF6dHm",
    "outputId": "7ebfbcdf-580d-41dc-97ce-756f348dde31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pclass_3', 'age_Senior', 'emb_nan']"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build the root node\n",
    "\n",
    "rcols = random.sample(splitter_columns, m)\n",
    "rcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1PYjQX6Y6dHw",
    "outputId": "a6a6eff7-b65b-487f-f968-fc06ca6a6ca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pclass_3', 0.04310124038694357)\n"
     ]
    }
   ],
   "source": [
    "columns_sorted = find_best_splitter(train2, rcols, 'Survived')\n",
    "(best_column, gig_value) = columns_sorted[0]\n",
    "print((best_column, gig_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "Zlg-n8DF6dH0",
    "outputId": "99dbd983-6951-42ad-9bc9-f44081b1b864"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'conjunction': [('pclass_3_1',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.04310124038694357,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('pclass_3_0',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.04310124038694357,\n",
       "  'prediction': None}]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "current_paths = [{'conjunction': [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                  'prediction': None,\n",
    "                  'gig_score': gig_value},\n",
    "                 {'conjunction': [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                  'prediction': None,\n",
    "                  'gig_score': gig_value}]\n",
    "                 \n",
    "current_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "2ng-Zuut6dH5",
    "outputId": "c18abc32-cd0b-4a89-a6ba-8033a420f19e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pclass_1', 'emb_S', 'ok_child']\n",
      "['pclass_1', 'sex_female', 'age_Adult']\n"
     ]
    }
   ],
   "source": [
    "table = train2\n",
    "\n",
    "tree_paths = []\n",
    "new_paths = []\n",
    "gig_cutoff = 0.0\n",
    "\n",
    "for path in current_paths:\n",
    "    conjunct = path['conjunction']\n",
    "    before_table = generate_table(table, conjunct)\n",
    "    rcols = random.sample(splitter_columns, m)       #new - chooses random subset for each node\n",
    "    print(rcols)\n",
    "    columns_sorted = find_best_splitter(before_table, rcols, 'Survived')  #using rcols\n",
    "    (best_column, gig_value) = columns_sorted[0]\n",
    "    if gig_value > gig_cutoff:\n",
    "        new_path_1 = {'conjunction': conjunct + [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                    'prediction': None,\n",
    "                     'gig_score': gig_value}\n",
    "        new_paths.append( new_path_1 ) #true\n",
    "        new_path_0 = {'conjunction': conjunct + [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                    'prediction': None,\n",
    "                     'gig_score': gig_value\n",
    "                     }\n",
    "        new_paths.append( new_path_0 ) #false\n",
    "    else:\n",
    "        #not worth splitting so complete the path with a prediction\n",
    "        path['prediction'] = compute_prediction(before_table, 'Survived')\n",
    "        tree_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "De1tErwo6dH8",
    "outputId": "6dab5598-29d5-4646-ece7-813cef8cd5d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'conjunction': [('pclass_3_1',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('emb_S_1', <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.020929647534482787,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('pclass_3_1',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('emb_S_0', <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.020929647534482787,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('pclass_3_0',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('sex_female_1',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.1949595798584,\n",
       "  'prediction': None},\n",
       " {'conjunction': [('pclass_3_0',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('sex_female_0',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.1949595798584,\n",
       "  'prediction': None}]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZJcJCToz6dH_"
   },
   "outputs": [],
   "source": [
    "for path in new_paths:\n",
    "    conjunct = path['conjunction']\n",
    "    before_table = generate_table(table, conjunct)\n",
    "    path['prediction'] = compute_prediction(before_table, 'Survived')\n",
    "    tree_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "AiF_tzpa6dIB",
    "outputId": "e622368b-89df-493e-e2da-2d246395f5b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'conjunction': [('pclass_3_1',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('emb_S_1', <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.020929647534482787,\n",
       "  'prediction': 0},\n",
       " {'conjunction': [('pclass_3_1',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('emb_S_0', <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.020929647534482787,\n",
       "  'prediction': 0},\n",
       " {'conjunction': [('pclass_3_0',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('sex_female_1',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.1949595798584,\n",
       "  'prediction': 1},\n",
       " {'conjunction': [('pclass_3_0',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>),\n",
       "   ('sex_female_0',\n",
       "    <function library_w19_week5b.build_pred.<locals>.<lambda>>)],\n",
       "  'gig_score': 0.1949595798584,\n",
       "  'prediction': 0}]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lAoni5ld6dIF"
   },
   "outputs": [],
   "source": [
    "tree2 = {'paths': tree_paths, 'weight': None, 'oob': left_out_indices2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbOJtEzw6dIK"
   },
   "outputs": [],
   "source": [
    "forest1.append(tree2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGvU0_b16dIQ"
   },
   "source": [
    "<h2>\n",
    "Let's stop at a two-tree forest\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "It would be better to have an odd number to break voting ties, but we will figure something out.\n",
    "<p>\n",
    "Now that we have a forest, let's see how to use it for prediction. I'll define a new function, `vote_taker`, that tallies up the votes of all the trees for a single row. Ties go to the negative outcome 0 (arbitrarily).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kW0MBHaU6dIR"
   },
   "outputs": [],
   "source": [
    "def vote_taker(row, forest):\n",
    "    votes = {0:0, 1:0}\n",
    "    for tree in forest:\n",
    "        prediction = tree_predictor(row, tree)\n",
    "        votes[prediction] += 1\n",
    "    winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZafVOevy6dIT",
    "outputId": "cb63c75e-4e29-4005-95c4-bcddce6c1321"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row0 = titanic_table.loc[0]\n",
    "vote_taker(row0, forest1)  #tree1 0, tree2 0, winner 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UGyY6tAg6dIX"
   },
   "source": [
    "\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "I'm going to define a new function that is very similar to `produce_scores`. But it will work on a forest instead of an individual tree.\n",
    "I commented on the one line I had to change.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7V_oq-OJlHf"
   },
   "outputs": [],
   "source": [
    "def forest_scores(table, forest, target):\n",
    "    scratch_table = pd.DataFrame(columns=['prediction', 'actual'])\n",
    "    scratch_table['prediction'] = table.apply(lambda row: vote_taker(row, forest), axis=1)  #only change is to call vote_taker\n",
    "    scratch_table['actual'] = table[target]  # just copy the target column\n",
    "    cases = scratch_table.apply(lambda row: predictor_case(row, pred='prediction', target='actual'), axis=1)\n",
    "    vc = cases.value_counts()\n",
    "    return [accuracy(vc), f1(vc), informedness(vc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OdyLcxfvKRFQ",
    "outputId": "55942581-f18f-4b5b-b9e6-25d7df9d5e74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7867564534231201, 0.62890625, 0.4543667912951779]"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_scores(titanic_table, forest1, 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5g5mXBX46dIy"
   },
   "source": [
    "<h2>\n",
    "Not that good\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "I'd like to try larger forests. Maybe 10 trees in the forest. But to do that, I don't want to copy and paste all that code. What I would like is a function that can build a forest for me, taking as a hyper parameter how many trees to include. Here is the start.\n",
    "<pre>\n",
    "<code>\n",
    "def forest_builder(table, column_choices, target, hypers):\n",
    "    depth = 2 if 'max-depth' not in hypers else hypers['max-depth']\n",
    "    tree_n = 5 if 'total-trees' not in hypers else hypers['total-trees']\n",
    "    m = int(len(column_choices)**.5) if 'm' not in hypers else hypers['m']\n",
    "</code>\n",
    "</pre>\n",
    "<p>\n",
    "The return should be a forest, i.e., a list of trees as seen above.\n",
    "<p>\n",
    "My implementation borrows heavily from `tree_builder_iter` from module 4. I am still using the nested function `iterative_build` to build a tree. But I have modified it to use bootstrapped training data for each tree and a random subset of attributes for each node in a tree. At the bottom I repeatedly call `iterative_build` to generate the trees for my forest. I also added some new keys to hypers.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apCGdrfY6dIy"
   },
   "outputs": [],
   "source": [
    "def forest_builder(table, column_choices, target, hypers):\n",
    "\n",
    "    tree_n = 5 if 'total-trees' not in hypers else hypers['total-trees']\n",
    "    m = int(len(column_choices)**.5) if 'm' not in hypers else hypers['m']\n",
    "    k = hypers['max-depth'] if 'max-depth' in hypers else min(2, len(column_choices))\n",
    "    gig_cutoff = hypers['gig-cutoff'] if 'gig-cutoff' in hypers else 0.0\n",
    "    rgen = hypers['random-state'] if 'random-state' in hypers else 0  #an int will work as seed with the sample method.\n",
    "\n",
    "    #build a single tree of depth n - call it multiple times to build multiple trees\n",
    "    def iterative_build(n):\n",
    "        train = table.sample(frac=1.0, replace=True, random_state=rgen)\n",
    "        train = train.reset_index()\n",
    "        left_out = table.loc[~table.index.isin(train['index'])]\n",
    "        left_out = left_out.reset_index() # this gives us the old index in its own column\n",
    "        oob_list = left_out['index'].tolist()  # list of row indices from original titanic table\n",
    "        \n",
    "        rcols = random.sample(column_choices, m)  # subspcace sampling - uses random.seed, not rng\n",
    "        columns_sorted = find_best_splitter(train, rcols, target)\n",
    "        (best_column, gig_value) = columns_sorted[0]\n",
    "\n",
    "        #Note I add _1 or _0 to make it more readable for debugging\n",
    "        current_paths = [{'conjunction': [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                          'prediction': None,\n",
    "                          'gig_score': gig_value},\n",
    "                         {'conjunction': [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                          'prediction': None,\n",
    "                          'gig_score': gig_value}\n",
    "                        ]\n",
    "        n -= 1  # we just built a level as seed so subtract 1 from n\n",
    "        tree_paths = []  # add completed paths here\n",
    "\n",
    "        while n>0:\n",
    "            new_paths = []\n",
    "            for path in current_paths:\n",
    "                conjunct = path['conjunction']  # a list of (name, lambda)\n",
    "                before_table = generate_table(train, conjunct)  #the subtable the current conjunct leads to\n",
    "                rcols = random.sample(column_choices, m)  # subspace\n",
    "                columns_sorted = find_best_splitter(before_table, rcols, target)\n",
    "                (best_column, gig_value) = columns_sorted[0]\n",
    "                if gig_value > gig_cutoff:\n",
    "                    new_path_1 = {'conjunction': conjunct + [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                                'prediction': None,\n",
    "                                 'gig_score': gig_value}\n",
    "                    new_paths.append( new_path_1 ) #true\n",
    "                    new_path_0 = {'conjunction': conjunct + [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                                'prediction': None,\n",
    "                                 'gig_score': gig_value\n",
    "                                 }\n",
    "                    new_paths.append( new_path_0 ) #false\n",
    "                else:\n",
    "                    #not worth splitting so complete the path with a prediction\n",
    "                    path['prediction'] = compute_prediction(before_table, target)\n",
    "                    tree_paths.append(path)\n",
    "            #end for loop\n",
    "\n",
    "            current_paths = new_paths\n",
    "            if current_paths != []:\n",
    "                n -= 1\n",
    "            else:\n",
    "                break  # nothing left to extend so have copied all paths to tree_paths\n",
    "        #end while loop\n",
    "\n",
    "        #Generate predictions for all paths that have None\n",
    "        for path in current_paths:\n",
    "            conjunct = path['conjunction']\n",
    "            before_table = generate_table(train, conjunct)\n",
    "            path['prediction'] = compute_prediction(before_table, target)\n",
    "            tree_paths.append(path)\n",
    "        return (tree_paths, oob_list)\n",
    "    \n",
    "    #let's build a forest\n",
    "    forest = []\n",
    "    for i in range(tree_n):\n",
    "        (paths, oob) = iterative_build(k)  #always use k for now\n",
    "        forest.append({'paths': paths, 'weight': None, 'oob': oob})\n",
    "        \n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_TdFYNd6dI2"
   },
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Ok, let's build a forest with 5 trees (the default).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4biX7WzG6dI2",
    "outputId": "08cb11eb-5187-4ed0-f158-ac44c2ccfe80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest2 = forest_builder(titanic_table, splitter_columns, 'Survived', hypers={'random-state':rng})\n",
    "len(forest2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z76mp4v16dI7"
   },
   "source": [
    "<div class=h1_cell>\n",
    "<p>\n",
    "Now get scores.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G6DSbyK_6dI7",
    "outputId": "8d860bcb-eb38-40de-92fd-e3cb3e8fb8f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7800224466891134, 0.684887459807074, 0.5007669446841148]"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_scores(titanic_table, forest2, 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ikxpV3L46dJK"
   },
   "source": [
    "<h2>\n",
    "Try 2 more\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "One with 11 trees with depth of 2, and one with 11 trees and depth of 1 (i.e., 11 stumps).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ftqnUcM-6dJL",
    "outputId": "68a4a2a7-1117-42b1-e3ec-34687df00316"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest3 = forest_builder(titanic_table, splitter_columns, 'Survived', hypers={'total-trees':11, 'random-state':rng})\n",
    "len(forest3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "13olq0P06dJN",
    "outputId": "d567647a-3d5d-4f02-d1a9-17ef592885fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.77665544332211, 0.6924265842349303, 0.5074297766273608]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_scores(titanic_table, forest3, 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hnvqqQIZ6dJQ",
    "outputId": "a15cc010-15b3-4146-e6e4-c67241e965e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest4 = forest_builder(titanic_table, splitter_columns, 'Survived', hypers={'total-trees':11, 'max-depth':1, 'random-state':rng})\n",
    "len(forest4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aGKGfO6A6dJT",
    "outputId": "49efa502-4103-4275-cfe0-c56e24217b60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7867564534231201, 0.62890625, 0.4543667912951779]"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_scores(titanic_table, forest4, 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "abjcS1UP6dJW"
   },
   "source": [
    "<h2>\n",
    "Should explore more\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "If we were ambitious, we could write yet another function that explored for us. Tried combinations of number of trees and depth and reported the best performing. I won't make you write this function but it should be in your grasp by this point. All you would be doing is repeating steps above but now in nested loops that produced various combinations to try.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sx2DKNf76dJY"
   },
   "source": [
    "<h2>\n",
    "Ouf Of Bag errors\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "We could now use K-Folding to do a better evaluation of our forests. But I want to consider another approach called *Out of Bag error* (jargon alert). You will now see where that `oob` value on a tree comes in handy. As reminder, for each tree we generated a training sample. But that sample always leaves some rows out because of replacement. We captured these \"left out\" rows in the `oob` entry. We actually captured the row indices in the larger Titanic table.\n",
    "<p>\n",
    "Here's what I would like to do. I would like to evaluate a forest on the out of bag rows. It kind of makes sense, right? A tree was trained on some set of rows that excluded the rows in oob. So the oob rows are a bit like the test data from K-Folding. We use the oob rows for testing.\n",
    "\n",
    "One way to look at it is I create a new testing table that is the union of the oob list on each tree. I then use this testing table to get predictions by forest vote taking. Here is the twist: a tree gets to vote on a row only if the row is in its oob list.\n",
    "<p>\n",
    "I am going to give you the chance to decide how to implement oob testing as part of your homework assignment.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "OVJ6BnBe6dJY"
   },
   "source": [
    "<hr>\n",
    "<h1>Write it out</h1>\n",
    "<div class=h1_cell>\n",
    "\n",
    "Did not change table but we did define new functions. Add them to your library.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jl4YX5YS6dJd"
   },
   "source": [
    "\n",
    "<h2>\n",
    "Next up\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "We will continue to look at forests. But study an alternative way to test them..\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufShB4sz6dJe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rf_intro_w19.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
