{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rh4uU7eob-bc"
   },
   "source": [
    "<h1>\n",
    "<center>\n",
    "Final Exam\n",
    "</center>\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "The final has 3 basic parts. Part 1 is wrangling a dataset and using ann_flex to train and test a model (40 points). Part 2 is to look at the results of testing in part 1 and do some filtering on the test samples (30 points). Part 3 is an exploration of an algorithm that tries to reduce weight updates (30 points). It uses a simulation loop.\n",
    " <p>\n",
    "   I will give you the dataset to use. You have to supply your library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "G8rLH27bbevq",
    "outputId": "8aaaa870-1fa6-4679-9186-38828f6cc0aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ann_flex\t ann_flex_predictor\t ann_flex_tester\t ann_predictor\t ann_simple\t ann_simple_batch\t ann_tester\t from_scratch\t from_scratch_batch\t \n",
      "from_scratch_flex\t mse\t mse_der\t sigmoid\t sigmoid_der\t \n"
     ]
    }
   ],
   "source": [
    "from library_w19_deep_2 import *\n",
    "\n",
    "%who function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zn2536_DVRFX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IP18ATeIua5"
   },
   "outputs": [],
   "source": [
    "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTST3CURFkC0lHSfR9mGzBAvCmLWl06kw9NSBC3UuD9hA1SlPjh807BRxfnvhq5hrFyRz5ZCTGrs7fr/pub?output=csv'\n",
    "movie_table = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hl0A9_GyQGG8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_table = movie_table[:200]  #trim it down to 200 rows\n",
    "len(movie_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "Lk5iS4oaQXjR",
    "outputId": "b91a072b-a8c6-4673-c989-6732499e71a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Color</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>723.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>3054.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.78</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>302.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>602.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>994.0</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.35</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Color</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>813.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Doug Walker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rob Walker</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   color      director_name  num_critic_for_reviews  duration  \\\n",
       "0  Color      James Cameron                   723.0     178.0   \n",
       "1  Color     Gore Verbinski                   302.0     169.0   \n",
       "2  Color         Sam Mendes                   602.0     148.0   \n",
       "3  Color  Christopher Nolan                   813.0     164.0   \n",
       "4    NaN        Doug Walker                     NaN       NaN   \n",
       "\n",
       "   director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
       "0                      0.0                   855.0  Joel David Moore   \n",
       "1                    563.0                  1000.0     Orlando Bloom   \n",
       "2                      0.0                   161.0      Rory Kinnear   \n",
       "3                  22000.0                 23000.0    Christian Bale   \n",
       "4                    131.0                     NaN        Rob Walker   \n",
       "\n",
       "   actor_1_facebook_likes        gross                           genres  \\\n",
       "0                  1000.0  760505847.0  Action|Adventure|Fantasy|Sci-Fi   \n",
       "1                 40000.0  309404152.0         Action|Adventure|Fantasy   \n",
       "2                 11000.0  200074175.0        Action|Adventure|Thriller   \n",
       "3                 27000.0  448130642.0                  Action|Thriller   \n",
       "4                   131.0          NaN                      Documentary   \n",
       "\n",
       "          ...          num_user_for_reviews language  country  content_rating  \\\n",
       "0         ...                        3054.0  English      USA           PG-13   \n",
       "1         ...                        1238.0  English      USA           PG-13   \n",
       "2         ...                         994.0  English       UK           PG-13   \n",
       "3         ...                        2701.0  English      USA           PG-13   \n",
       "4         ...                           NaN      NaN      NaN             NaN   \n",
       "\n",
       "        budget  title_year actor_2_facebook_likes imdb_score  aspect_ratio  \\\n",
       "0  237000000.0      2009.0                  936.0        7.9          1.78   \n",
       "1  300000000.0      2007.0                 5000.0        7.1          2.35   \n",
       "2  245000000.0      2015.0                  393.0        6.8          2.35   \n",
       "3  250000000.0      2012.0                23000.0        8.5          2.35   \n",
       "4          NaN         NaN                   12.0        7.1           NaN   \n",
       "\n",
       "  movie_facebook_likes  \n",
       "0                33000  \n",
       "1                    0  \n",
       "2                85000  \n",
       "3               164000  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "an3i3EhpkywZ"
   },
   "source": [
    "<h2>Question 1: get your wrangling boots on (15 points)</h2>\n",
    "<p>\n",
    "I am going to tell you what I want and then let you figure out the steps to get there.\n",
    "  <p>\n",
    "   1. I wanti `mdb_score` to be binned into 3 values using `qcut`. I then want that one-hot encoded into the list of labels for `ann_flex`. FInal shape of your `labels` is (n,3).\n",
    "   2. I would like to use the following columns as part of a sample: `facenumber_in_poster,\tnum_user_for_reviews,\tbudget`. Please normalize these columns.\n",
    "   3. I would like to use  `language` as also part of a sample.\n",
    "   4. You should end up with 4 values in each sample.\n",
    " <br><p> \n",
    "Your `ann_flex` function will choke on `NaN` values so make sure you remove rows that contain them.\n",
    "   <p>\n",
    "When you have `feature_set` (the list of samples) and `labels` ready to go, I'll meet you at the next question.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XBwrDNgC-oM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.654381829869295, 0.79, 1],\n",
       "       [0.0, 0.2652667666595243, 1.0, 1],\n",
       "       [0.125, 0.2129847868009428, 0.8166666666666667, 1],\n",
       "       [0.0, 0.578744375401757, 0.8333333333333334, 1],\n",
       "       [0.125, 0.15813156203128348, 0.879, 1]], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#`imdb_score` to be binned into 3 values using `qcut\n",
    "movie_table['imdb_score_binned'] = pd.qcut(movie_table['imdb_score'], 3, ['Low', 'Medium', 'High'])\n",
    "\n",
    "#I would like 2 output nodes, corresponding to the one-hot encoding of coap_binned.\n",
    "one_hot_imdb_score = pd.get_dummies(movie_table[\"imdb_score_binned\"], prefix = \"imdb_score\", dummy_na = False)\n",
    "movie_table = movie_table.join(one_hot_imdb_score)\n",
    "movie_table = movie_table.dropna()\n",
    "labels = movie_table[['imdb_score_Low', 'imdb_score_Medium','imdb_score_High']].values\n",
    "\n",
    "#sample: `facenumber_in_poster, num_user_for_reviews, budget`\n",
    "#normalize these columns\n",
    "movie_table[\"facenumber_in_poster_normed\"] = movie_table[\"facenumber_in_poster\"] / movie_table[\"facenumber_in_poster\"].max()\n",
    "movie_table[\"num_user_for_reviews_normed\"] = movie_table[\"num_user_for_reviews\"] / movie_table[\"num_user_for_reviews\"].max()\n",
    "movie_table[\"budget_normed\"] = movie_table[\"budget\"] / movie_table[\"budget\"].max()\n",
    "\n",
    "ann_table = movie_table[['facenumber_in_poster_normed', 'num_user_for_reviews_normed', 'budget_normed', 'language']]\n",
    "ann_table = ann_table.dropna()\n",
    "ann_table.language[ann_table.language == 'English'] = 1\n",
    "feature_set = ann_table.values\n",
    "\n",
    "print(feature_set.shape)\n",
    "feature_set[:5]\n",
    "\n",
    "\n",
    "#using dropna() on movie_table at the start makes it 193 instead of 194, \n",
    "#but label and sample shape dont match up otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ygG8ZREC_Sy"
   },
   "source": [
    "My feature set has this shape and first 5 values:\n",
    "<pre>\n",
    "(194, 4)\n",
    "array([[0.        , 0.64881341, 0.78894472, 1.        ],\n",
    "       [0.        , 0.25342913, 1.        , 1.        ],\n",
    "       [0.125     , 0.20030481, 0.81574539, 1.        ],\n",
    "       [0.        , 0.57195733, 0.83249581, 1.        ],\n",
    "       [0.125     , 0.14456782, 0.87839196, 1.        ]])\n",
    "       </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzWKRykGM5Vk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(labels.shape)\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-AhSHLkDSNi"
   },
   "source": [
    "My labels has this shape and first 5 values:\n",
    "<pre>\n",
    "(194, 3)\n",
    "array([[0, 0, 1],\n",
    "       [0, 1, 0],\n",
    "       [0, 1, 0],\n",
    "       [0, 0, 1],\n",
    "       [0, 1, 0]], dtype=uint8)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmpGOC1aLqz2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NJjQrErgWcWY"
   },
   "source": [
    "<h2>Question 2: train a model (15 points)</h2>\n",
    "\n",
    "Here's where you earn your 15 takehome points. Show that your `ann_flex` works correctly.\n",
    "<p>\n",
    "Train your model with the first 150 rows. Use `epochs` at 3000 and `cost-reporting` at whatever you like. Everything else can be default values. Here are my resulting `weights` and `biases`.\n",
    "<pre>\n",
    "array([[ 0.49499155, -1.51876998,  1.2508087 ],\n",
    "       [-7.17156319, -0.38214105,  3.18578869],\n",
    "       [-2.76749659, -1.26703916,  3.34669796],\n",
    "       [ 0.62092268,  0.17293429, -2.23830144]])\n",
    "array([ 1.41175081,  0.4811565 , -2.15045844])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vO8wp8k8zSY1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.711989156200089)\n",
      "(1000, 0.6819104060697413)\n",
      "(2000, 0.681835817985708)\n",
      "(3000, 0.6818358186821057)\n",
      "[[0.4961878915452624 -1.5200497743826602 1.2520488745112297]\n",
      " [-7.3028570666893735 -0.39072485746112656 3.2356135452762707]\n",
      " [-2.7850737440601487 -1.2693358989058319 3.3655347073933624]\n",
      " [0.6875687525258146 0.17857115788033556 -2.2738415215636723]]\n",
      "[ 1.47839688  0.48679337 -2.18599852]\n"
     ]
    }
   ],
   "source": [
    "(weights, biases) = from_scratch_flex(feature_set[:150], labels[:150], hypers={'epochs':3000, 'cost-reporting': 1000})\n",
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "upFVvbbYXLZ1"
   },
   "source": [
    "<h2>Question 3: test your model (10 points)</h2>\n",
    "\n",
    "You used the first 150 samples to train your model. Test your model with remaining samples from 200 you started with.\n",
    "<p>\n",
    "  For computing accuracy, you will have 3 raw values as output. Use the max value as the position of the 1. For instance, if you had output\n",
    "  <p>\n",
    "    `       array([0.55081372, 0.36331553, 0.11846781])`\n",
    "    <p>\n",
    "      you would predict '(1,0,0)`. The max value is in the 0th position so would place the 1 there. Once you have done this conversion, you can compare your predictions against labels to get accuracy.\n",
    "<p>\n",
    "        My accuracy is `0.36`. Just barely above the roll of a 3-sided dice.\n",
    "  <p>\n",
    "    One last note. You will need the raw output of your model in the next question so good to keep track of it here so you have it there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U7-WTDTi3KYT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4266666666666667\n"
     ]
    }
   ],
   "source": [
    "#(weights, biases) = from_scratch_flex(feature_set[:150], labels[:150], hypers={'epochs':3000, 'cost-reporting': 1000})\n",
    "predictions = ann_flex_tester(feature_set[:150], weights, biases)\n",
    "\n",
    "pred = []\n",
    "for i in range(len(predictions)):\n",
    "    \n",
    "    mx = predictions[i].tolist().index(max(predictions[i].tolist()))\n",
    "    #print(mx)\n",
    "    #for j in range(len(predictions[i])):\n",
    "    temp = [0,0,0]\n",
    "    temp[mx]  = 1\n",
    "    pred.append(temp)\n",
    "        \n",
    "#print(pred)\n",
    "#accuracy = 0.0\n",
    "accuracy = len(predictions)\n",
    "for j in range(len(pred)):\n",
    "    \n",
    "    #if 1 of 3 is inaccurate, all are\n",
    "    if(pred[j][0] != labels[j][0] or pred[j][1] != labels[j][1] or pred[j][2] != labels[j][2]):\n",
    "        #accuracy += 1\n",
    "        accuracy -= 1\n",
    "\n",
    "#averaged\n",
    "accuracy = accuracy / len(predictions)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8WmOrRhW85U"
   },
   "source": [
    "<h2>Question 4:  filtering the test set (30 points)</h2>\n",
    "  \n",
    "I'd like to reduce the number of samples in the feature set I use for testing. I know we are only using a small number of test samples to keep processing costs down in the exam, but normally the size could be in the millions. What I would like to do is find the samples that have similar errors when doing prediction. Here is what I propose to do: look at pairwise sets of samples. If the 2 samples in the pair have roughly the same overall error (i.e., within epsilon), I can remove one of them from the test set: it is redundant.\n",
    "  <p>\n",
    "  I'm going to ask you to help me with the first part of this problem. I'd like an ordered list, pairwise, of all the samples along with the absolute difference in their overall errors. That's a mouthful. Let me give you some more details. I am using results we got from question 3.\n",
    "  \n",
    "  1. As you know, `labels` is a list of  triples where each triple is one-hot encoded.  Your raw output is also a triple of  values. What do I mean by \"raw output\"? I mean the actual 3 values that you get from your model, e.g., `array([0.55081372, 0.36331553, 0.11846781])`. For each such raw output, calculate the absolute difference between the 2 triples, i.e., your raw output triple and the label triple. This will give you a new triple of errors. So if the label for my example raw output above was `(0,0,1)`, I would get this as the error triple: `(abs(0-0.55081372), abs(0-0.36331553), abs(1-0.11846781))`. \n",
    "  2. Sum the error triple. That sum is what I want to store with the sample, i.e., I will record the sample index (or equivalently the label index) and a single summed error that goes with it. Note that this is different than the practice problem where you were doing an average. We are not doing any averaging.\n",
    "  3. I'd now like you to go pairwise through the samples and for each unique pair, record the absolute difference between their summed errors. As an example, if you were using a dictionary to keep track of your results, you might see an entry `(0,1): .003`, which signifies that the absolute difference between sample 0 and sample 1 is .003. What does that actually mean? The two samples are fairly close in their errors. Both errors could be quite high. But the absolute difference between them is small.\n",
    "  4. Order the list based on ascending absolute differences.\n",
    "\n",
    "  You can stop there. Normally I would then use your ordered list to filter out samples that have errors within some epsilon of each other. We do not need 2 separate samples that mimic each other in terms of errors they produce. We can just keep one of them and toss the other.\n",
    "<p>\n",
    "  You can see my final results below for the first 10 in my ordered list. To keep processing times down, I trimmed predictions and labels to [:15], i.e. the first 15.\n",
    "  <pre>\n",
    "  [((0, 3), 0.002331643103141934),\n",
    " ((7, 10), 0.01036188464574006),\n",
    " ((11, 12), 0.016973839107757627),\n",
    " ((0, 2), 0.028251848582276695),\n",
    " ((2, 3), 0.03058349168541863),\n",
    " ((5, 14), 0.0453548688750367),\n",
    " ((10, 14), 0.04570192275791962),\n",
    " ((6, 8), 0.05405101534935941),\n",
    " ((7, 14), 0.05606380740365968),\n",
    " ((5, 6), 0.06109838820689739)]\n",
    " </pre>\n",
    " <p>\n",
    "  What this means is that the total error for sample 0 and the total error for sample 3 are within 0.00233 of each other using absolute difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GLsb3C7QBmGN"
   },
   "source": [
    "To keep processing time within reason, only work with the first 15 predictions from your testing. Here are mine. If your first 15 don't match my first 15, go ahead and use mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "id": "g24Qv2ezdRKN",
    "outputId": "82f56bed-e278-4c9a-ebf0-4c457b075dbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.55081372, 0.36331553, 0.11846781],\n",
       " [0.63322896, 0.5091635, 0.06235565],\n",
       " [0.7097191, 0.50770786, 0.04740651],\n",
       " [0.37215582, 0.45147866, 0.11034364],\n",
       " [0.45966018, 0.50442377, 0.08079772],\n",
       " [0.15938415, 0.47507109, 0.15527721],\n",
       " [0.09379516, 0.47731639, 0.18199096],\n",
       " [0.64372884, 0.28360809, 0.14045216],\n",
       " [0.66493551, 0.32965622, 0.1117983],\n",
       " [0.57558268, 0.5153202, 0.06451307],\n",
       " [0.28899897, 0.45579208, 0.12019616],\n",
       " [0.63175644, 0.41794559, 0.08506059],\n",
       " [0.20354411, 0.49121776, 0.12801538],\n",
       " [0.70649204, 0.25956437, 0.13452677],\n",
       " [0.60337277, 0.37912699, 0.09892885]]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions_15 = predictions[:15]\n",
    "predictions_15 = [[0.55081372, 0.36331553, 0.11846781],[0.63322896, 0.5091635 , 0.06235565],[0.7097191 , 0.50770786, 0.04740651],[0.37215582, 0.45147866, 0.11034364],[0.45966018, 0.50442377, 0.08079772],[0.15938415, 0.47507109, 0.15527721],[0.09379516, 0.47731639, 0.18199096],[0.64372884, 0.28360809, 0.14045216],[0.66493551, 0.32965622, 0.1117983 ],[0.57558268, 0.5153202 , 0.06451307],[0.28899897, 0.45579208, 0.12019616],[0.63175644, 0.41794559, 0.08506059],[0.20354411, 0.49121776, 0.12801538],[0.70649204, 0.25956437, 0.13452677],[0.60337277, 0.37912699, 0.09892885]]\n",
    "predictions_15 #First 15 predictions from question 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKwIzckMB7qk"
   },
   "source": [
    "Similarily, we need the first 15 labels from the test set. Here are mine. If your first 15 don't match my first 15, go ahead and use mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "id": "YtdKa8cBdUgU",
    "outputId": "8ba908da-1f40-4ac8-c785-6abed1dc2d0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 0, 1],\n",
       " [0, 1, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 1, 0],\n",
       " [1, 0, 0],\n",
       " [0, 1, 0],\n",
       " [0, 0, 1],\n",
       " [1, 0, 0],\n",
       " [0, 1, 0]]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels_15 = labels[:15]\n",
    "labels_15 = [[0, 0, 1],[0, 1, 0],[0, 1, 0],[0, 0, 1],[0, 1, 0],[1, 0, 0],[0, 0, 1],[0, 0, 1],[0, 0, 1],[0, 1, 0],[1, 0, 0],[0, 1, 0],[0, 0, 1],[1, 0, 0],[0, 1, 0]]\n",
    "labels_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aKvudTPG5F7Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1.79566144], [1, 1.18642111], [2, 1.24941775], [3, 1.71329084], [4, 1.03603413], [5, 1.47096415], [6, 1.38912059], [7, 1.78688477], [8, 1.88279343], [9, 1.12477555], [10, 1.2869892699999999], [11, 1.29887144], [12, 1.5667464899999999], [13, 0.6875991], [14, 1.32317463]]\n"
     ]
    }
   ],
   "source": [
    "#For each such raw output, calculate the absolute difference between the 2 triples, \n",
    "#i.e., your raw output triple and the label triple\n",
    "errors = []\n",
    "for i in range(len(predictions_15)):\n",
    "    zero = abs(predictions_15[i][0] - labels_15[i][0])\n",
    "    one = abs(predictions_15[i][1] - labels_15[i][1])\n",
    "    two = abs(predictions_15[i][2] - labels_15[i][2])\n",
    "    error = zero + one + two    #sum triple error\n",
    "    \n",
    "    errors.append([i, error])\n",
    "    \n",
    "print(errors)\n",
    "    \n",
    "#for each unique pair, record the absolute difference between their summed errors\n",
    "\n",
    "#Order the list based on ascending absolute differences\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kij1-pe-gXOV"
   },
   "source": [
    "<h2>Question 5: ignoring weight changes (30 points)</h2>\n",
    "\n",
    "For efficiency reasons, we may want to avoid making weight changes unless the change really matters. I'd like you to use a simulation loop to test out this algorithm:\n",
    "\n",
    " 1. Keep track of the weight changes from a previous sample. Unlike momentum, you need only to keep track of a single change matrix. I call this my history cache. Initially it will start with a zeroed out change matrix.\n",
    " 2. Compare the current weight change (simulated) with the weight change matrix in the history cache.\n",
    " 3. If they are close, do nothing; go immediately to the next sample. You can just ignore the weight change for the current sample and do nothing to the history cache.\n",
    " 4. If they are not close, then go ahead and make the (simulated) weight change to weights and store the current (simulated) weight change in your history cache, replacing what ever was there.\n",
    "<p>\n",
    "I hope you are asking what the heck does \"close\" mean. Well, I'll tell you. Those clever folks at numpy headquarters have defined a method to compare the closeness of 2 matrices. Here is what I would like you to use:\n",
    "<pre>\n",
    "  np.allclose(history_cache, simulated_changes, atol=.09)\n",
    "</pre>\n",
    "Pretty cool, huh. Normally `atol`, the tolerance the function uses, would be a hyper-parameter. I am just going to use .09.\n",
    "<p>\n",
    "I printed out some results for you to compare against. I printed out the starting weights and the ending weights. And every time I ignored a weight change I printed the sample index and the string `close`. Here is what I got. You can see I avoided 4 updates to weights.\n",
    "<pre>\n",
    "[[-0.02509198  0.09014286]\n",
    " [ 0.04639879  0.0197317 ]\n",
    " [-0.06879627 -0.0688011 ]]\n",
    "==============================\n",
    "(1, 'close')\n",
    "(2, 'close')\n",
    "(5, 'close')\n",
    "(9, 'close')\n",
    "array([[ 0.11476858, -0.0774422 ],\n",
    "       [ 0.20985929, -0.14123441],\n",
    "       [-0.04380995, -0.18179776]])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "403xa6LMeD4J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02509198  0.09014286]\n",
      " [ 0.04639879  0.0197317 ]\n",
      " [-0.06879627 -0.0688011 ]]\n",
      "==============================\n",
      "2, 'close'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.10962184,  0.10628575],\n",
       "       [ 0.17090019, -0.03729647],\n",
       "       [ 0.11474705, -0.19432364]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_n = 3    #how many input nodes\n",
    "output_n = 2   #how many output nodes\n",
    "sample_n = 10  #how many simulated samples to try\n",
    "\n",
    "np.random.seed(42)\n",
    "weights = .2*np.random.rand(input_n,output_n) - .1  #initial value of weights matrix\n",
    "history_cache = np.zeros((input_n, output_n)) #populate with 0s in shape of weights\n",
    "\n",
    "print(weights)\n",
    "print('='*30)\n",
    "\n",
    "for i in range(sample_n):\n",
    "    #generate simulated weight changes as if coming from backprop\n",
    "    simulated_changes = .2*np.random.rand(input_n,output_n) - .1\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Keep track of the weight changes from a previous sample. \n",
    "    #Unlike momentum, you need only to keep track of a single change matrix. \n",
    "    #I call this my history cache. Initially it will start with a zeroed out change matrix\n",
    "    #history_cache = simulated_changes\n",
    "    #not sure if this should updae here or not\n",
    "    \n",
    "    #Compare the current weight change (simulated) with the weight change matrix in the history cache\n",
    "    if(np.allclose(history_cache, simulated_changes, atol=.09)):\n",
    "        #if close enough\n",
    "        print(\"%s, 'close'\" %i)\n",
    "    else:\n",
    "        \n",
    "        #make the (simulated) weight change to weights and store the current (simulated) weight change in your history \n",
    "        weights = weights - simulated_changes\n",
    "        history_cache = simulated_changes\n",
    "    \n",
    "    \n",
    "\n",
    "weights  #values when done with for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "final_inclass_w19.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
