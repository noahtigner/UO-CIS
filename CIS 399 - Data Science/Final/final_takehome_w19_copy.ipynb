{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rh4uU7eob-bc"
   },
   "source": [
    "<h1>\n",
    "<center>\n",
    "Final Exam - take home portion\n",
    "</center>\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "You will need to finish this takehome portion of the final exam before arriving for the in-class exam. The in-class portion will build on your answer here.\n",
    "  <p>\n",
    "    There is only 1 question on the takehome portion. It is worth 15 points of the final. But as noted, you need to finish it to be sucessful on the in-class portion.\n",
    "    <p>\n",
    "      I'll give you some new content and then ask the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_F-eyfiQj2ig"
   },
   "source": [
    "<h2>Bring in library from module 8</h2>\n",
    "<p>\n",
    "  We don't need the batch version so I am importing from deep_1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BQcquKEsbB0b",
    "outputId": "6d5b66df-0e5d-4411-abb8-50ae2b2c8cdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'library_w19_deep_1.py': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm library_w19_deep_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "Wl7zyWU-bG55",
    "outputId": "41631646-2a60-463f-f34c-670a260561a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-49648fc3-7773-4b99-bac0-853d8526e6f6\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-49648fc3-7773-4b99-bac0-853d8526e6f6\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving library_w19_deep_1.py to library_w19_deep_1.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'library_w19_deep_1.py': b\"import pandas as pd\\nimport numpy as np\\n\\ndef sigmoid(x):  \\n    return 1/(1+np.exp(-x))\\n\\ndef mse(z,y):\\n  return (z-y)**2\\n\\ndef mse_der(z,y):\\n  return z-y\\n\\ndef sigmoid_der(x):  \\n    return sigmoid(x)*(1-sigmoid(x))\\n\\ndef ann_simple(all_samples, labels, weights, bias, hypers={}):\\n  \\n  '''\\n  Can build an ANN with n input nodes and one output node.\\n  Uses sigmoid and mse.\\n  '''\\n  \\n  input_n = all_samples.shape[1]  #number of inputs in each sample\\n  \\n  assert weights.shape == (input_n,1), 'weights needs to have same shape as sample'\\n  assert all_samples.shape[0] >= 1, 'all_samples must represent 1 or more samples'\\n  assert bias.shape == (1,) , 'a single bias weight for output node'\\n  assert labels.shape[1] == 1, 'actual value for the 1 output node'\\n  assert labels.shape[0] == all_samples.shape[0], 'labels must match up with samples'\\n  \\n  hyper_keys = [*hypers]  #fails on 2.7\\n  target_set = set(['epochs', 'cost-reporting', 'learning-rate'])  #might add more later\\n  diff_set = set(hyper_keys) - target_set\\n  if diff_set: print('WARNING: unrecognized hyper parameters ' + str(diff_set))\\n\\n  max_epochs = hypers['epochs'] if 'epochs' in hypers else 100\\n  cost_reporting = hypers['cost-reporting'] if 'cost-reporting' in hypers else 100  #how often to report epoch cost\\n  alpha = hypers['learning-rate'] if 'learning-rate' in hypers else .05\\n  \\n  cost_accumulator = [0, 0]  #[count, sum] use to print out costs now and then\\n  \\n  for i in range(max_epochs):\\n\\n    #Go through each sample forward and backward\\n    for j in range(len(all_samples)):\\n\\n\\n      #do forward propogation\\n      sample = np.expand_dims(all_samples[j], axis=1) #transform to match up with weight shape\\n      XW = np.multiply(sample, weights)\\n      XW_sum = np.sum(XW, axis=0)\\n      raw_output = XW_sum + bias\\n      z = sigmoid(raw_output)\\n\\n      #compute error\\n      cost = mse(z, labels[j])\\n      cost_accumulator[0] += 1\\n      cost_accumulator[1] += cost\\n\\n      #back propogation\\n      mse_deriv_value = mse_der(z, labels[j])\\n      sigmoid_deriv_value = sigmoid_der(raw_output)\\n      z_delta = mse_deriv_value * sigmoid_deriv_value\\n\\n      #update weights\\n      for k in range(len(weights)):\\n        #print(('before weight', weights[k]))\\n        weights[k][0] -= alpha * all_samples[j][k] * z_delta\\n        #print(('after weight', weights[k]))\\n\\n      #update bias\\n      bias -=  1.0*z_delta\\n\\n    #print ith cost value\\n    if i%cost_reporting == 0:\\n      average_cost = cost_accumulator[1]/cost_accumulator[0]  #really mse where n is cost_reporting epochs\\n      print((i,average_cost))\\n      cost_accumulator = [0, 0]  #reset\\n  #end epoch loop\\n\\n  if cost_accumulator[0]:\\n    average_cost = cost_accumulator[1]/cost_accumulator[0]  #really mse where n is cost_reporting epochs\\n    print((max_epochs,average_cost))\\n\\n  return (weights,bias)  #don't lose these! We worked hard to get them.\\n\\n#build/train a new ann starting with known random seeds\\ndef from_scratch(samples, labels, hypers):\\n  \\n  input_n = samples.shape[1]\\n  \\n  #reset weights to initial values. Seed of 42 guarantees same random values\\n  np.random.seed(42)\\n  weights = np.random.rand(input_n,1)\\n  bias = np.random.rand(1)\\n  \\n  return ann_simple(samples, labels, weights, bias, hypers)\\n\\ndef ann_predictor(sample, weights, bias):\\n  \\n  s2 = np.expand_dims(sample, axis=1)\\n  XW = np.multiply(s2, weights)\\n  XW_sum = np.sum(XW, axis=0)\\n  raw_output = XW_sum + bias\\n  z = sigmoid(raw_output)\\n\\n  return 1 if z > .5 else 0\\n\\ndef ann_tester(samples, labels, weights, bias):\\n  weights = np.array(weights)\\n  bias = np.array(bias)\\n  \\n  predictions = [ann_predictor(s, weights, bias) for s in samples]\\n  zipped = list(zip(predictions, labels))\\n  \\n  return (zipped.count((1,1)) + zipped.count((0,0)))/len(zipped)\\n\\n\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G8rLH27bbevq",
    "outputId": "1cbdd89c-abce-412e-976b-5e3f9e54aa8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ann_predictor\t ann_simple\t ann_tester\t from_scratch\t mse\t mse_der\t sigmoid\t sigmoid_der\t \n"
     ]
    }
   ],
   "source": [
    "from library_w19_deep_1 import *\n",
    "\n",
    "%who function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zn2536_DVRFX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZLcP8sGK3Ebc"
   },
   "source": [
    "<h2>An upgrade to our week 8 code</h2>\n",
    "\n",
    "I want to look at an ANN  that will have multiple input and multiple output nodes. We started to be a bit elastic in week 8 by allowing any number of input nodes. I want to go full-elastic and allow any number of ouput nodes. So I'll generate weights based on the length of a sample and the length of a label.\n",
    "<p>\n",
    "  I am going to set myself a challenge. I want to avoid any constants other than hyper-parameters. So don't want to hard-wire in how many nodes I will have. I'd also like to avoid for loops. Instead, I want to build on the powerful vector and matrix operations numpy provides. You can see if I meet the challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wPjVuFdfBA4"
   },
   "source": [
    "<h2>Using a Dot Product</h2>\n",
    "\n",
    "In week 8 we used `np.multiply` and `np.sum` to compute the raw input to the output nodes. We then used that raw input as argument to sigmoid to get the final output. I want to use something a little more sophisticated to replace those 2 separate operations.  It is called a dot product. And to show it off, I am going to introduce a more complicated ANN that has 3 inputs and 3 outputs. Check out the image below.\n",
    "<p>\n",
    "  <img src='https://www.dropbox.com/s/7zjjpft0ulbh0ah/dot3.png?raw=1'>\n",
    "  <p>\n",
    "    Assume we have 3 input nodes and 3 output nodes. We will expand this to a larger dimension in a minute but same idea will apply. To feed forward, I need to come up with a raw input to each of the 3 output nodes. We will need 9 link weights and 3 bias weights, right? As you can see, each output node has 3 links coming into it: one from in1, one from in2, one from in3. In the diagram above, you can view the first column in the 3x3 matrix as the weights for all the links coming into out1, the second column as the weights for out2, the third column as the weights for out3. I am omitting the bias weights for now. But there would be a vector of the 3 bias weights as well.\n",
    "    <p>\n",
    "      For the row on the left, you can view in1 as the value for the in1 node, etc.\n",
    "      <p>\n",
    "        Ok, the cool part. I can use a dot-product to get the raw input values for the 3 output nodes. The resulting row holds those 3 values.  Let's check it out with code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lc3TcqOUfBA6"
   },
   "outputs": [],
   "source": [
    "weights = np.array([[0, 1, 2],  #test values for weights\n",
    "              [3, 4, 5],\n",
    "             [6, 7, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i8unzsXt5R7K"
   },
   "outputs": [],
   "source": [
    "biases =  np.array([-1, -2, -3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j23qxx5IfBA9"
   },
   "outputs": [],
   "source": [
    "sample = np.array([.10,.20,.30])  #test values for one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fBA1ZzytfBBC",
    "outputId": "2872ecd7-cf77-4104-b45a-dae726d8ff43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.4, 3. , 3.6])"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = sample.dot(weights)  #raw input to each output node\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5SefpXKQ2Pup"
   },
   "source": [
    "You should convince yourself that raw[0] is the sum of products of column 0 in the matrix, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GTqRZsRM5nLK",
    "outputId": "976d17cc-a51f-4958-e27e-706e11a59247"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4, 1. , 0.6])"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_raw = np.add(raw, biases)\n",
    "full_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M1odlIXofBBI"
   },
   "source": [
    "<h2>You've heard of GPUs and Deep Learning?</h2>\n",
    "\n",
    "Taking the dot product is one of the things GPUs (Graphical Processing Units) excel at. Hope you can see that the dot product is highly parallelizable. And that parrallelization is one of the tricks a GPU can perform. High-powered GPUs grew out of the gaming industry and now have been harnessed for neural nets. Nvidia is the major player in the field.\n",
    "<p>\n",
    "  BTW: You can choose to use a GPU on colab. Go under Runtime and Change Runtime Type. You will see GPU as an option. Spoiler alert: you won't see any difference in performance until you get to ANNs with 1000s of inputs and millions of weights. But as reminder, everything we are doing in class does scale. Same basic forward and backward propogation operations apply in small nets and huge nets.\n",
    "  <p>\n",
    "    You will also see the option of a TPU. This is not a separate chip like a GPU, but a co-processor that runs with your CPU. It stands for Tensor Processing Unit. Google invented it. You probably have questions. What is a tensor? Look at weights above. It is a tensor! So most of the things we have been doing with vectors and matrices has a fancier name of 1D and 2D tensors. Is a TPU better than a GPU? Not in performance. But yes in cost and energy consumption (and heat generated). There is a reason google built one of their server-farms in the Dalles: it is right next to the Bonneville Power Plant!\n",
    "    <p>\n",
    "      Here is further discussion of GPU and TPU: https://www.quora.com/How-different-is-a-TPU-from-GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSRxoh2OfBBI"
   },
   "source": [
    "<h2>Vectorize the activation function</h2>\n",
    "\n",
    "There is another place that has potential for parallelism. Once we have our 3 raw inputs to the 3 output nodes, we need to apply sigmoid to each. I could do this with a map. And this should tell you there is parallelization potential: any map operation has potential to be made parallel. So here is the map code. Why all high values? Remember what sigmoid does with large values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bysZTc4jfBBJ",
    "outputId": "1a62a98d-df09-462f-f5b6-13ea117b7aa0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8021838885585817, 0.7310585786300049, 0.6456563062257954]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zm = list(map(sigmoid, full_raw))\n",
    "zm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2eSLTIrfBBN"
   },
   "source": [
    "Here is an alternative way that perhaps has more potential given the community interest in cranking the performance on all the numpy operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MVamzIzEfBBO",
    "outputId": "3a4a6512-02f6-47fe-e19e-f66c4ef0b2d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80218389, 0.73105858, 0.64565631])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsig = np.vectorize(sigmoid)\n",
    "zv = fsig(full_raw)\n",
    "zv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "abIo3C4WfBBR"
   },
   "source": [
    "This gives us our 3 ouput values and ends forward propogation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GUsfoP98fBBR"
   },
   "source": [
    "<h2>Computing error (AKA cost)</h2>\n",
    "\n",
    "We have 3 separate costs to compute, one for each of the 3 output nodes. I am going to use a map.\n",
    "<p>\n",
    "  Let's say the label is [4,4,3]. I know this is slightly weird. We have always been using target columns (e.g., Survived, Loan_Status) that have a single binary value. What's up with 3 values? For our toy example, it is weird. You will have to wait a bit to see its actual use. Hint: we will need to one-hot encode the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cSOWwLQKfBBS",
    "outputId": "e559e371-0c86-446a-be6c-63a95207d3e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.22602788, 10.68597802,  5.54293423])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.array([4,4,3])  #the actual value that goes with the sample - not very motivating at moment\n",
    "\n",
    "costs = np.array([mse(a,b) for (a,b) in zip(zv, label)])  #will get 3 costs for the 3 output nodes\n",
    "\n",
    "costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FqQLoWkTvSkC"
   },
   "source": [
    "That ends forward propogation. Let's take a look at backward propogation. If we think about it, we will need to backpropogate from the 3 output nodes individually. Each output node leads to 3 weights. When we finish all 3 we will have updates for all 9 weights (and the 3 bias weights).\n",
    "<p>\n",
    "  Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gCA2ylMovqZ-",
    "outputId": "af280c51-ef24-4443-f3d1-0529c34b45de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.19781611, -3.26894142, -2.35434369])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 output nodes so 3 mse_der values to compute\n",
    "\n",
    "\n",
    "mse_deriv_values = np.array([mse_der(a,b) for (a,b) in zip(zv, label)])\n",
    "mse_deriv_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-7ue9ZhVzaLJ"
   },
   "source": [
    "Next up: sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FZkZNzzMqFew",
    "outputId": "d08ae8a0-7d0f-4df6-94a6-cbeb656aca8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.076255  , 0.04517666, 0.02588959])"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsig_der = np.vectorize(sigmoid_der) #using numpy built-in mapping function\n",
    "\n",
    "sigmoid_deriv_values = fsig_der(raw)\n",
    "sigmoid_deriv_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLIAyI_DzqEM"
   },
   "source": [
    "The 3 z_delta values up next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hH163c-jxv4g",
    "outputId": "4f192ab9-4d35-44f5-8271-163cccd561cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24384946, -0.14767985, -0.060953  ])"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_deltas = np.multiply(mse_deriv_values, sigmoid_deriv_values)\n",
    "z_deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JU89pGD7z3W5"
   },
   "source": [
    "Now ready to update all 9 weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "JYu08Kga0FtI",
    "outputId": "c6847f78-eafd-47df-e7af-863b87c41350"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.02438495, -0.04876989, -0.07315484]),\n",
       " array([-0.01476799, -0.02953597, -0.04430396]),\n",
       " array([-0.0060953, -0.0121906, -0.0182859])]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1\n",
    "\n",
    "weight_changes = [sample*z_deltas[i] for i in range(len(z_deltas))]\n",
    "weight_changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mp1mRluN1DJj"
   },
   "source": [
    "Unfortunately, the change matrix does not line up with our weight matrix. The weights are column-based. Column 0 represents all the links coming into output node 0. What we have above is all the links coming into output node 0 as the row 0. Solution? Several. Pick your poison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "_eIvfBiT1hc5",
    "outputId": "95a8d643-beda-4062-d9b2-a727e74b9eb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02438495, -0.01476799, -0.0060953 ],\n",
       "       [-0.04876989, -0.02953597, -0.0121906 ],\n",
       "       [-0.07315484, -0.04430396, -0.0182859 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 2 - alternative 1\n",
    "\n",
    "wt = np.transpose(weight_changes)\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "A68SMk200nR1",
    "outputId": "4c2f213e-b64b-40eb-8301-4670291a0a82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02438495, -0.01476799, -0.0060953 ],\n",
       "       [-0.04876989, -0.02953597, -0.0121906 ],\n",
       "       [-0.07315484, -0.04430396, -0.0182859 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 2 - alternative 2\n",
    "\n",
    "ws = np.column_stack(weight_changes)\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YPNRzjp29YU"
   },
   "source": [
    "We now have the weights and changes to the weights aligned. Watch how slick it is to update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "NZ4rjUg42tnl",
    "outputId": "ccb20096-6e84-4256-e9b2-8ba67e3a427a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just as reminder, here are the weights\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "YGSXBdik4IzZ",
    "outputId": "712d8581-1aab-42a2-e0e1-d4fb849eb3c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02438495, 1.01476799, 2.0060953 ],\n",
       "       [3.04876989, 4.02953597, 5.0121906 ],\n",
       "       [6.07315484, 7.04430396, 8.0182859 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.subtract(weights, wt)  #going with the transpose version\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2DnEZ5Y05Wg"
   },
   "source": [
    "The biases are easy peasy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rR9uPvKq8Mw5",
    "outputId": "c268e132-008a-4951-f9a4-821099d139fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.75615054, -1.85232015, -2.939047  ])"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases = np.subtract(biases, z_deltas)\n",
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2a7p9xF57e4l"
   },
   "source": [
    "<h2>I think we have it</h2>\n",
    "\n",
    "You have all the pieces for a new function `ann_flex`. Go ahead and write it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1DQAdSJeZHuv"
   },
   "source": [
    "<h2>Final exam question 1: define ann_flex (15 points)</h2>\n",
    "<p>\n",
    "  Use ann_simple as your basis. In particular, we will not be using ann_simple_batch. I started it for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0c2VERDw8tYZ"
   },
   "outputs": [],
   "source": [
    "def ann_flex(all_samples, all_labels, weights, biases, hypers={}):\n",
    "  \n",
    "  '''\n",
    "  Can build an ANN with n input nodes and m output nodes.\n",
    "  Uses sigmoid and mse.\n",
    "  '''\n",
    "  \n",
    "  input_n = all_samples.shape[1]  #number of inputs in each sample\n",
    "  output_n = all_labels.shape[1]      #number of outputs in each label\n",
    "  \n",
    "  assert weights.shape == (input_n,output_n), 'weights needs to have same shape as sample'\n",
    "  assert all_samples.shape[0] >= 1, 'all_samples must represent 1 or more samples'\n",
    "  assert biases.shape == (output_n,) , 'a bias weight for each output node'\n",
    "  assert all_labels.shape[0] == all_samples.shape[0], 'labels must match up with samples'\n",
    "  \n",
    "  hyper_keys = [*hypers]  #fails on 2.7\n",
    "  target_set = set(['epochs', 'cost-reporting', 'learning-rate'])  #might add more later\n",
    "  diff_set = set(hyper_keys) - target_set\n",
    "  if diff_set: print('WARNING: unrecognized hyper parameters ' + str(diff_set))\n",
    "\n",
    "  max_epochs = hypers['epochs'] if 'epochs' in hypers else 100\n",
    "  cost_reporting = hypers['cost-reporting'] if 'cost-reporting' in hypers else 100  #how often to report epoch cost\n",
    "  alpha = hypers['learning-rate'] if 'learning-rate' in hypers else .05\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xzi9RQauZjdN"
   },
   "source": [
    "I'll give you the next one. Notice I changed the weight creation code a bit. I moved weights between -.1 and +.1. It's one heuristic out of many for generating initial weights of an ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQysu39eBKne"
   },
   "outputs": [],
   "source": [
    "def from_scratch_flex(samples, labels, hypers):\n",
    "  \n",
    "  input_n = samples.shape[1]\n",
    "  output_n = labels.shape[1]\n",
    "  \n",
    "  #reset weights to initial values. Seed of 42 guarantees same random values\n",
    "  np.random.seed(42)\n",
    "  weights = .2*np.random.rand(input_n,output_n) - .1\n",
    "  biases = np.random.rand(output_n)\n",
    "  \n",
    "  return ann_flex(samples, labels, weights, biases, hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "U1-djnqfBcqN",
    "outputId": "beabe6b4-3d0e-4835-effb-6a0633f16720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1.0248370947474648)\n",
      "(1, 0.9150220318962172)\n",
      "(2, 0.8159534381771475)\n",
      "(3, 0.7378534387504471)\n",
      "(4, 0.680950671446293)\n",
      "(5, 0.640234274488902)\n",
      "(6, 0.610501870499008)\n",
      "(7, 0.587984873656967)\n",
      "(8, 0.5702434582005558)\n",
      "(9, 0.555738124644553)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.40240815, -0.33955348,  0.31486134],\n",
       "        [-0.3574284 , -0.68043077,  0.15884282]]),\n",
       " array([ 0.05964438, -0.95320536,  0.19292864]))"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test with 2 input nodes and 3 output nodes\n",
    "\n",
    "test_samples = np.array([[.1,.2], [.4,.5]])\n",
    "test_labels = np.array([[1,0,0], [0,0,1]])  #notice one-hot encoded\n",
    "\n",
    "from_scratch_flex(test_samples, test_labels, hypers={'epochs':10, 'cost-reporting': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Nm3U0AmZr7S"
   },
   "source": [
    "Note that I am printing the total cost above. The total cost is the simple sum of the cost of each of the output nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6gypdq5nDUSX"
   },
   "outputs": [],
   "source": [
    "def ann_flex_predictor(sample, weights, biases):\n",
    "  fsig = np.vectorize(sigmoid)\n",
    "  \n",
    "  #do forward propogation\n",
    "  raw = sample.dot(weights)\n",
    "  full_raw = np.add(raw, biases)\n",
    "  final_output = fsig(full_raw) #an array of values for output nodes\n",
    "\n",
    "  return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hR2qgzDSHJAq"
   },
   "source": [
    "Just copying weights and biases from above. And made up test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "myRYghzqFSZY",
    "outputId": "4d10f0b4-72af-4005-8d6e-ec4cbd5990a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46802724, 0.22701469, 0.57531103])"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_flex_predictor(np.array([.2,.3]), np.array([[-0.40240815, -0.33955348,  0.31486134], [-0.3574284 , -0.68043077,  0.15884282]]), np.array([ 0.05964438, -0.95320536,  0.19292864]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BbQzF8zMaFMt"
   },
   "source": [
    "Is that a good answer for the 3 ouput nodes? Who knows :) It is just a made up example. We can try something more realistic in a minute.\n",
    "<p>\n",
    "  Finally, we can define a tester that will produce the list of predictions that go with the list of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9k2ctMvBEPX6"
   },
   "outputs": [],
   "source": [
    "\n",
    "def ann_flex_tester(samples,  weights, biases):\n",
    "  \n",
    "  predictions = [ann_flex_predictor(s, weights, biases) for s in samples] #an array of arrays\n",
    "  \n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZKbQOt2cseo"
   },
   "outputs": [],
   "source": [
    "predictions = ann_flex_tester(np.array([[.2,.3], [.3, .4], [.4,.5]]), np.array([[-0.40240815, -0.33955348,  0.31486134], [-0.3574284 , -0.68043077,  0.15884282]]), np.array([ 0.05964438, -0.95320536,  0.19292864]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "pbDdnfB-dYNW",
    "outputId": "fd5a0783-99f8-4ef7-fbd1-e57e64724bb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.46802724, 0.22701469, 0.57531103]),\n",
       " array([0.44916391, 0.20961565, 0.58684167]),\n",
       " array([0.43044567, 0.1932168 , 0.59827785])]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UUaifWJQB4qx"
   },
   "source": [
    "From this point I could get the labels and comare predictions against them. Given this is a toy example, it won't make much sense. Let's look at a more realistic example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "buQNFD36COkG"
   },
   "source": [
    "<h2>Another test case for your code</h2>\n",
    "<p>\n",
    "  Let's look at one of the iconic data sets for deep learning. I like it because it shows that virtually any kind of data can be a target for an ANN. The data set is the pixels from a large set of hand-drawn digits, 0 through 9. Each image is 28 by 28 pixels. Each pixel will have a value between 0 and 255 to denote the grayscale of that pixel.\n",
    "  <p>\n",
    "    The base data set has 60,000 training images and 10,000 testing images. We are going to cut that down to 1,000 each. We will also normalize the pixel value. Here is the cool part. The whole thing has been packaged up by a package called keras. Check out the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jx31dgFZnJyf",
    "outputId": "33845d1e-7b01-4bb6-86eb-d5e71e23568c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NYnIiy-2EgDB"
   },
   "source": [
    "We now have a training set (x_train, y_train) and a test set (x_test, y_test). Let's do some more wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPT6tMZVEfEd"
   },
   "outputs": [],
   "source": [
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28) / 255,\n",
    "                  y_train[0:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDa8tQ3ZENC-"
   },
   "source": [
    "So `images` is our feature set and `labels` are our labels. Note that I have flattened out the 28 by 28 matrix into a single vector of 784. So I will have 784 input nodes. I also normalized the values by dividing by the max, 255. I also chopped down to 1000 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Yw5YmjGeneFL",
    "outputId": "858ed93b-9980-4ba0-9443-0f4899051002"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 784)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oGLiGoyvItsh"
   },
   "source": [
    "Let's look some of the pixel values in the first image, which we will see later is a hand-written 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "id": "M018ksFjAAOt",
    "outputId": "8d9d5f29-3fff-4fdf-f9c6-5cf12991c62d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0][:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHXw1MCBJFZn"
   },
   "source": [
    "Wrangle the labels next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fPqNVnRnrcrK",
    "outputId": "3f1c9f9a-9afa-4b66-e40f-106f3185c415"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XgPAb4evrtpM",
    "outputId": "aa9fc86f-a462-4ae2-eb4b-9d35bbb5d744"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OhWKonF_FsRW"
   },
   "source": [
    "This is not ideal for ANN output. It is true we would only need one output node the way things are. It would spit out values between 0 and 9. We will find it better to one-hot encode the labels (CIS472), giving us 10 output nodes per image. Let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "B_PkCMY1nbIB",
    "outputId": "1c9b219b-17c2-4ea2-9a6e-ff39c419bac1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "for i,l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lj72yt65GjeN"
   },
   "source": [
    "We now have labels with 10 values per sample. Let's look at first. We should all 0s except for a 1 in the 6th position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H6pPH3PtGhje",
    "outputId": "052f6053-c17d-48de-bf8c-ca343846b83e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]  #the ohe of 5 from range 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RjLGzV5RHaXb"
   },
   "source": [
    "Do same thing for test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z-bB5oYJr1gc",
    "outputId": "1494f540-359e-47c4-b699-b8e957d4df43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i,l in enumerate(y_test):\n",
    "  test_labels[i][l] = 1\n",
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6wsxfyNsHnSK"
   },
   "source": [
    "The digit 7, correct? This is cool: we have a way to visualize the actual 28 by 28 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "uP4nmfk2uPjj",
    "outputId": "9a91acb0-f17f-4885-fc00-b3ce4208ed69"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7+fkgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "first_image = x_test[0]\n",
    "pixels = first_image.reshape((28, 28))  #convert it back into the matrix form\n",
    "plt.imshow(pixels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "emFmHsrfpFt6"
   },
   "source": [
    "Here is a visualization of the ann we will build.\n",
    "<p>\n",
    "\n",
    "<img src='https://www.dropbox.com/s/20zwd4blrnaggrw/Screenshot%202019-03-03%2009.39.00.png?raw=1' width='300' height='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zdjos4_EJb55"
   },
   "source": [
    "Ok, I am ready for training. I am going to time this and show my results below. I started at 1000 epochs and worked my way up. I am including the result I got for 10,000 epochs. I did it before I started timing. It is close enough to 3,000 that I am just going to use that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hKGoLVF0KdH_"
   },
   "source": [
    "<pre>\n",
    "(1000, 0.056168013147983)\n",
    "elapsed time: 200.64850234985352  (with GPU 226.79888653755188). So much for GPU boosting performance!\n",
    "\n",
    "(2000, 0.04659837399874399)\n",
    "elapsed time: 447.965735912323\n",
    "\n",
    "(3000, 0.04401768636464867)\n",
    "elapsed time: 692.5456459522247\n",
    "\n",
    "(10000, 0.04400429181679943)\n",
    "A long time!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "pcJj2sU6vX6y",
    "outputId": "a808aa31-ad9e-41a3-ce28-fcafd1ae4074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.6193040115499521)\n",
      "(1000, 0.05616087601348139)\n",
      "(2000, 0.04659580009774936)\n",
      "(3000, 0.04401768636464867)\n",
      "elapsed time: 696.7748854160309\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "(model_weights, model_biases) = from_scratch_flex(images, one_hot_labels, hypers={'epochs':3000, 'cost-reporting': 1000})\n",
    "\n",
    "end = time.time()\n",
    "print('elapsed time: '+ str(end - start))  # in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "URLKMBEj-mfQ",
    "outputId": "bb16194b-2567-42ac-eb4c-03e9bbd8b1c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02509198,  0.09014286,  0.04639879,  0.0197317 , -0.06879627,\n",
       "        -0.0688011 , -0.08838328,  0.07323523,  0.020223  ,  0.04161452],\n",
       "       [-0.0958831 ,  0.09398197,  0.06648853, -0.05753218, -0.06363501,\n",
       "        -0.0633191 , -0.03915155,  0.00495129, -0.013611  , -0.04175417],\n",
       "       [ 0.02237058, -0.07210123, -0.04157107, -0.02672763, -0.008786  ,\n",
       "         0.05703519, -0.06006524,  0.00284689,  0.01848291, -0.09070992],\n",
       "       [ 0.02150897, -0.06589518, -0.08698968,  0.08977711,  0.09312641,\n",
       "         0.06167947, -0.03907725, -0.08046558,  0.03684661, -0.0119695 ],\n",
       "       [-0.07559235, -0.00096462, -0.0931223 ,  0.08186408, -0.048244  ,\n",
       "         0.03250446, -0.03765778,  0.0040136 ,  0.00934206, -0.06302911],\n",
       "       [ 0.09391693,  0.05502656,  0.08789979,  0.07896547,  0.01958   ,\n",
       "         0.08437485, -0.0823015 , -0.06080343, -0.09095454, -0.03493393],\n",
       "       [-0.02226454, -0.04573019,  0.0657475 , -0.02864933, -0.0438131 ,\n",
       "         0.00853922, -0.07181516,  0.0604394 , -0.08508987,  0.09737739],\n",
       "       [ 0.05444895, -0.06025686, -0.09889558,  0.06309229,  0.04137147,\n",
       "         0.04580143,  0.05425407, -0.08519107, -0.02830685, -0.07682619],\n",
       "       [ 0.07262069,  0.02465963, -0.0338204 , -0.08728833, -0.03780354,\n",
       "        -0.03496334,  0.04592124,  0.02751149,  0.07744255, -0.00555701],\n",
       "       [-0.07608115,  0.04264896,  0.05215701,  0.01225544,  0.05419344,\n",
       "        -0.00124088,  0.00454657, -0.0144918 , -0.09491617, -0.07842171]])"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights[:10][:10]  #out of a total of 784 x 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "n2NTXGSZ-zYB",
    "outputId": "d2d4e7d2-ddad-4789-8e47-b60317b21d32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.77871279, -0.57293872, -3.05380539, -3.07492339, -0.72955601,\n",
       "        0.05552463, -0.58926611, -0.69084225, -8.7103922 , -5.67148457])"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_biases  #10 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "xyN42O7QCkV4",
    "outputId": "1fd4cf23-27e2-45e2-f6e6-df66c9a2868e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([9.19811610e-06, 7.03891256e-19, 1.49362739e-06, 2.86423684e-06,\n",
       "        4.11103865e-09, 5.59917878e-09, 1.07389335e-18, 9.99999999e-01,\n",
       "        1.24395995e-06, 9.88044143e-10]),\n",
       " array([1.76403288e-04, 4.26054156e-14, 1.56935879e-02, 3.42238540e-07,\n",
       "        9.60528724e-20, 2.59065126e-02, 4.08372291e-02, 1.36667949e-24,\n",
       "        2.70159062e-10, 2.94848821e-10]),\n",
       " array([2.05976144e-10, 9.99990279e-01, 3.63423311e-04, 5.08178824e-04,\n",
       "        1.01339255e-09, 1.13162435e-09, 2.30406867e-04, 2.16070967e-04,\n",
       "        6.12980628e-07, 6.25444204e-06]),\n",
       " array([9.99704139e-01, 2.25596812e-22, 1.98534182e-13, 1.61686101e-21,\n",
       "        1.91259175e-20, 2.44881025e-08, 1.13259696e-10, 6.46448406e-05,\n",
       "        2.93523747e-12, 1.52114413e-32]),\n",
       " array([4.39031133e-09, 1.09730569e-10, 1.45262422e-07, 1.02526208e-11,\n",
       "        9.99912751e-01, 9.54376115e-16, 7.22668995e-05, 2.14774896e-06,\n",
       "        5.88261510e-05, 1.33513915e-07]),\n",
       " array([9.79143990e-13, 9.99845557e-01, 5.55447731e-05, 4.94764691e-05,\n",
       "        2.39636754e-10, 2.66794555e-12, 1.91242051e-08, 2.13856106e-03,\n",
       "        1.32493727e-05, 1.13064482e-05]),\n",
       " array([9.10300985e-11, 3.31683317e-12, 2.17496997e-14, 5.35781440e-07,\n",
       "        9.99929648e-01, 4.32599058e-02, 1.79464463e-10, 1.11051972e-13,\n",
       "        1.02891154e-05, 1.47023994e-01]),\n",
       " array([8.65348468e-16, 9.91486118e-07, 6.46203975e-15, 3.30175628e-05,\n",
       "        2.36944437e-07, 2.71323232e-10, 2.16506875e-05, 2.55740289e-05,\n",
       "        1.71555190e-08, 9.99210634e-01]),\n",
       " array([7.60599415e-07, 1.53878199e-05, 9.97567875e-01, 3.64275052e-23,\n",
       "        4.25365604e-07, 2.04393061e-11, 2.09193992e-04, 3.32639954e-21,\n",
       "        6.97757093e-10, 1.96058379e-13]),\n",
       " array([1.33764143e-11, 4.19545465e-19, 1.70807960e-18, 3.27214008e-16,\n",
       "        1.01330427e-07, 2.91474906e-11, 7.04656074e-12, 3.61953695e-05,\n",
       "        2.38828293e-10, 2.04652330e-02])]"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = ann_flex_tester(test_images, model_weights, model_biases)  #notice I am using test images\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4M3mpI7RUmTB"
   },
   "source": [
    "I am going to convert preds from one-hot to actual value by taking the index of the largest value in the 10 outputs. The `numpy argmax` function does what I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Fjnm6MCSVZp9",
    "outputId": "4f594710-be1c-4c5e-f742-db9e425c2c55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 6, 1, 0, 4, 1, 4, 9, 2, 9]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_values = [np.argmax(p) for p in preds]\n",
    "preds_values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "WC8McswcTEGF",
    "outputId": "3b514b36-30a8-483e-b31d-7180b1e5c83c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 7),\n",
       " (6, 2),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (4, 4),\n",
       " (1, 1),\n",
       " (4, 4),\n",
       " (9, 9),\n",
       " (2, 5),\n",
       " (9, 9)]"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped = list(zip(preds_values, y_test[0:1000]))  #notice I am using test labels\n",
    "zipped[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z4x6SjIUTJLu",
    "outputId": "a25c5ce1-0965-45e4-ea05-f736bfa46d0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.817"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 if p==a else 0 for p,a in zipped])/len(zipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vy-AsxFpZzFX"
   },
   "source": [
    "So we trained on training set and tested on test set. And we had an accuracy of roughly 82%.\n",
    "<p>\n",
    "  Just to hammer home the problem of overfitting the training set, let's try predictions on the training set, i.e., we will train and test on the same set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "mNVyU3OPYH7s",
    "outputId": "7471cbb6-ffcc-462f-d14b-051fed97e98e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.11345678e-09, 4.33374830e-11, 9.98334386e-13, 2.60037746e-03,\n",
       "        5.19008564e-19, 9.99173758e-01, 1.35544856e-14, 5.36775063e-10,\n",
       "        3.35914995e-09, 4.43281353e-15]),\n",
       " array([9.99989827e-01, 4.78666452e-15, 1.59875063e-14, 7.41391817e-14,\n",
       "        8.73029393e-22, 3.97064913e-07, 4.66784235e-13, 1.20244147e-10,\n",
       "        2.07994186e-06, 6.54517209e-25]),\n",
       " array([3.60157203e-09, 2.19467761e-07, 1.04602211e-06, 2.84108102e-03,\n",
       "        9.99995386e-01, 7.31099099e-09, 3.32690929e-06, 3.63405363e-08,\n",
       "        1.10473050e-08, 9.10238975e-12]),\n",
       " array([1.06462088e-08, 9.99821303e-01, 4.44888422e-04, 9.63394785e-07,\n",
       "        7.85069815e-08, 7.71352029e-12, 1.01459405e-07, 3.39311656e-06,\n",
       "        2.96709640e-05, 1.43966335e-14]),\n",
       " array([3.20066980e-12, 8.37260139e-09, 3.99946269e-14, 3.46562416e-16,\n",
       "        4.00481952e-05, 7.23599716e-10, 4.10524393e-12, 4.37919873e-05,\n",
       "        3.50278674e-05, 9.99354783e-01]),\n",
       " array([4.04781034e-07, 2.24468560e-16, 9.95112977e-01, 1.77813796e-16,\n",
       "        2.87034705e-17, 2.55819290e-08, 6.33451550e-12, 5.64267631e-08,\n",
       "        2.83264935e-09, 3.56239393e-04]),\n",
       " array([2.09197158e-18, 9.99999787e-01, 4.40719445e-07, 6.17209990e-05,\n",
       "        9.03024918e-13, 2.11918318e-08, 7.56766065e-08, 2.48569431e-10,\n",
       "        1.96161666e-09, 2.61466758e-09]),\n",
       " array([1.34902117e-07, 1.24360763e-17, 1.55675749e-05, 9.99999973e-01,\n",
       "        5.11684326e-14, 5.75649099e-11, 6.04933072e-23, 7.26106538e-16,\n",
       "        2.60763349e-09, 8.25419750e-08]),\n",
       " array([3.35411940e-11, 9.99885387e-01, 9.47678540e-09, 3.45845694e-05,\n",
       "        7.45481932e-10, 4.30458562e-04, 4.98363313e-06, 2.44611648e-03,\n",
       "        3.88815090e-03, 1.91010964e-06]),\n",
       " array([9.06568436e-09, 1.57147577e-08, 4.67059727e-10, 3.77334627e-11,\n",
       "        9.99999983e-01, 3.35191037e-07, 1.16746705e-08, 6.99943243e-12,\n",
       "        1.13072585e-08, 3.27154681e-08])]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = ann_flex_tester(images, model_weights, model_biases)  #notice using images which is training data\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Dqs_zGzfYH7w",
    "outputId": "0fb4cfa9-1b25-432f-9fb2-8d9b94789a10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 0, 4, 1, 9, 2, 1, 3, 1, 4]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_values = [np.argmax(p) for p in preds]\n",
    "preds_values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "znGmRdsvYH75",
    "outputId": "2920f0ba-3cb7-4da6-93f3-1b7950fef93d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 5),\n",
       " (0, 0),\n",
       " (4, 4),\n",
       " (1, 1),\n",
       " (9, 9),\n",
       " (2, 2),\n",
       " (1, 1),\n",
       " (3, 3),\n",
       " (1, 1),\n",
       " (4, 4)]"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped = list(zip(preds_values, y_train[:1000]))  #notice using labels from training set\n",
    "zipped[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Qz0ZzTBIYH7_",
    "outputId": "62ed6155-87e4-4c1e-8800-28e7119cdfcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 if p==a else 0 for p,a in zipped])/len(zipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XJMuKNDgabg_"
   },
   "source": [
    "Uh, kind of a big difference. Which is more realistic? The 82% from testing set. The 96% is a outcome of us overfitting the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ceOJcSWxEQJ-"
   },
   "source": [
    "<hr>\n",
    "<h1>Write it out</h1>\n",
    "<div class=h1_cell>\n",
    "\n",
    "You will need the 4 new flex functions, `ann_flex`, `from_scratch_flex`, `ann_flex_predictor` and `ann_flex_tester` for the final exam. Easiest is to just add them to your library then import them on the in-class final.\n",
    "  <p>\n",
    "    I decided to name my new library `library_w19_deep_2.py`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnemLc3wlAPx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NMP7x5idOyW"
   },
   "source": [
    "<h1>Closing notes</h1>\n",
    "\n",
    "When we start building models for the MNIST digits, we are working on the same problems that researchers in the deep learning field are working on. In particular, image analysis is huge at the moment. Think of face-recognition or cameras on self-driving cars. What we did not get to is the next level up in complexity for our ANNs. This comes in two forms. First, someone had a big idea of adding more node-levels between the input nodes and output nodes. They called them hidden levels. They are not really hidden. We can see what is going on with them. Check this out.\n",
    "<p>\n",
    "  <img src='https://api.ning.com/files/ZPzAct5-edBSzPfgsOgtMdL-fcUYWnyqd0Wou8Wqok-DgBFbc4ZbFHKPRl3F9ho49QbIzuuzXQgUaC2Z-pJRMfQlA0wM0dY3/ANNDiagram.png' height=\"300\" width=\"300\">\n",
    "  <p>The good news that nothing new is really going on. There are still weights on links. The nodes still use an activation function. Forward propogation is the same. Backward propogation is mostly the same, just more complicated propogating back all the way to weights on links from input. But still quite mechanical. And because it is so mechanical, it is trivial to add new hidden layers to your heart's content. How many should you add? Excellent question. The number of hidden layers and the number of nodes in each layer, become new hyper-parameters (CIS472).\n",
    "    <p>\n",
    "      The second big thing is that someone noticed that if you treat each pixel as independent, you are losing context information. So the pixels are not really independent. They are made up of lines and curves. And above that, eyes and ears, etc. So the hot thing now are what are called convolutional nets or CONV nets or CNN. Here is a visualization.\n",
    "      <p>\n",
    "        <img src='https://www.dropbox.com/s/0paldnl1ke76kxi/Screenshot%202019-03-08%2015.01.41.png?raw=1' height=\"300\" width=\"350\">\n",
    "      <p>\n",
    "        You move a filter along the image and take the average value of all the pixels in the filter. That becomes the actual input to your ANN. You can see in the picture above I can slide the 2by2 filter 1 step along horizontal axis and 1 step along vertical axis. And I can do that twice, giving me 9 different filter values. I store that info in a matrix of 3by3. The cute thing is that you can add a sequence of these filtering layers in. If you are lucky, the first filters will pick up basic picture information. Later filters will start recognizing, lines and curves. The final filters might be specialists in finding eyes and nose. In essence, you get a set of specialists that find certain features in the image.\n",
    "        <p>\n",
    "          I expect the department will be adding more and more deep learning courses: it is one of our focus areas. Keep an eye out for them."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "final_takehome_w19.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
