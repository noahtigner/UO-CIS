{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CcejYk1YkV0f"
   },
   "source": [
    "<h1>\n",
    "<center>\n",
    "Midterm 2\n",
    "</center>\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "There are 2 parts on the midterm, 50 points each. Each part has 3 questions. There is also an extra credit problem at the end.\n",
    "<p>\n",
    "We will use the Titanic table for this midterm. I have a wrangled version of it on google sheets that I set up for you.\n",
    "<p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vkh1bqA3kV0m"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "titanic_table = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vR2XbLnUuYlxaFMdS8_bBX3iKUIDEii6Lg5Rxesf-Oh8a6z8-vAN6UDGejaOrBg5130h4O_dLkecKWQ/pub?output=csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uScGH6USkV0r"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "5AEsijjqF3JH",
    "outputId": "56b17d16-228d-4e2e-d375-9335c2b8d4af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>no_age</th>\n",
       "      <th>filled_age</th>\n",
       "      <th>emb_C</th>\n",
       "      <th>emb_Q</th>\n",
       "      <th>emb_S</th>\n",
       "      <th>emb_nan</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>age_Child</th>\n",
       "      <th>age_Adult</th>\n",
       "      <th>age_Senior</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ok_child</th>\n",
       "      <th>pclass_1</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "      <th>pclass_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                     Name   Sex   Age  SibSp  Parch  \\\n",
       "0         0       3  Braund, Mr. Owen Harris  male  22.0      1      0   \n",
       "\n",
       "      Ticket  Fare Cabin Embarked  no_age  filled_age  emb_C  emb_Q  emb_S  \\\n",
       "0  A/5 21171  7.25   NaN        S       0        22.0      0      0      1   \n",
       "\n",
       "   emb_nan age_bin  age_Child  age_Adult  age_Senior  sex_female  sex_male  \\\n",
       "0        0   Child          1          0           0           0         1   \n",
       "\n",
       "   ok_child  pclass_1  pclass_2  pclass_3  pclass_nan  \n",
       "0         0         0         0         1           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_table.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8aUB0VpgqXA"
   },
   "outputs": [],
   "source": [
    "!rm library_w19_week7.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "dnHr-TA6gvK5",
    "outputId": "6c973436-a54c-4bf3-93f5-06f301fda288"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-f5fb0da9-4018-48d6-a0c1-68276f25c43c\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-f5fb0da9-4018-48d6-a0c1-68276f25c43c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving library_w19_week7.py to library_w19_week7.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'library_w19_week7.py': b'import random\\nimport numpy as np\\nfrom functools import reduce\\nfrom types import SimpleNamespace\\nimport pandas as pd\\n\\ndef predictor_case(row, pred, target):\\n  case_dict = {(0,0): \\'true_negative\\', (1,1): \\'true_positive\\', (0,1): \\'false_negative\\', (1,0): \\'false_positive\\'}\\n  actual = row[target]\\n  prediction = row[pred]\\n  case = case_dict[(prediction, actual)]\\n  return case\\n\\ndef accuracy(cases):\\n  if \\'true_positive\\' in cases:\\n    tp = cases[\\'true_positive\\']\\n  else: tp = 0\\n  if \\'true_negative\\' in cases: \\n    tn = cases[\\'true_negative\\']\\n  else: tn = 0\\n  if \\'false_positive\\' in cases: \\n    fp = cases[\\'false_positive\\']\\n  else: fp = 0\\n  if \\'false_negative\\' in cases:\\n    fn = cases[\\'false_negative\\']\\n  else: fn = 0\\n  total = tp + tn + fp + fn\\n  if (total > 0):\\n    return (tp + tn)/(tp+tn+fp+fn)\\n  else: return 0\\n\\ndef f1(cases):\\n\\n   #the heart of the matrix\\n  if \\'true_positive\\' in cases:\\n   tp = cases[\\'true_positive\\']\\n  else: tp = 0\\n  if \\'true_negative\\' in cases: \\n    tn = cases[\\'true_negative\\']\\n  else: tn = 0\\n  if \\'false_positive\\' in cases: \\n    fp = cases[\\'false_positive\\']\\n  else: fp = 0\\n  if \\'false_negative\\' in cases:\\n    fn = cases[\\'false_negative\\']\\n  else: fn = 0\\n  #other measures we can derive\\n  totpos = tp+fn\\n  if totpos > 0: \\n    recall = 1.0*tp/(tp+fn)  # positive correct divided by total positive in the table\\n  else: recall = 0\\n  pospred = tp + fp\\n  if pospred > 0:\\n    precision = 1.0*tp/(tp+fp) # positive correct divided by all positive predictions made\\n  else: precision = 0\\n  #now for the one we want\\n  if recall == 0 and precision == 0: \\n    f1 = 0\\n  elif recall == 0 and precision > 0: \\n    f1 = 2/(1/precision)\\n  elif recall > 0 and precision == 0: \\n    f1 = 2/(1/recall)\\n  else:\\n    f1 = 2/(1/recall + 1/precision)\\n  return f1\\n\\ndef informedness(cases):\\n  if \\'true_positive\\' in cases:\\n    tp = cases[\\'true_positive\\']\\n  else: tp = 0\\n  if \\'true_negative\\' in cases: \\n    tn = cases[\\'true_negative\\']\\n  else: tn = 0\\n  if \\'false_positive\\' in cases: \\n    fp = cases[\\'false_positive\\']\\n  else: fp = 0\\n  if \\'false_negative\\' in cases:\\n    fn = cases[\\'false_negative\\']\\n  else: fn = 0\\n  totpos = tp+fn\\n  if totpos > 0:\\n    recall = 1.0*tp/(tp+fn)  # positive correct divided by total positive in the table\\n  else: recall = 0\\n  totneg = tn + fp\\n  if totneg > 0:\\n    specificty = 1.0*tn/(tn+fp) # negative correct divided by total negative in the table\\n  else: specificty = 0\\n  J = (recall + specificty) - 1\\n  return J\\n\\ndef probabilities(counts):\\n    count_0 = 0 if 0 not in counts else counts[0]  #could have no 0 values\\n    count_1 = 0 if 1 not in counts else counts[1]\\n    total = count_0 + count_1\\n    probs = (0,0) if total == 0 else (count_0/total, count_1/total)  #build 2-tuple\\n    return probs\\n\\ndef gini(counts):\\n    (p0,p1) = probabilities(counts)\\n    sum_probs = p0**2 + p1**2\\n    gini = 1 - sum_probs\\n    return gini\\n\\ndef gig(starting_table, split_column, target_column):\\n    \\n    #split into two branches, i.e., two sub-tables\\n    true_table = starting_table.loc[starting_table[split_column] == 1]\\n    false_table = starting_table.loc[starting_table[split_column] == 0]\\n    \\n    #Now see how the target column is divided up in each sub-table (and the starting table)\\n    true_counts = true_table[target_column].value_counts()  # Note using true_table and not starting_table\\n    false_counts = false_table[target_column].value_counts()  # Note using false_table and not starting_table\\n    starting_counts = starting_table[target_column].value_counts() \\n    \\n    #compute the gini impurity for the 3 tables\\n    starting_gini = gini(starting_counts)\\n    true_gini = gini(true_counts)\\n    false_gini = gini(false_counts)\\n\\n    #compute the weights\\n    starting_size = len(starting_table.index)\\n    true_weight = 0.0 if starting_size == 0 else len(true_table.index)/starting_size\\n    false_weight = 0.0 if starting_size == 0 else len(false_table.index)/starting_size\\n    \\n    #wrap it up and put on a bow\\n    gig = starting_gini - (true_weight * true_gini + false_weight * false_gini)\\n    \\n    return gig\\n    \\ndef build_pred(column, branch):\\n    return lambda row: row[column] == branch\\n\\ndef find_best_splitter(table, choice_list, target):\\n  \\n    assert (len(table)>0),\"Cannot split empty table\"\\n    assert (target in table),\"Target must be column in table\"\\n    \\n    gig_scores = map(lambda col: (col, gig(table, col, target)), choice_list)  #compute tuple (col, gig) for each column\\n    gig_sorted = sorted(gig_scores, key=lambda item: item[1], reverse=True)  # sort on gig\\n    return gig_sorted\\n\\nfrom functools import reduce\\n\\ndef generate_table(table, conjunction):\\n  \\n    assert (len(table)>0),\"Cannot generate from empty table\"\\n\\n    sub_table = reduce(lambda subtable, pair: subtable.loc[pair[1]], conjunction, table)\\n    return sub_table\\n\\ndef compute_prediction(table, target):\\n  \\n    assert (len(table)>0),\"Cannot predict from empty table\"\\n    assert (target in table),\"Target must be column in table\"\\n    \\n    counts = table[target].value_counts()  # counts looks like {0: v1, 1: v2}\\n\\n    if 0 not in counts:\\n        prediction = 1\\n    elif 1 not in counts:\\n        prediction = 0\\n    elif counts[1] > counts[0]:  # ties go to 0 (negative)\\n        prediction = 1\\n    else:\\n        prediction = 0\\n\\n    return prediction\\n  \\n\\ndef build_tree_iter(table, choices, target, hypers={} ):\\n\\n    assert (len(choices)>0),\"Must have at least one column in choices\"\\n    assert (target in table), \"Target column not in table\"\\n    assert (len(table) > 1), \"Table must have more than 1 row\"\\n    \\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(4, len(choices))\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\n    \\n    def iterative_build(k):\\n        columns_sorted = find_best_splitter(table, choices, target)\\n        (best_column, gig_value) = columns_sorted[0]\\n        \\n        #Note I add _1 or _0 to make it more readable for debugging\\n        current_paths = [{\\'conjunction\\': [(best_column+\\'_1\\', build_pred(best_column, 1))],\\n                          \\'prediction\\': None,\\n                          \\'gig_score\\': gig_value},\\n                         {\\'conjunction\\': [(best_column+\\'_0\\', build_pred(best_column, 0))],\\n                          \\'prediction\\': None,\\n                          \\'gig_score\\': gig_value}\\n                        ]\\n        k -= 1  # we just built a level as seed so subtract 1 from k\\n        tree_paths = []  # add completed paths here\\n        \\n        while k>0:\\n            new_paths = []\\n            for path in current_paths:\\n                old_conjunction = path[\\'conjunction\\']  # a list of (name, lambda)\\n                before_table = generate_table(table, old_conjunction)  #the subtable the current conjunct leads to\\n                columns_sorted = find_best_splitter(before_table, choices, target)\\n                (best_column, gig_value) = columns_sorted[0]\\n                if gig_value > gig_cutoff:\\n                    new_path_1 = {\\'conjunction\\': old_conjunction + [(best_column+\\'_1\\', build_pred(best_column, 1))],\\n                                \\'prediction\\': None,\\n                                 \\'gig_score\\': gig_value}\\n                    new_paths.append( new_path_1 ) #true\\n                    new_path_0 = {\\'conjunction\\': old_conjunction + [(best_column+\\'_0\\', build_pred(best_column, 0))],\\n                                \\'prediction\\': None,\\n                                 \\'gig_score\\': gig_value}\\n                    new_paths.append( new_path_0 ) #false\\n                else:\\n                    #not worth splitting so complete the path with a prediction\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\n                    tree_paths.append(path)\\n            #end for loop\\n            \\n            current_paths = new_paths\\n            if current_paths != []:\\n                k -= 1\\n            else:\\n                break  # nothing left to extend so have copied all paths to tree_paths\\n        #end while loop\\n\\n        #Generate predictions for all paths that have None\\n        for path in current_paths:\\n            conjunction = path[\\'conjunction\\']\\n            before_table = generate_table(table, conjunction)\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\n            tree_paths.append(path)\\n        return tree_paths\\n\\n    return {\\'paths\\': iterative_build(k), \\'weight\\': None}\\n\\n\\ndef tree_predictor(row, tree):\\n    \\n    #go through each path, one by one (could use a map instead of for loop?)\\n    for path in tree[\\'paths\\']:\\n        conjuncts = path[\\'conjunction\\']\\n        result = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\n        if all(result):\\n            return path[\\'prediction\\']\\n    raise LookupError(\\'No true paths found for row: \\' + str(row))\\n\\ndef path_id(row, tree):\\n  assert (len(tree[\\'paths\\']) > 0), \"Tree must have at least one path\"\\n  counter = 0 # a counter to keep track of current index\\n  for path in tree[\\'paths\\']: \\n    boolean_list = map(lambda pair: pair[1](row), path[\\'conjunction\\'])\\n    b = list(boolean_list)\\n    if (all(b)): \\n      return counter\\n    else: counter+=1\\n\\ndef reorder_paths(table, tree):\\n  count = table.apply(lambda row: path_id(row, tree), axis=1)  # get the counts\\n  pdict = dict(count.value_counts())#convert to dict\\n  newl = list(pdict.items())#convert to list\\n  newl.sort(key=lambda tup: tup[1],reverse=True) #sort the list of paths\\n  paths = map(lambda f: tree[\\'paths\\'][f[0]] , newl)\\n  return(list(paths))\\n\\ndef compute_training(slices, left_out):\\n    training_slices = []\\n    for i,slice in enumerate(slices):\\n        if i == left_out:\\n            continue\\n        training_slices.append(slices[i])\\n    return pd.concat(training_slices)  # note we are returning a table (DataFrame)\\n\\ndef produce_scores(table, tree, target):\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: tree_predictor(row, tree), axis=1)\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\n    vc = cases.value_counts()\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\n\\ndef k_fold(table, k, target, hypers, candidate_columns):  \\n    #set up the table where we will record fold results\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\n    \\n    #generate the slices\\n    total_len = len(table.index)\\n    slice_size = int(total_len/(1.0*k))\\n    slices = []\\n    for i in range(k-1):\\n        a_slice =  table[i*slice_size:(i+1)*slice_size]\\n        slices.append( a_slice )\\n    slices.append( table[(k-1)*slice_size:] )  # whatever is left\\n    \\n    #generate test results\\n    all_scores = []  #keep track of all k results\\n    for i in range(k):\\n        test_table = slices[i]\\n        train_table = compute_training(slices, i)\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\n        results_row = {\\'name\\': \\'fold_\\'+str(i), \\'accuracy\\': scores[0], \\'f1\\': scores[1], \\'informedness\\': scores[2]}\\n        k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\n        all_scores.append(scores)\\n    \\n    #compute average of all folds\\n    avg_scores = tuple(reduce(lambda total, triple: np.add(triple, total), all_scores)/k)\\n    results_row = {\\'name\\': \\'average\\', \\'accuracy\\': avg_scores[0], \\'f1\\': avg_scores[1], \\'informedness\\': avg_scores[2]}\\n    k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\n    \\n    #note that I add the meta comment as last step to avoid it being wiped out\\n    k_fold_results_table.meta = SimpleNamespace()\\n    k_fold_results_table.meta.hypers  = hypers # adds comment to remind me of hyper params used\\n    \\n    return k_fold_results_table\\n\\n#Determine if slices are mutually exclusive\\ndef verify_unique(slices):\\n    print((\\'total length all slices\\', sum([len(s) for s in slices])))\\n    for i, a_slice in enumerate(slices[:-1]):\\n        a_set = set(a_slice.index)\\n        for j, b_slice in enumerate(slices[i+1:]):\\n            b_set = set(b_slice.index)\\n            int_set = a_set.intersection(b_set)  # should be empty set as result\\n            print((i,j+i+1,int_set))\\n    return None\\n\\ndef k_fold_random(table, k, target, hypers, candidate_columns):\\n    \\n    #set up the table where we will record fold results\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\n  \\n    total_len = len(table.index)\\n    split_size = int(total_len/(1.0*k))\\n    slices = []\\n    used = []\\n\\n    #generate the slices\\n    \\n    for i in range(k-1):\\n      ctr = 0\\n      a_slice = []\\n      while ctr < split_size:\\n        ind = random.randint(0,total_len-1) # get a random index\\n        if ind not in used:\\n          # get the row corresponding to that index in table\\n          row = table.loc[ind]\\n          #add the row to the slice list\\n          a_slice.append(row)\\n          # add the index to the used list and increment counter\\n          used.append(ind)\\n          ctr +=1\\n      # make new subtable with slice list\\n      kslice = pd.DataFrame(a_slice)\\n      # add table to slices list\\n      slices.append(kslice)\\n    lslice = []\\n    # this is for the remaining indices because there may be less than split_size in last slice\\n    while len(used) != total_len:\\n      ind = random.randint(0,total_len-1) # get a random index\\n      if ind not in used:\\n        # get the row corresponding to that index in table\\n        row = table.loc[ind]\\n        #add the row to the slice list\\n        lslice.append(row)\\n        # add the index to the used list\\n        used.append(ind)\\n    # make new subtable with last slice list and add to slices\\n    last = pd.DataFrame(lslice)\\n    slices.append(last)\\n    \\n    verify_unique(slices)\\n    \\n    all_scores = []  #keep track of all k results\\n    for i in range(k):\\n        test_table = slices[i]\\n        train_table = compute_training(slices, i)\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\n        results_row = {\\'name\\': \\'fold_\\'+str(i), \\'accuracy\\': scores[0], \\'f1\\': scores[1], \\'informedness\\': scores[2]}\\n        k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\n        all_scores.append(scores)\\n    \\n    #compute average of all folds\\n    avg_scores = tuple(reduce(lambda total, triple: np.add(triple, total), all_scores)/k)\\n    results_row = {\\'name\\': \\'average\\', \\'accuracy\\': avg_scores[0], \\'f1\\': avg_scores[1], \\'informedness\\': avg_scores[2]}\\n    k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\n    \\n    #note that I add the meta comment as last step to avoid it being wiped out\\n    k_fold_results_table.meta = SimpleNamespace()\\n    k_fold_results_table.meta.hypers  = hypers # adds comment to remind me of hyper params used\\n    \\n    \\n    return k_fold_results_table\\n\\n\\ndef vote_taker(row, forest):\\n    votes = {0:0, 1:0}\\n    for tree in forest:\\n        prediction = tree_predictor(row, tree)\\n        votes[prediction] += 1\\n    winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\\n    return winner\\n\\ndef forest_scores(table, forest, target):\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: vote_taker(row, forest), axis=1)  #only change is to call vote_taker\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\n    vc = cases.value_counts()\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\n\\n\\ndef forest_builder(table, column_choices, target, hypers):\\n\\n    tree_n = 5 if \\'total-trees\\' not in hypers else hypers[\\'total-trees\\']\\n    m = int(len(column_choices)**.5) if \\'m\\' not in hypers else hypers[\\'m\\']\\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(2, len(column_choices))\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\n    rgen = hypers[\\'random-state\\'] if \\'random-state\\' in hypers else 0  #an int will work as seed with the sample method.\\n\\n    #build a single tree of depth n - call it multiple times to build multiple trees\\n    def iterative_build(n):\\n        train = table.sample(frac=1.0, replace=True, random_state=rgen)\\n        train = train.reset_index()\\n        left_out = table.loc[~table.index.isin(train[\\'index\\'])]\\n        left_out = left_out.reset_index() # this gives us the old index in its own column\\n        oob_list = left_out[\\'index\\'].tolist()  # list of row indices from original titanic table\\n        \\n        rcols = random.sample(column_choices, m)  # subspcace sampling - uses random.seed, not rng\\n        columns_sorted = find_best_splitter(train, rcols, target)\\n        (best_column, gig_value) = columns_sorted[0]\\n\\n        #Note I add _1 or _0 to make it more readable for debugging\\n        current_paths = [{\\'conjunction\\': [(best_column+\\'_1\\', build_pred(best_column, 1))],\\n                          \\'prediction\\': None,\\n                          \\'gig_score\\': gig_value},\\n                         {\\'conjunction\\': [(best_column+\\'_0\\', build_pred(best_column, 0))],\\n                          \\'prediction\\': None,\\n                          \\'gig_score\\': gig_value}\\n                        ]\\n        n -= 1  # we just built a level as seed so subtract 1 from n\\n        tree_paths = []  # add completed paths here\\n\\n        while n>0:\\n            new_paths = []\\n            for path in current_paths:\\n                conjunct = path[\\'conjunction\\']  # a list of (name, lambda)\\n                before_table = generate_table(train, conjunct)  #the subtable the current conjunct leads to\\n                rcols = random.sample(column_choices, m)  # subspace\\n                columns_sorted = find_best_splitter(before_table, rcols, target)\\n                (best_column, gig_value) = columns_sorted[0]\\n                if gig_value > gig_cutoff:\\n                    new_path_1 = {\\'conjunction\\': conjunct + [(best_column+\\'_1\\', build_pred(best_column, 1))],\\n                                \\'prediction\\': None,\\n                                 \\'gig_score\\': gig_value}\\n                    new_paths.append( new_path_1 ) #true\\n                    new_path_0 = {\\'conjunction\\': conjunct + [(best_column+\\'_0\\', build_pred(best_column, 0))],\\n                                \\'prediction\\': None,\\n                                 \\'gig_score\\': gig_value\\n                                 }\\n                    new_paths.append( new_path_0 ) #false\\n                else:\\n                    #not worth splitting so complete the path with a prediction\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\n                    tree_paths.append(path)\\n            #end for loop\\n\\n            current_paths = new_paths\\n            if current_paths != []:\\n                n -= 1\\n            else:\\n                break  # nothing left to extend so have copied all paths to tree_paths\\n        #end while loop\\n\\n        #Generate predictions for all paths that have None\\n        for path in current_paths:\\n            conjunct = path[\\'conjunction\\']\\n            before_table = generate_table(train, conjunct)\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\n            tree_paths.append(path)\\n        return (tree_paths, oob_list)\\n    \\n    #let\\'s build a forest\\n    forest = []\\n    for i in range(tree_n):\\n        (paths, oob) = iterative_build(k)  #always use k for now\\n        forest.append({\\'paths\\': paths, \\'weight\\': None, \\'oob\\': oob})\\n        \\n    return forest\\n\\n\\ndef oob_vote_taker(row, forest): \\n  votes = {0:0, 1:0, 2:0} # using 2 as the bin for when tree\\'s aren\\'t allowed to take a vote\\n  for tree in forest: \\n    if row.name in tree[\\'oob\\']: \\n      prediction = tree_predictor(row, tree)\\n      votes[prediction] += 1\\n    else: \\n      votes[2]+=1\\n  winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\\n  return winner\\n\\ndef oob_forest_scores(table, forest, target): \\n  \\n  oob_union = [] # empty list to contain the union of the oob lists for the trees in the forest  \\n  \\n  #populates oob_union\\n  for tree in forest: \\n    oob_union = list(set(oob_union) | set(tree[\\'oob\\']))\\n  \\n  #create a scratch table with only the rows from table that are in oob_union\\n  pass_table = table.loc[table.index.isin(oob_union)] # this is the subtable of table of rows that are in the union\\n  oob_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\n  oob_table[\\'prediction\\'] = pass_table.apply(lambda row: oob_vote_taker(row, forest), axis= 1)\\n  oob_table[\\'actual\\'] = pass_table[target]\\n  \\n  cases = oob_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\n  vc = cases.value_counts()\\n  return [accuracy(vc), f1(vc), informedness(vc)]\\n\\n#your code\\n\\nimport numpy as np\\nimport operator\\n\\ndef euclidean_distance(vector1, vector2): #vector 1 is the specific row we are predicting for (i) and vector2 is the whole table\\n  d = {}\\n  length = vector1.shape[1] # this returns the number of columns in the specific row we are testing for \\n  for x in range(len(vector2)) : \\n    if (x == vector1.index): \\n        continue\\n    else: \\n      distance = 0\\n      for y in range(length): \\n        distance += np.square(vector1.iloc[0,y] - vector2.iloc[x,y])\\n      d[x] = np.sqrt(distance)\\n  return d\\n\\ndef knn(row_index, table, columns,k, target):\\n  length = len(table) # get the length of the table\\n  distance = {} # an empty dictionary to hold the distances between the row index and all the other rows in table\\n  t= table[columns]\\n  distance = euclidean_distance(t.iloc[[row_index]], t)\\n  # sort the distances   \\n  sorted_dist = sorted(distance.items(), key=operator.itemgetter(1)) # returns a sorted list of tuples \\n  sorted_ind = [i[0] for i in sorted_dist] # we just need the indexes\\n  \\n  #gather votes from k rows \\n  votes = {0:0, 1:0}\\n  for x in range(k):\\n    row = table.iloc[sorted_ind[x]]\\n    vote = row[target]\\n    votes[vote] += 1\\n  winner = 1 if votes[1]>votes[0] else 0\\n  return winner  \\n\\ndef knn_tester(table, k, columns, target): \\n  scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\n  for x in range(len(table)):\\n    row = table.iloc[x]\\n    vote = knn(x,table,columns,k,target)\\n    scratch_table.at[x,\\'prediction\\'] = vote\\n    scratch_table.at[x,\\'actual\\'] = row[target]\\n  cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\n  vc = cases.value_counts()\\n  a = accuracy(vc)\\n  return a\\n\\n\\n\\n\\n'}"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "Il6HlbWggzMB",
    "outputId": "6cbe92ed-dfbf-4e0d-80df-f396878e9504"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t build_pred\t build_tree_iter\t compute_prediction\t compute_training\t euclidean_distance\t f1\t find_best_splitter\t forest_builder\t \n",
      "forest_scores\t generate_table\t gig\t gini\t informedness\t k_fold\t k_fold_random\t knn\t knn_tester\t \n",
      "oob_forest_scores\t oob_vote_taker\t path_id\t predictor_case\t probabilities\t produce_scores\t reorder_paths\t tree_predictor\t verify_unique\t \n",
      "vote_taker\t \n"
     ]
    }
   ],
   "source": [
    "from library_w19_week7 import *\n",
    "\n",
    "%who function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mYPJRcSZsznx"
   },
   "source": [
    "<h2>Columns used in all questions</h2>\n",
    "\n",
    "We will use 14 columns from the table to make predictions on `Survived`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3TDm9WllKCAv"
   },
   "outputs": [],
   "source": [
    "usable_columns = [\n",
    " 'emb_C',\n",
    " 'emb_Q',\n",
    " 'emb_S',\n",
    " 'emb_nan',\n",
    " 'age_Child',\n",
    " 'age_Adult',\n",
    " 'age_Senior',\n",
    " 'no_age',\n",
    " 'ok_child',\n",
    " 'sex_female',\n",
    " 'pclass_1',\n",
    " 'pclass_2',\n",
    " 'pclass_3',\n",
    " 'pclass_nan'\n",
    "]\n",
    "\n",
    "target = 'Survived'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "843csVX-py7C"
   },
   "source": [
    "<h1>\n",
    "Part 1. Explore random forest behavior\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "For prediction purposes, we have been treating a forest as a single predictor. It does call on its trees to get a prediction, but we don't see that. All we see is the final prediction. I'd like to dig deeper into individual tree behavior. I'll ask you to complete a set of programming problems to do this.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l9S58jH5py7D"
   },
   "source": [
    "<h2>\n",
    "Problem 1. Build a matrix of tree predictions (10 points)\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "The matrix will be a list of lists. Let's say the forest we are working with has 11 trees. Then the first list will be the predictions of the 11 trees for row 0 of the Titanic table, i.e., it will be a list of 11 binary values. The next list will be the 11 predictions for row 1 of the Titanic table. Given that we have 891 rows in the Titanic table, we will have 891 lists in our outer list.\n",
    "<p>\n",
    "Let's say I store my matrix in `all_trees`. Then `all_trees[i][j]` will represent the vote of the jth tree for row i.\n",
    "  <p>\n",
    "    Here is what you should see for the first 10 rows.\n",
    "<p>\n",
    "<pre>\n",
    "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    " [1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1],\n",
    " [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
    " [1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1],\n",
    " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    " [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    " [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
    " [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
    " [1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1]]\n",
    " </pre>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kr4hJ08Tpy7D"
   },
   "source": [
    "<h2>\n",
    "Here is forest to test on\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "  But first set random seeds so you get same results as mine.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NN01O5OJqioB"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rng = np.random.RandomState(24)  #Will pass as arg to pandas sample method\n",
    "random.seed(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GysL7AY8py7N",
    "outputId": "b8d719d0-1d75-4762-956d-79296d9d3a2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest11 = forest_builder(titanic_table, usable_columns, target, hypers={'total-trees':11, 'random-state':rng})\n",
    "len(forest11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHHWb3Vj2xns"
   },
   "source": [
    "Now build the matrix and check your results against mine above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "UjMSCnflpy7R",
    "outputId": "7edef6ac-b338-43bc-d1d4-da1ad3ed46fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1],\n",
       " [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       " [1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1]]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trees = []\n",
    "for i in range (len(titanic_table)):\n",
    "  rowpred = [];\n",
    "  for n,m in enumerate(forest11):\n",
    "    rowpred.append(tree_predictor(titanic_table.loc[i], m))\n",
    "  all_trees.append(rowpred)\n",
    "  \n",
    "all_trees[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jci-WoYQkV1E"
   },
   "source": [
    "<h1>\n",
    "Problem 2: The most correct tree (10 points)\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Produce an ordered list, from most correct to least correct, of the 11 trees taken over the 891 rows. A tree is correct if its prediction matches the `Survived` column in the target row. Here are my results.\n",
    "  <pre>\n",
    "[(2, 707),\n",
    " (1, 701),\n",
    " (10, 701),\n",
    " (4, 674),\n",
    " (6, 643),\n",
    " (7, 637),\n",
    " (3, 613),\n",
    " (0, 595),\n",
    " (5, 581),\n",
    " (8, 577),\n",
    " (9, 574)]\n",
    " </pre>\n",
    "  The winner is tree2. It was correct 707 out of 891 times.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "qOQr56-AWICk",
    "outputId": "aa90f436-3a8d-4e58-93aa-8baf3bcc13ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 707),\n",
       " (1, 701),\n",
       " (10, 701),\n",
       " (4, 674),\n",
       " (6, 643),\n",
       " (7, 637),\n",
       " (3, 613),\n",
       " (0, 595),\n",
       " (5, 581),\n",
       " (8, 577),\n",
       " (9, 574)]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctness = {}\n",
    "# initialize the dict to 0 for each tree's correctness count\n",
    "for i in range(len(forest11)):\n",
    "  correctness[i] = 0\n",
    "for i in range(len(titanic_table)):\n",
    "  row_preds = all_trees[i]\n",
    "  row_in_table = titanic_table.loc[i]\n",
    "  target_value = row_in_table[target]\n",
    "  for j in range(len(row_preds)):\n",
    "    if (row_preds[j] == target_value):\n",
    "      correctness[j]+=1\n",
    "\n",
    "sorted(correctness.items(), key=lambda pair: pair[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7e4hXgK9So7t"
   },
   "source": [
    "<h1>\n",
    "Problem 3: voting blocks (30 points)\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Taking trees pairwise, produce an ordered list of which trees vote the same (right or wrong) most often.\n",
    "  <p>\n",
    "    For each specific row:\n",
    "    <pre>\n",
    " 1. if (tree1,tree2) vote the same then I record that.\n",
    " 2. if (tree1,tree3) vote the same then I record that.\n",
    " etc\n",
    "</pre>\n",
    "I do that for the entire table. Here is first part of sorted list I got for forest11.\n",
    "<pre>\n",
    "[[((5, 8), 887),\n",
    " ((2, 10), 863),\n",
    " ((7, 10), 815),\n",
    " ((1, 4), 810),\n",
    " ((3, 10), 797),\n",
    " ((2, 7), 787),\n",
    " ((1, 6), 785),\n",
    " ((4, 6), 780),\n",
    " ((2, 3), 769),\n",
    " ((7, 9), 754)]\n",
    "</pre>\n",
    "  So tree5 and tree8 vote the same (right or wrong) 887 out of 891 times.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "colab_type": "code",
    "id": "6GbkATeMdZZE",
    "outputId": "49fd063f-492e-4d34-e54f-80343d76f372"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((5, 8), 887),\n",
       " ((2, 10), 863),\n",
       " ((7, 10), 815),\n",
       " ((1, 4), 810),\n",
       " ((3, 10), 797),\n",
       " ((2, 7), 787),\n",
       " ((1, 6), 785),\n",
       " ((4, 6), 780),\n",
       " ((2, 3), 769),\n",
       " ((7, 9), 754),\n",
       " ((1, 10), 747),\n",
       " ((3, 7), 721),\n",
       " ((1, 2), 719),\n",
       " ((6, 10), 711),\n",
       " ((2, 6), 695),\n",
       " ((3, 6), 685),\n",
       " ((4, 10), 680),\n",
       " ((9, 10), 680),\n",
       " ((3, 9), 678),\n",
       " ((5, 7), 675),\n",
       " ((1, 7), 671),\n",
       " ((7, 8), 671),\n",
       " ((2, 9), 668),\n",
       " ((0, 10), 661),\n",
       " ((2, 4), 656),\n",
       " ((0, 2), 655),\n",
       " ((1, 3), 653),\n",
       " ((2, 8), 651),\n",
       " ((2, 5), 647),\n",
       " ((6, 7), 643),\n",
       " ((3, 5), 633),\n",
       " ((3, 8), 629),\n",
       " ((5, 10), 627),\n",
       " ((8, 10), 623),\n",
       " ((0, 9), 610),\n",
       " ((4, 5), 610),\n",
       " ((4, 8), 606),\n",
       " ((4, 7), 604),\n",
       " ((6, 9), 598),\n",
       " ((3, 4), 596),\n",
       " ((0, 7), 585),\n",
       " ((8, 9), 568),\n",
       " ((0, 3), 567),\n",
       " ((6, 8), 565),\n",
       " ((5, 9), 564),\n",
       " ((5, 6), 561),\n",
       " ((1, 5), 553),\n",
       " ((1, 8), 549),\n",
       " ((1, 9), 546),\n",
       " ((0, 4), 538),\n",
       " ((0, 5), 521),\n",
       " ((0, 1), 517),\n",
       " ((0, 8), 517),\n",
       " ((0, 6), 505),\n",
       " ((4, 9), 493)]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "#create combinations of the trees\n",
    "combos = list(combinations_with_replacement((0,1,2,3,4,5,6,7,8,9,10),2))\n",
    "voting_blocks = {}\n",
    "#add them to a dict with the initialized value as 0 \n",
    "for i in range(len(combos)):\n",
    "  voting_blocks[combos[i]] = 0\n",
    "#delete the values where its the same row, i.e. {((0,0):0)}\n",
    "for i in range(len(forest11)):\n",
    "  del voting_blocks[(i,i)]\n",
    "# build dict\n",
    "for i in range(len(titanic_table)):\n",
    "  row = all_trees[i]\n",
    "  for com in voting_blocks:\n",
    "    if(row[com[0]] == row[com[1]]):\n",
    "      voting_blocks[com]+=1\n",
    "\n",
    "sorted(voting_blocks.items(), key=lambda pair: pair[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDz3NazI3upr"
   },
   "source": [
    "It looks like for 891 rows, trees 5 and 8 vote the same in 887 of them. So they vote the same except for 4 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pGLaWlIMhMoP"
   },
   "source": [
    "<h1>\n",
    "Part 2. Explore knn behavior\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "I'd like more information on how the rows are selected and how they vote.\n",
    "  <p>\n",
    "    Note for each of these problems I do not care what the actual prediction is. I am not computing accuracy but instead the internal working of the rows in voting.\n",
    "    <p>\n",
    "      <p>\n",
    "Given the constrained time of the midterm, I am going to slice off 100 rows and just work with that.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ipjCjQb4Fjp"
   },
   "outputs": [],
   "source": [
    "small_titanic = titanic_table[:100]  #use this slice in your code to cut down on computing time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a8T3WbkRp6ko"
   },
   "source": [
    "<h1>\n",
    "Problem 4: A row's top-k counts (20 points)\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "For each row, count how many times it made the top-k. Store your answer in top_list in sorted fashion. Here are the first part of my results\n",
    "  <pre>\n",
    "[(0, 30),\n",
    " (12, 28),\n",
    " (4, 27),\n",
    " (13, 27),\n",
    " (37, 27),\n",
    " (8, 19),\n",
    " (29, 19),\n",
    " (45, 19),\n",
    " (51, 19),\n",
    " (59, 19)]\n",
    " </pre>\n",
    "  So row 0 was among the top-k chosen 30 times out of 100 rows.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bI89hxwnq6Oi"
   },
   "source": [
    "<h3>Hint</h3>\n",
    "\n",
    "For this problem, and really most of the problems dealing with KNN, I started with the knn function and then modified it to do what is called for. For this problem, what is called for is a modified version of knn that does not return a prediction but instead the k rows selected to vote, i.e. the top k.\n",
    "<p>\n",
    "  Once I had the modified function, I called it in a loop that iterated over all the row indices of the Titanic table. The loop body updated a global data structure. At the end I got it in sorted list form and was finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNycIoYvVIEv"
   },
   "outputs": [],
   "source": [
    "def knn_topk(row_index, table, columns,k, target):\n",
    "  length = len(table) # get the length of the table\n",
    "  distance = {} # an empty dictionary to hold the distances between the row index and all the other rows in table\n",
    "  t= table[columns]\n",
    "  distance = euclidean_distance(t.iloc[[row_index]], t)\n",
    "  # sort the distances   \n",
    "  sorted_dist = sorted(distance.items(), key=operator.itemgetter(1)) # returns a sorted list of tuples \n",
    "  top_k = []\n",
    "  #find the top k and increment their counts\n",
    "  for key,item in enumerate(sorted_dist):\n",
    "    if (key > k):\n",
    "      break\n",
    "    top_k.append(item[0])\n",
    "  return top_k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1717
    },
    "colab_type": "code",
    "id": "_vt_fTvPVH5L",
    "outputId": "deb8f898-c8cd-4788-cc02-98d312c03737"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 32),\n",
       " (12, 28),\n",
       " (4, 27),\n",
       " (13, 27),\n",
       " (37, 27),\n",
       " (51, 27),\n",
       " (2, 21),\n",
       " (23, 20),\n",
       " (8, 19),\n",
       " (29, 19),\n",
       " (45, 19),\n",
       " (59, 19),\n",
       " (67, 19),\n",
       " (69, 18),\n",
       " (20, 17),\n",
       " (3, 16),\n",
       " (5, 16),\n",
       " (10, 16),\n",
       " (21, 16),\n",
       " (74, 16),\n",
       " (81, 16),\n",
       " (90, 16),\n",
       " (18, 15),\n",
       " (25, 15),\n",
       " (14, 14),\n",
       " (26, 14),\n",
       " (35, 14),\n",
       " (75, 14),\n",
       " (19, 13),\n",
       " (24, 13),\n",
       " (38, 13),\n",
       " (49, 13),\n",
       " (64, 13),\n",
       " (6, 12),\n",
       " (41, 12),\n",
       " (62, 12),\n",
       " (76, 12),\n",
       " (80, 12),\n",
       " (86, 12),\n",
       " (89, 12),\n",
       " (1, 11),\n",
       " (40, 11),\n",
       " (53, 11),\n",
       " (68, 11),\n",
       " (71, 11),\n",
       " (83, 11),\n",
       " (91, 11),\n",
       " (17, 10),\n",
       " (30, 10),\n",
       " (34, 10),\n",
       " (36, 10),\n",
       " (42, 10),\n",
       " (46, 10),\n",
       " (48, 10),\n",
       " (57, 10),\n",
       " (52, 9),\n",
       " (66, 9),\n",
       " (70, 9),\n",
       " (99, 9),\n",
       " (15, 8),\n",
       " (54, 8),\n",
       " (56, 8),\n",
       " (84, 8),\n",
       " (92, 8),\n",
       " (98, 8),\n",
       " (7, 7),\n",
       " (11, 7),\n",
       " (22, 7),\n",
       " (27, 7),\n",
       " (31, 7),\n",
       " (39, 7),\n",
       " (55, 7),\n",
       " (65, 7),\n",
       " (72, 7),\n",
       " (9, 6),\n",
       " (28, 6),\n",
       " (32, 6),\n",
       " (47, 6),\n",
       " (50, 6),\n",
       " (60, 6),\n",
       " (63, 6),\n",
       " (82, 6),\n",
       " (33, 5),\n",
       " (58, 5),\n",
       " (73, 5),\n",
       " (77, 5),\n",
       " (79, 5),\n",
       " (85, 5),\n",
       " (87, 5),\n",
       " (95, 5),\n",
       " (44, 3),\n",
       " (78, 3),\n",
       " (96, 3),\n",
       " (97, 3),\n",
       " (16, 2),\n",
       " (43, 2),\n",
       " (61, 2),\n",
       " (88, 2),\n",
       " (94, 2),\n",
       " (93, 0)]"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = {}\n",
    "for i in range(len(small_titanic)):\n",
    "  topk[i] = 0\n",
    "for i in range(len(small_titanic)):\n",
    "  top_k = knn_topk(i, small_titanic, usable_columns, 10, target)\n",
    "  # top_k is a list of the indices of the top k rows\n",
    "  for ind in top_k:\n",
    "    topk[ind]+=1\n",
    "sorted(topk.items(), key=lambda pair: pair[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GRGbsp05_2JW"
   },
   "source": [
    "<h1>\n",
    "Problem 5: A row's correct count (20 points)\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "For each row, count how many times it was correct. Store your result in correct_list, in sorted fashion. Here are the first part of my results.\n",
    "  <pre>\n",
    "[(0, 25),\n",
    " (12, 25),\n",
    " (37, 25),\n",
    " (4, 19),\n",
    " (13, 19),\n",
    " (51, 19),\n",
    " (59, 19),\n",
    " (67, 18),\n",
    " (69, 14),\n",
    " (8, 13)]\n",
    " </pre>\n",
    "  So when row 0 was in the top-k, it was correct 25 times.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yl7-4037Zyq7"
   },
   "outputs": [],
   "source": [
    "def knn3(row_index, table, columns,k, target):\n",
    "  length = len(table) # get the length of the table\n",
    "  distance = {} # an empty dictionary to hold the distances between the row index and all the other rows in table\n",
    "  t= table[columns]\n",
    "  distance = euclidean_distance(t.iloc[[row_index]], t)\n",
    "  # sort the distances   \n",
    "  sorted_dist = sorted(distance.items(), key=operator.itemgetter(1)) # returns a sorted list of tuples \n",
    "  \n",
    "  votes = {}\n",
    "  \n",
    "  #gather votes from k rows \n",
    "  for key,item in enumerate(sorted_dist):\n",
    "    if (key > k):\n",
    "      break\n",
    "    row = table.iloc[item[0]]\n",
    "    vote = row[target]\n",
    "    votes[item[0]] = vote\n",
    "  return votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1717
    },
    "colab_type": "code",
    "id": "GtcJ0KkzZ5NU",
    "outputId": "fb56f09e-6838-4eab-f1e2-4e138386e5df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 26),\n",
       " (12, 25),\n",
       " (37, 25),\n",
       " (51, 25),\n",
       " (4, 19),\n",
       " (13, 19),\n",
       " (59, 19),\n",
       " (67, 19),\n",
       " (69, 18),\n",
       " (2, 14),\n",
       " (75, 14),\n",
       " (8, 13),\n",
       " (29, 13),\n",
       " (45, 13),\n",
       " (80, 12),\n",
       " (86, 12),\n",
       " (89, 12),\n",
       " (3, 11),\n",
       " (91, 11),\n",
       " (5, 10),\n",
       " (25, 10),\n",
       " (90, 10),\n",
       " (6, 9),\n",
       " (19, 9),\n",
       " (20, 9),\n",
       " (24, 8),\n",
       " (76, 8),\n",
       " (10, 7),\n",
       " (23, 7),\n",
       " (35, 7),\n",
       " (53, 7),\n",
       " (56, 7),\n",
       " (57, 7),\n",
       " (62, 7),\n",
       " (64, 7),\n",
       " (84, 7),\n",
       " (1, 6),\n",
       " (9, 6),\n",
       " (15, 6),\n",
       " (21, 6),\n",
       " (22, 6),\n",
       " (26, 6),\n",
       " (42, 6),\n",
       " (48, 6),\n",
       " (68, 6),\n",
       " (83, 6),\n",
       " (17, 5),\n",
       " (30, 5),\n",
       " (34, 5),\n",
       " (39, 5),\n",
       " (58, 5),\n",
       " (66, 5),\n",
       " (74, 5),\n",
       " (77, 5),\n",
       " (81, 5),\n",
       " (87, 5),\n",
       " (95, 5),\n",
       " (7, 4),\n",
       " (14, 4),\n",
       " (18, 4),\n",
       " (27, 4),\n",
       " (28, 4),\n",
       " (31, 4),\n",
       " (32, 4),\n",
       " (38, 4),\n",
       " (40, 4),\n",
       " (41, 4),\n",
       " (46, 4),\n",
       " (47, 4),\n",
       " (49, 4),\n",
       " (50, 4),\n",
       " (52, 4),\n",
       " (54, 4),\n",
       " (63, 4),\n",
       " (70, 4),\n",
       " (71, 4),\n",
       " (82, 4),\n",
       " (92, 4),\n",
       " (98, 4),\n",
       " (99, 4),\n",
       " (11, 3),\n",
       " (33, 3),\n",
       " (36, 3),\n",
       " (79, 3),\n",
       " (85, 3),\n",
       " (43, 2),\n",
       " (44, 2),\n",
       " (55, 2),\n",
       " (60, 2),\n",
       " (61, 2),\n",
       " (65, 2),\n",
       " (78, 2),\n",
       " (94, 2),\n",
       " (96, 2),\n",
       " (72, 1),\n",
       " (73, 1),\n",
       " (88, 1),\n",
       " (97, 1),\n",
       " (16, 0),\n",
       " (93, 0)]"
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_pairs = {} # a list  of tuples (index,times correct)\n",
    "for i in range(len(small_titanic)):\n",
    "  participant_pairs[i] = 0\n",
    "participant_pairs\n",
    "for i in range(len(small_titanic)):\n",
    "  row = small_titanic.loc[i]\n",
    "  targ = row[target]\n",
    "  votes = knn3(i, small_titanic, usable_columns, 10, target)\n",
    "  for ind,val in votes.items():\n",
    "    if (val == targ):\n",
    "      participant_pairs[ind]+=1\n",
    "  \n",
    "pairs = participant_pairs.items()\n",
    "sorted(pairs, key=lambda pair: pair[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "3I7M9aHDD0bT",
    "outputId": "f6edc6ae-331c-4e70-8f4d-e3f1eb512d17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 25),\n",
       " (12, 25),\n",
       " (37, 25),\n",
       " (4, 19),\n",
       " (13, 19),\n",
       " (51, 19),\n",
       " (59, 19),\n",
       " (67, 18),\n",
       " (69, 14),\n",
       " (8, 13)]"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dhkbicwyCE4-"
   },
   "source": [
    "<h1>\n",
    "Problem 6: Put them together to get each row's \"batting average\" (10 points)\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Use `top_list` and `correct_list` to compute what percentage each row was correct, i.e., divide times correct by total times in top-k. Then sort the list by highest average. When I did that I got results below taken from the slice ` [50:80]`.  I am showing my results more toward the middle to  give you a better answer to shoot for. REMEMBER: this is for items 50:80.\n",
    "  <pre>\n",
    "[(82, 0.6),\n",
    " (85, 0.6),\n",
    " (62, 0.5833333333333334),\n",
    " (7, 0.5714285714285714),\n",
    " (31, 0.5714285714285714),\n",
    " (48, 0.5714285714285714),\n",
    " (92, 0.5714285714285714),\n",
    " (20, 0.5625),\n",
    " (53, 0.5555555555555556),\n",
    " (66, 0.5555555555555556),\n",
    " (1, 0.5454545454545454),\n",
    " (68, 0.5454545454545454),\n",
    " (30, 0.5),\n",
    " (34, 0.5),\n",
    " (35, 0.5),\n",
    " (64, 0.5),\n",
    " (83, 0.5),\n",
    " (88, 0.5),\n",
    " (96, 0.5),\n",
    " (98, 0.5),\n",
    " (70, 0.4444444444444444),\n",
    " (99, 0.4444444444444444),\n",
    " (11, 0.42857142857142855),\n",
    " (5, 0.4),\n",
    " (21, 0.4),\n",
    " (27, 0.4),\n",
    " (40, 0.4),\n",
    " (46, 0.4),\n",
    " (71, 0.4),\n",
    " (23, 0.375)]\n",
    " </pre>\n",
    "  So row 82 is batting 60%. When I divide the number of times it voted correctly (in `correct_list`) by the number of times it made the top-k (in `top_list`), it was correct .6 (60%) of the time. It has a 600 batting average!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AjAbRlxnsag0"
   },
   "source": [
    "<h3>Hint</h3>\n",
    "\n",
    "For this problem I did not define a new function. I just figured out a way to get info out of top_list and correct_list to get what I wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "Fr0Wl2D8EAlg",
    "outputId": "a6bf2592-5cd1-4a97-dc75-4792ff96e6e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(82, 0.6),\n",
       " (85, 0.6),\n",
       " (62, 0.5833333333333334),\n",
       " (7, 0.5714285714285714),\n",
       " (31, 0.5714285714285714),\n",
       " (48, 0.5714285714285714),\n",
       " (92, 0.5714285714285714),\n",
       " (20, 0.5625),\n",
       " (53, 0.5555555555555556),\n",
       " (66, 0.5555555555555556),\n",
       " (1, 0.5454545454545454),\n",
       " (68, 0.5454545454545454),\n",
       " (30, 0.5),\n",
       " (34, 0.5),\n",
       " (35, 0.5),\n",
       " (64, 0.5),\n",
       " (83, 0.5),\n",
       " (88, 0.5),\n",
       " (96, 0.5),\n",
       " (98, 0.5),\n",
       " (70, 0.4444444444444444),\n",
       " (99, 0.4444444444444444),\n",
       " (11, 0.42857142857142855),\n",
       " (5, 0.4),\n",
       " (21, 0.4),\n",
       " (27, 0.4),\n",
       " (40, 0.4),\n",
       " (46, 0.4),\n",
       " (71, 0.4),\n",
       " (23, 0.375)]"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remember that you should show rows 50:80\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBDW7kqMkV1F"
   },
   "source": [
    "<h2>\n",
    "Extra Credit: razor-thin majority\n",
    "</h2>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Find what target rows were decided by either 1 vote or were a tie. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lfvy__LRs-vP"
   },
   "source": [
    "<h3>Hint</h3>\n",
    "\n",
    "I went back to modifying knn for this problem. I replaced the knn function with a razor_thin function. It did much of the same work as knn, but instead of returning a prediction, it returned True or False. True if there was razor thin majority (or tie vote) and False otherwise. I then kept track of what rows I got a True for and sorted the list and was done.\n",
    "<p>\n",
    "  Caveat: I found no razor-thin votes so had an empty list. I even tried with entire titanic table and still got no razor thins. I wonder if I can put this off to \"group think\". Never seems to be a close call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ubUqJMuQs0Kx",
    "outputId": "0810851f-7d28-4781-fd73-986d64eef894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "midterm2_w19.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
