{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fe8qblPnzh04"
   },
   "source": [
    "<h1>\n",
    "<center>\n",
    "Module 3: Automating tree-building (Part 1)\n",
    "</center>\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "\n",
    "The goal is to eventually build a tool that will generate a decision tree for us. So instead of us trying to guess what nodes and leaves to put in a tree, the tool will do it for us. The tool I have in mind will incrementally build a tree. First, it will find the best root node. Then it will follow each branch and ask what nodes are the best for  each. Eventually it will halt when every path through the tree ends in a leaf (prediction) node.\n",
    "<p>\n",
    "We won't take all that on in this module. Instead we will look at a key piece: judging what node should be added to the tree next. To make this judgement, we need a way to measure the goodness of a node/question.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "MSP9zR4hzh06",
    "outputId": "0634b31a-1519-4368-aeac-5481db757411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWhqDsHw0Cmg"
   },
   "outputs": [],
   "source": [
    "with open('/content/gdrive/My Drive/class_tables/titanic_wrangled_week2.csv', 'r') as f:\n",
    "  titanic_table = pd.read_csv(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "colab_type": "code",
    "id": "I2_I0D9Dzh1C",
    "outputId": "7dac93da-fb8c-4fd5-a822-9ebcb7dcb86a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>no_age</th>\n",
       "      <th>filled_age</th>\n",
       "      <th>emb_C</th>\n",
       "      <th>emb_Q</th>\n",
       "      <th>emb_S</th>\n",
       "      <th>emb_nan</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>age_Child</th>\n",
       "      <th>age_Adult</th>\n",
       "      <th>age_Senior</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ok_child</th>\n",
       "      <th>pclass_1</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Child</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \\\n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S   \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C   \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S   \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S   \n",
       "\n",
       "   no_age  filled_age  emb_C  emb_Q  emb_S  emb_nan age_bin  age_Child  \\\n",
       "0       0        22.0      0      0      1        0   Child          1   \n",
       "1       0        38.0      1      0      0        0   Adult          0   \n",
       "2       0        26.0      0      0      1        0   Child          1   \n",
       "3       0        35.0      0      0      1        0   Adult          0   \n",
       "4       0        35.0      0      0      1        0   Adult          0   \n",
       "\n",
       "   age_Adult  age_Senior  sex_female  sex_male  ok_child  pclass_1  pclass_2  \\\n",
       "0          0           0           0         1         0         0         0   \n",
       "1          1           0           1         0         0         1         0   \n",
       "2          0           0           1         0         0         0         0   \n",
       "3          1           0           1         0         0         1         0   \n",
       "4          1           0           0         1         0         0         0   \n",
       "\n",
       "   pclass_3  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I am setting the option to see all the columns of our table as we build it.\n",
    "pd.set_option('display.max_columns', None)\n",
    "titanic_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwamuQqDzh1H"
   },
   "source": [
    "<hr>\n",
    "<h1>\n",
    "Importing library\n",
    "</h1>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "Bring in the functions we defined in past modules.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "FAT2JoLv4WbI",
    "outputId": "9cf18a73-3f99-44e3-8565-ae65d78ddd46"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-13e69e0d-f5f3-4878-9a59-e7c6e27e114d\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-13e69e0d-f5f3-4878-9a59-e7c6e27e114d\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving library_w19_week2.py to library_w19_week2.py\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()\n",
    "# choose the file on your computer to upload it then\n",
    "from library_w19_week2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U7l-CiSPzh1S",
    "outputId": "4dbe275e-23b8-4389-d066-d439bd82dd97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t f1\t informedness\t predictor_case\t \n"
     ]
    }
   ],
   "source": [
    "%who function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mNhqv3MBzh1W"
   },
   "source": [
    "<hr>\n",
    "<h1>\n",
    "Revisiting the stump\n",
    "</h1>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "Remember the tree we built in module 2? Here it is again.\n",
    "<p>\n",
    "<img src=\"https://www.dropbox.com/s/2940iqadl1nswbq/stump.png?raw=1\" width=\"300\" height=\"300\">\n",
    "<p>\n",
    "Here is a question I want to ask: Is using sex_female as a root node better than using age_child as a root node? Let's set out to answer that question.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uzKospMezh1Y"
   },
   "source": [
    "<div class=just_text>\n",
    "One thing I will need is the probablity of our target column `Survived`. First I'll build a Series with the counts of the 2 values.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "3Gk306L0zh1Z",
    "outputId": "88dee970-df20-4c4e-9106-911f13efd508"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_counts = titanic_table['Survived'].value_counts()  # returns a series\n",
    "root_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1n1Mx_7ezh1d"
   },
   "outputs": [],
   "source": [
    "def probabilities(counts):\n",
    "    count_0 = 0 if 0 not in counts else counts[0]  #could have no 0 values\n",
    "    count_1 = 0 if 1 not in counts else counts[1]\n",
    "    total = count_0 + count_1\n",
    "    probs = (0,0) if total == 0 else (count_0/total, count_1/total)  #build 2-tuple\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4-Fbf6cazh1h",
    "outputId": "bf40c11d-5110-4609-dd56-6d936c085a1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6161616161616161, 0.3838383838383838)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_probs = probabilities(root_counts)\n",
    "root_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GnFJuGFozh1n"
   },
   "source": [
    "<div class=just_text>\n",
    "All we did is count how many 0s and how many 1s relative to the total number of passengers. When we do the divisions, we get the probabilities we need.\n",
    "  <p>We can see that 61.6% of passengers perished.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xA0VzV3Ozh1r"
   },
   "source": [
    "<hr>\n",
    "<h1>\n",
    "Gini to the rescue\n",
    "</h1>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "<p>\n",
    "There are 2 well-known algorithms for measuring the goodness of a splitter (i.e., a binary column we are contemplating adding to our tree), *`Entropy`* and *`Gini`*. I am going to choose Gini going forward in this course. If you want a good discussion of the difference between the two, with pointers to more theoretical arguments, this is a good place to start: https://datascience.stackexchange.com/questions/10228/gini-impurity-vs-entropy. I'll let you explore Entropy in this week's assignment and compare how it does against gini.\n",
    "<p>\n",
    "The general idea is that we are going to look at the mixture of 0s and 1s in the table before we split with a column. Then we split and look at the mixtures of the 2 sub-tables (one on each branch). Here is the Gini formula (sometimes called *`Gini impurity`*) - P stands for probability (obtained by our `probabilities` function):\n",
    "<p>\n",
    "`Gini index = 1 – (P(Target=0)**2 + P(Target=1)**2)`\n",
    "<p>\n",
    "We will apply it to the before-split table and the 2 after-split sub-tables. We will end up with 3 separate gini values.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ep3m3YV_zh1s"
   },
   "outputs": [],
   "source": [
    "def gini(counts):\n",
    "    (p0,p1) = probabilities(counts)\n",
    "    sum_probs = p0**2 + p1**2\n",
    "    gini = 1 - sum_probs\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6g4-0Mi4zh1v",
    "outputId": "6d3baa6f-4202-4011-af28-3f0e4d4bce7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4730129578614428"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini(root_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isb5S1zWzh10"
   },
   "source": [
    "<div class=just_text>\n",
    "We now have the Gini score for the Titanic table as a whole. The lower the score, the better.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xan4eFczzh11"
   },
   "source": [
    "<h2>\n",
    "Do the split\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "We need to build 2 sub-tables that corresond to the 1 (True) and 0 (False) branches of the column we are splitting on. Let's do that now.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hinhmdgrzh12"
   },
   "outputs": [],
   "source": [
    "true_table = titanic_table.loc[titanic_table['sex_female'] == 1]  # one branch\n",
    "false_table = titanic_table.loc[titanic_table['sex_female'] == 0] # the other branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XWh14jXPzh16"
   },
   "source": [
    "<div class=just_text>\n",
    "We now have the 2 sub-tables, one for True branch and one for False branch.\n",
    "We want to apply gini to each sub-table. First get the counts, then the probabilities. That will give us what we need to get Gini score for each subtable.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m4zMIFa1zh18",
    "outputId": "7127ffb9-7f70-4911-ffbf-2733c044c1d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25796178343949044, 0.7420382165605095)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_counts = true_table['Survived'].value_counts()  # Note using true_table and not titanic_table\n",
    "true_probs = probabilities(true_counts)\n",
    "true_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P4i0MKwOzh2A",
    "outputId": "f4cecda1-0f9f-42e6-defb-a6a29e2487c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8110918544194108, 0.18890814558058924)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_counts = false_table['Survived'].value_counts()  # using false_table\n",
    "false_probs = probabilities(false_counts)\n",
    "false_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4Jcp8v_szh2F",
    "outputId": "b15b3ae6-bf77-4f62-abe4-0e1516fe0353"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3828350034484158"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini(true_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TgoFazmbzh2K",
    "outputId": "08443175-9eb6-4485-db2a-2fb159f4eb83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3064437162277842"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini(false_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDS-YJFVzh2O"
   },
   "source": [
    "<div class=just_text>\n",
    "Cool. We now have 3 separate gini values for the 3 tables involved. Our next step is to combine these values in a way  that gives us an overall goodness-of-the-split score. To do so, we will use something called *`gini information gain`* (GIG). The formula for GIG is as follows:\n",
    "<p>\n",
    "`GIG = start_gini − (w_true * gini_true + w_false * gini_false)`\n",
    "<p>\n",
    "where w_true is a weight of |true_table|/|titanic_table| (i.e., the size of true_table divided by the size of the starting table) and w_false is a weight of |false_table|/|titanic_table|.\n",
    "<p>\n",
    "Unlike plain Gini, which uses 0 as the best score, the gig uses 1 as the best score.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mF3LSmANzh2P"
   },
   "source": [
    "<h2>\n",
    "Let's put it all together\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "Let's build a function gig that pulls everything together in one place. The idea is that if you supply a starting table and a column to split on, it will calculate the goodness of the split as the gig score. The bigger, the better.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U93cmMaPzh2Q"
   },
   "outputs": [],
   "source": [
    "def gig(starting_table, split_column, target_column):\n",
    "    \n",
    "    #split into two branches, i.e., two sub-tables\n",
    "    true_table = starting_table.loc[starting_table[split_column] == 1]\n",
    "    false_table = starting_table.loc[starting_table[split_column] == 0]\n",
    "    \n",
    "    #Now see how the target column is divided up in each sub-table (and the starting table)\n",
    "    true_counts = true_table[target_column].value_counts()  # Note using true_table and not starting_table\n",
    "    false_counts = false_table[target_column].value_counts()  # Note using false_table and not starting_table\n",
    "    starting_counts = starting_table[target_column].value_counts() \n",
    "    \n",
    "    #compute the gini impurity for the 3 tables\n",
    "    starting_gini = gini(starting_counts)\n",
    "    true_gini = gini(true_counts)\n",
    "    false_gini = gini(false_counts)\n",
    "\n",
    "    #compute the weights\n",
    "    starting_size = len(starting_table.index)\n",
    "    true_weight = 0.0 if starting_size == 0 else len(true_table.index)/starting_size\n",
    "    false_weight = 0.0 if starting_size == 0 else len(false_table.index)/starting_size\n",
    "    \n",
    "    #wrap it up and put on a bow\n",
    "    gig = starting_gini - (true_weight * true_gini + false_weight * false_gini)\n",
    "    \n",
    "    return gig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FdQiZx3Wzh2S",
    "outputId": "abf2525f-a210-45eb-a293-ead524b1ce89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1396479574728524"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gig(titanic_table, 'sex_female', 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mCI34qfHzh2V"
   },
   "source": [
    "<hr>\n",
    "<h2>\n",
    "Compare with another split\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "Ok, this is pretty cool. We can now check out various columns to choose for a split and see what the gig is for each. Let's try ok_child.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hJ-U3BN4zh2X",
    "outputId": "66dc7ebd-e175-4cbb-b84f-2f38a869439a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010321527428076904"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gig(titanic_table, 'ok_child', 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ckjpjnBWzh2e"
   },
   "source": [
    "<div class=just_text>\n",
    "It has lower score so \"worse\" than sex_female: you want low gini scores but high gig scores.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kfF6jDQqzh2e"
   },
   "source": [
    "<hr>\n",
    "<h2>\n",
    "Let's go down a branch\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "We were comparing different choices for the root node. Assume we try all columns and sex_female has largest gig score. So we choose it as the root node. We now have 2 branches with a sub-table on each. You guessed it. We can now run the gig on each of the sub-tables to decide what the best choice is. Let's focus on the false branch, i.e., sex_female has value 0. First I'll build the sub-table.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1aU8utwzh2f"
   },
   "outputs": [],
   "source": [
    "false_table = titanic_table.loc[titanic_table['sex_female'] == 0]  #we already have this table (see above) so just doing it here as reminder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j18oFGDDzh2j"
   },
   "source": [
    "<div class=just_text>\n",
    "Now we can start exploring choices for the sub-node\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0pipitjpzh2k",
    "outputId": "9acbf3ff-5550-4bd1-996b-c9ebcd5321a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013270999683399065"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try emb_S\n",
    "\n",
    "gig(false_table, 'emb_S', 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5d2RyXmWzh2o",
    "outputId": "d05c78c6-d848-4b6b-84cc-001373c6166b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01736419615130408"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try pclass_1\n",
    "\n",
    "gig(false_table, 'pclass_1', 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CKPNLeTWzh2r"
   },
   "source": [
    "<div class=just_text>\n",
    "Looks like pclass_1 is the winner between the 2. It has higher gig score then emb_S.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-094pJmwzh2x"
   },
   "source": [
    "<hr>\n",
    "<h1>\n",
    "Let's do one more thing\n",
    "</h1>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "I think I am fairly close to being able to automate the selection of the best split given the starting table. I'll first decide on the columns I want in the candidate set. Then just map over them to get their gig scores. Finally I'll take the max value.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "J8m-5gLZzh2y",
    "outputId": "f647d169-93fa-4126-910d-99cd1c0d0c71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked', 'no_age', 'filled_age',\n",
       "       'emb_C', 'emb_Q', 'emb_S', 'emb_nan', 'age_bin', 'age_Child',\n",
       "       'age_Adult', 'age_Senior', 'sex_female', 'sex_male', 'ok_child',\n",
       "       'pclass_1', 'pclass_2', 'pclass_3'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_table.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GtSHOGKxzh23"
   },
   "source": [
    "<div class=just_text>\n",
    "Now I'll just copy and paste from above output and delete the columns that are non-binary or not-useful. I could have done this programatically but this seems simpler.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxPR4ncxzh23"
   },
   "outputs": [],
   "source": [
    "column_candidates = ['no_age',\n",
    "       'emb_C', 'emb_Q', 'emb_S', 'emb_nan', 'age_Child',\n",
    "       'age_Adult', 'age_Senior', 'sex_female', \n",
    "        'ok_child', 'pclass_1', 'pclass_2',\n",
    "       'pclass_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0HYjkK_zh27"
   },
   "source": [
    "<div class=just_text>\n",
    "I'm ready to do a mapping. This mapping is for the root node.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "Kmo9JfHEzh28",
    "outputId": "d68ef1ac-f11d-43d8-9078-9e7960c41c0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sex_female', 0.1396479574728524),\n",
       " ('pclass_3', 0.049137852428292605),\n",
       " ('pclass_1', 0.03866453536487213),\n",
       " ('emb_C', 0.013388557365673015),\n",
       " ('emb_S', 0.011461161069371395),\n",
       " ('ok_child', 0.010321527428076904),\n",
       " ('pclass_2', 0.004121814088680398),\n",
       " ('no_age', 0.0040207042231273915),\n",
       " ('emb_nan', 0.0017082345882156735),\n",
       " ('age_Child', 0.0006257143143247879),\n",
       " ('age_Senior', 0.00048458255066557987),\n",
       " ('age_Adult', 0.00019771072603869122),\n",
       " ('emb_Q', 6.303036606203349e-06)]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gig_scores = map(lambda col: (col, gig(titanic_table, col, 'Survived')), column_candidates)\n",
    "gig_sorted = sorted(gig_scores, key=lambda item: item[1], reverse=True)\n",
    "gig_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ruFvCiKzzh2_"
   },
   "source": [
    "<div class=just_text>\n",
    "Now that we know sex_female is the best choice for the root node, we can follow both its true and false branches and rerun the mapping for each. We will take on this problem in the next module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nsCWiWvKzh2_"
   },
   "source": [
    "\n",
    "<h2>\n",
    "Are we done?\n",
    "</h2>\n",
    "<p>\n",
    "<div class=h1_cell>\n",
    "Have we chosen the best column for the root? I can say we have chosen the best column from the candidate columns we started with. But we did not have all the columns, e.g., we are missing SibSp, Parch. And there are myriad ways to bin the continuous columns of Fare and Age.\n",
    "<p>\n",
    "So, no, I can't say I have the best column. It would not be hard to wrangle the remaining discrete columns to put them in play. It also would not be hard to programmatically generate all possible bins for Fare and Age. However, by my calculation, taking just the integers from 0 to 80 for age, the computational cost is O(80**3).\n",
    "  <p>\n",
    "    So yes, I am happy with the columns I have for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vrRlIjFyzh3B"
   },
   "source": [
    "<hr>\n",
    "<h1>No writing necessary</h1>\n",
    "<div class=h1_cell>\n",
    "\n",
    "We did not change the titanic_table nor the titanic_results table. So no need to write them out.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XyVmE-228WGu"
   },
   "source": [
    "<hr>\n",
    "<h1>But we did add some new functions</h1>\n",
    "<div class=h1_cell>\n",
    "\n",
    "Sowe need a newr library_w19_week3.py file. I'd open your library_w19_week2.py file, add the new functions from this notebook, then save as library_w19_week3.py. That gives you all the functions from week 2 plus the new ones.\n",
    "  <p>\n",
    "    IMPORTANT: you need to create your library before moving on to the loan table assignment. Do it now!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RdGGU0cxzh3E"
   },
   "source": [
    "<hr>\n",
    "<h1>Next up</h1>\n",
    "<div class=h1_cell>\n",
    "\n",
    "    In the next module, we will build on the gig function. We will use it to build a full tree.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gini_intro_w19_v2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
